{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Stopping for Batch-mode Experimentation\n",
    "\n",
    "> Code for using active learning and automatic stopping for designing experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created with nbdev by Zoltan Puha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`python -m pip install  git+https://github.com/puhazoli/asbe`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use\n",
    "ASBE builds on the functional views of modAL, where an AL algorithm can be run by putting together pieces. You need the following ingredients:\n",
    "- an ITE estimator (`ITEEstimator()`),\n",
    "- an acquisition function,\n",
    "- and an assignment function.\n",
    "- Additionaly, you can add a stopping criteria to your model. \n",
    "If all the above are defined, you can construct an `ASLearner`, which will help you in the active learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/dask/dataframe/utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "from asbe.core import *\n",
    "from asbe.base import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "X = np.random.normal(size = N*2).reshape((-1,2))\n",
    "t = np.random.binomial(n = 1, p = 0.5, size = N)\n",
    "y = np.random.binomial(n = 1, p = 1/(1+np.exp(X[:, 1]*2 + t*3)))\n",
    "ite = 1/(1+np.exp(X[:, 1]*2 + t*3)) - 1/(1+np.exp(X[:, 1]*2))\n",
    "a = BaseITEEstimator(LogisticRegression(solver=\"lbfgs\"))\n",
    "a.fit(X, t, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning actively\n",
    "Similarly, you can create an `ASLearner`, for which you will initialize the dataset and set the preferred modeling options. Let's see how it works:\n",
    "- we will use XBART to model the treatment effect with a one-model approach\n",
    "- we will use expected model change maximization\n",
    "    - for that, we need an approximate model, we will use the `SGDRegressor`\n",
    "    \n",
    "You can call `.fit()` on the `ASLearner`, which will by default fit the training data supplied. To select new units from the pool, you just need to call the `query()` method, which will return the selected `X` and the `query_ix` of these units. `ASLearner` expects the `n2` argument, which tells  how many units are queried at once. For sequential AL, we can set this to 1. Additionally, some query strategies can require different treatment effect estimates - EMCM needs uncertainty around the ITE. We can explicitly tell the the `ITEEstimator` to return all the predicted treatment effects. \n",
    "Then, we can teach the newly acquired units to the learner, by calling the `teach` function. The `score` function provides an evaluation of the given learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xbart import XBART\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3101592544754032"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, t_train, t_test, y_train, y_test, ite_train, ite_test = train_test_split(\n",
    "    X, t, y, ite,  test_size=0.8, random_state=1005)\n",
    "ds = {\"X_training\": X_train,\n",
    "     \"y_training\": y_train,\n",
    "     \"t_training\": t_train,\n",
    "     \"X_pool\": deepcopy(X_test), \n",
    "     \"y_pool\": deepcopy(y_test),\n",
    "     \"t_pool\": deepcopy(t_test),\n",
    "     \"X_test\": X_test,\n",
    "     \"y_test\": y_test,\n",
    "      \"t_test\": t_test,\n",
    "      \"ite_test\": ite_test\n",
    "     }\n",
    "asl = BaseActiveLearner(estimator = BaseITEEstimator(model = XBART(),\n",
    "                                         two_model=False),\n",
    "                        acquisition_function=BaseAcquisitionFunction(),\n",
    "                        assignment_function=BaseAssignmentFunction(),\n",
    "                        stopping_function = None,\n",
    "                        dataset=ds)\n",
    "asl.fit()\n",
    "X_new, query_idx = asl.query(no_query=10)\n",
    "asl.teach(query_idx)\n",
    "preds = asl.predict(asl.dataset[\"X_test\"])\n",
    "asl.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
