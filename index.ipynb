{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Stopping for Batch-mode Experimentation\n",
    "\n",
    "> Code for using active learning and automatic stopping for designing experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created with nbdev by ZP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`python -m pip install  git+https://github.com/puhazoli/asbe`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use\n",
    "ASBE builds on the functional views of modAL, where an AL algorithm can be run by putting together pieces. You need the following ingredients:\n",
    "- an ITE estimator (`ITEEstimator()`),\n",
    "- an acquisition function,\n",
    "- and an assignment function.\n",
    "- Additionaly, you can add a stopping criteria to your model. \n",
    "If all the above are defined, you can construct an `ASLearner`, which will help you in the active learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/dask/dataframe/utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "from asbe.core import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "X = np.random.normal(size = N).reshape((int(N/2),2))\n",
    "t = np.random.binomial(n = 1, p = 0.5, size = int(N/2))\n",
    "y = np.random.binomial(n = 1, p = 1/(1+np.exp(X[:, 1]*2 + t*3)))\n",
    "a = ITEEstimator(LogisticRegression(solver=\"lbfgs\"))\n",
    "a.fit(X, t, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning actively\n",
    "Similarly, you can create an `ASLearner`, for which you will initialize the dataset and set the preferred modeling options. Let's see how it works:\n",
    "- we will use XBART to model the treatment effect with a one-model approach\n",
    "- we will use expected model change maximization\n",
    "    - for that, we need an approximate model, we will use the `SGDRegressor`\n",
    "    \n",
    "You can call `.fit()` on the `ASLearner`, which will by default fit the training data supplied. To select new units from the pool, you just need to call the `query()` method, which will return the selected `X` and the `query_ix` of these units. `ASLearner` expects the `n2` argument, which tells  how many units are queried at once. For sequential AL, we can set this to 1. Additionally, some query strategies can require different treatment effect estimates - EMCM needs uncertainty around the ITE. We can explicitly tell the the `ITEEstimator` to return all the predicted treatment effects. \n",
    "Then, we can teach the newly acquired units to the learner, by calling the `teach` function. The `score` function provides an evaluation of the given learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xbart import XBART\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.190240308680396"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, t_train, t_test, y_train, y_test = train_test_split(X, t, y, test_size=0.8,\n",
    "                                                                    random_state=1005)\n",
    "X_pool = np.copy(X_test)\n",
    "asl = ASLearner(estimator = ITEEstimator(model = XBART(),\n",
    "                                         two_model=False), \n",
    "         query_strategy=expected_model_change_maximization,\n",
    "         X_training = X_train,\n",
    "         t_training = t_train,\n",
    "         y_training = y_train,\n",
    "         X_pool     = X_pool,\n",
    "         X_test     = X_test,\n",
    "         approx_model=SGDRegressor())\n",
    "asl.fit()\n",
    "X_new, query_idx = asl.query(asl.X_pool, n2=10, return_mean = False)\n",
    "asl.teach(X_new, t_test[query_idx], y_test[query_idx])\n",
    "preds, *rest = asl.predict(asl.X_test)\n",
    "asl.score(preds, y_test, t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
