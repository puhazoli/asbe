{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASBE - Automatic Stopping for Batch Experiments\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cells will be exported to asbe.core,\n",
      "unless a different module is specified after an export flag: `%nbdev_export special.module`\n"
     ]
    }
   ],
   "source": [
    "%nbdev_default_export core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "import numpy as np\n",
    "\n",
    "from modAL.models.base import BaseLearner\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, RegressorMixin\n",
    "from typing import Union, Optional\n",
    "from copy import deepcopy\n",
    "from pylift.eval import UpliftEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def random_batch_sampling(classifier, X_pool, n2):\n",
    "    \"Randomly sample a batch from a pool of unlabaled samples\"\n",
    "    n_samples = X_pool.shape[0]\n",
    "    query_idx = np.random.choice(range(n_samples), size=n2,replace=False)\n",
    "    return X_pool[query_idx], query_idx\n",
    "\n",
    "def uncertainty_batch_sampling(classifier, X_pool, n2, **kwargs):\n",
    "    \"Select the top $n_2$ most uncertain units\"\n",
    "    ite_preds, y1_preds, y_preds = classifier.predict(X_pool, **kwargs)\n",
    "    # Calculate variance based on predicted\n",
    "    if y1_preds.shape[0] <= 1 or \\\n",
    "    len(y1_preds.shape) <= 1:\n",
    "            raise Exception(\"Not possible to calculate uncertainty when dimensions <=1 \")\n",
    "    ite_vars = np.var(classifier.estimator.y1_preds - classifier.estimator.y0_preds, axis=1)\n",
    "    query_idx = np.argsort(ite_vars)[-n2:][::-1]\n",
    "        \n",
    "    return X_pool[query_idx], query_idx\n",
    "\n",
    "def expected_model_change_maximization(classifier, X_pool, n2, **kwargs):\n",
    "    # Get mean of predicted ITE\n",
    "    ite_train_preds, y1_train_preds, y_train_preds = \\\n",
    "        classifier.predict(classifier.X_training, **kwargs)\n",
    "    classifier.approx_model = classifier.approx_model.fit(\n",
    "        classifier.X_training,\n",
    "        ite_train_preds if ite_train_preds.shape[1]>0 else np.mean(ite_train_preds, axis=1))\n",
    "    print(classifier.approx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "estimator_type = ClassifierMixin\n",
    "class ASLearner(BaseLearner):\n",
    "    \"\"\"A(ctively)S(topping)Learner class for automatic stopping in batch-mode AL\"\"\"\n",
    "    def __init__(self,\n",
    "                 estimator: estimator_type=None, \n",
    "                 query_strategy=None,\n",
    "                 assignment_fc=None,\n",
    "                 X_training: np.ndarray = None,\n",
    "                 t_training: np.ndarray = None,\n",
    "                 y_training: np.ndarray = None,\n",
    "                 X_pool: np.ndarray = None,\n",
    "                 X_test: np.ndarray = None,\n",
    "                 approx_model: RegressorMixin = None\n",
    "                ) -> None:\n",
    "        self.estimator = estimator\n",
    "        self.query_strategy = query_strategy\n",
    "        self.assignment_fc = assignment_fc\n",
    "        self.X_training = X_training\n",
    "        self.y_training = y_training\n",
    "        self.t_training = t_training\n",
    "        self.X_pool     = X_pool\n",
    "        self.X_test     = X_test\n",
    "        self.approx_model = approx_model\n",
    "        \n",
    "    def _add_queried_data_class(self, X, t, y):\n",
    "        self.X_training = np.vstack((self.X_training, X))\n",
    "        self.t_training = np.concatenate((self.t_training, t))\n",
    "        self.y_training = np.concatenate((self.y_training, y))\n",
    "    \n",
    "    def _update_estimator_values(self):\n",
    "        self.estimator.__dict__.update(X_training = self.X_training,\n",
    "                               y_training  =        self.y_training,\n",
    "                               t_training  =        self.t_training,\n",
    "                               X_test      =        self.X_test)\n",
    "\n",
    "    def teach(self, X_new, t_new, y_new):\n",
    "        \"\"\"Teaching new instances to the estimator selected bu the query_strategy\n",
    "        \n",
    "        If no `assignment_fc` is added, all selected samples are used\n",
    "        If assignment function is added, only those instances are used, where\n",
    "        $\\hat{T} = T$\n",
    "        \"\"\"\n",
    "        if self.assignment_fc is None:\n",
    "            self._add_queried_data_class(X_new, t_new, y_new)\n",
    "            self.fit()\n",
    "    \n",
    "    def fit(self):\n",
    "        self._update_estimator_values()\n",
    "        self.estimator.fit()\n",
    "        \n",
    "    def predict(self, X=None, **kwargs):\n",
    "        \"\"\"Method for predicting treatment effects within Active Learning\n",
    "        \n",
    "        Default is to predict on the unlabeled pool\"\"\"\n",
    "        if X is None:\n",
    "            raise Exception(\"You need to supply an unlabeled pool of instances (with shape (-1,{}))\".format(self.X_training.shape[1]))\n",
    "        self.preds = self.estimator.predict(X, **kwargs)\n",
    "        return self.preds\n",
    "    \n",
    "    def score(self, preds=None, y_true=None, t_true=None, metric = \"Qini\"):\n",
    "        \"\"\"\n",
    "        Scoring the predictions - either ITE or observed outcomes are needed.\n",
    "        \n",
    "        If observed outcomes are provided, the accompanying treatments are also needed.\n",
    "        \"\"\"\n",
    "        if metric == \"Qini\":\n",
    "            upev = UpliftEval(t_true, y_true, self.preds[0] if preds is None else preds)\n",
    "            self.scores = upev\n",
    "        return self.scores.q1_aqini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "class ITEEstimator(BaseEstimator):\n",
    "    \"\"\" Class for building a naive estimator for ITE estimation\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 model: estimator_type = None,\n",
    "                 two_model: bool = False,\n",
    "                 **kwargs\n",
    "                ) -> None:\n",
    "        self.model = model\n",
    "        self.two_model = two_model\n",
    "\n",
    "    def fit(self,X_training: np.ndarray = None,\n",
    "                 t_training: np.ndarray = None,\n",
    "                 y_training: np.ndarray = None,\n",
    "                 X_test: np.ndarray = None):\n",
    "        if X_training is not None:\n",
    "            self.X_training = X_training\n",
    "            self.y_training = y_training\n",
    "            self.t_training = t_training\n",
    "            self.X_test = X_test\n",
    "        self.N_training = self.X_training.shape[0]\n",
    "        # if \"N_training\" not in self.__dict__:\n",
    "        #     self.N_training = self.X_training.shape[0]\n",
    "        if self.two_model:\n",
    "            self.m1 = deepcopy(self.model)\n",
    "            control_ix = np.where(self.t_training == 0)[0]\n",
    "            self.model.fit(self.X_training[control_ix,:],\n",
    "                           self.y_training[control_ix])\n",
    "            self.m1.fit(self.X_training[-control_ix,:],\n",
    "                        self.y_training[-control_ix])\n",
    "        else:\n",
    "            self.model.fit(np.hstack((self.X_training,\n",
    "                                      self.t_training.reshape((self.N_training, -1)))),\n",
    "                           self.y_training)\n",
    "            \n",
    "    def _predict_without_proba(self, model, X, **kwargs):\n",
    "        return model.predict(X,\n",
    "            return_mean = kwargs[\"return_mean\"] if \"return_mean\" in kwargs else True)\n",
    "            \n",
    "    def predict(self, X=None, **kwargs):\n",
    "        if X is None:\n",
    "            X = self.X_test\n",
    "        N_test = X.shape[0]\n",
    "        try:\n",
    "            if self.two_model:\n",
    "                self.y1_preds = self.m1.predict_proba(X)[:,1]\n",
    "                self.y0_preds = self.model.predict_proba(X)[:,1]\n",
    "            else:\n",
    "                \n",
    "                self.y1_preds = self.model.predict_proba(\n",
    "                                    np.hstack((X,\n",
    "                                    np.ones(N_test).reshape(-1,1))))[:,1]\n",
    "                self.y0_preds = self.model.predict_proba(\n",
    "                    np.hstack((X,\n",
    "                               np.zeros(N_test).reshape(-1,1))))[:,1]\n",
    "        except AttributeError:\n",
    "            if type(self.model) is XBART:\n",
    "                if self.two_model:\n",
    "                    self.y1_preds = self._predict_without_proba(self.m1, X, **kwargs)\n",
    "                    self.y0_preds = self._predict_without_proba(self.model, X, **kwargs)\n",
    "                else: \n",
    "                    self.y1_preds = self._predict_without_proba(self.model,\n",
    "                             np.hstack((X,\n",
    "                             np.ones(N_test).reshape(-1,1))), **kwargs)\n",
    "                    self.y0_preds = self._predict_without_proba(self.model,\n",
    "                        np.hstack((X,\n",
    "                                   np.zeros(N_test).reshape(-1,1))), **kwargs)\n",
    "        return self.y1_preds - self.y0_preds, self.y1_preds, self.y0_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.normal(size = 1000).reshape((500,2))\n",
    "t = np.random.binomial(n = 1, p = 0.5, size = 500)\n",
    "y = np.random.binomial(n = 1, p = 1/(1+np.exp(X[:, 1]*2 + t*3)))\n",
    "X_test = np.random.normal(size = 200).reshape((100,2))\n",
    "t_test = np.random.binomial(n = 1, p = 0.5, size = 100)\n",
    "y_test = np.random.binomial(n = 1, p = 1/(1+np.exp(X_test[:, 1]*2 + t_test*3)))\n",
    "a = ITEEstimator(LogisticRegression(solver=\"lbfgs\"), two_model = True)\n",
    "a.fit(X, t, y)\n",
    "assert type(a.model) == LogisticRegression  # test assigning a model\n",
    "assert a.X_training.shape  == (500,2)       # test data passing for class\n",
    "assert a.model.intercept_ is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = ITEEstimator(RandomForestClassifier(), X, t, y, X_test, two_model = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "asl = ASLearner(estimator = ITEEstimator(model = RandomForestClassifier()), \n",
    "         query_strategy=random_batch_sampling,\n",
    "         X_training=X,\n",
    "                t_training=t,\n",
    "                y_training=y,\n",
    "                X_test=X_test)\n",
    "asl.fit()\n",
    "ite_pred, y1_pred, y0_pred = asl.predict(asl.X_test)\n",
    "X_sel, query_sel = asl.query(asl.X_test, n2=10)\n",
    "assert ite_pred.shape[0] == 100\n",
    "assert X_sel.shape       == (10,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xbart import XBART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 100\n",
    "p       = 5\n",
    "n_pool  = 1000\n",
    "n_test  = 1000\n",
    "n2      = 20\n",
    "X_train = np.random.normal(size = n_train*p).reshape((n_train,p))\n",
    "t_train = np.random.binomial(n = 1, p = 0.5, size = n_train)\n",
    "y_train = np.random.binomial(n = 1, p = 1/(1+np.exp(-1*(X_train[:, 1]*2 + t_train*3))))\n",
    "\n",
    "X_pool = np.random.normal(size = n_pool*p).reshape((n_pool,p))\n",
    "t_pool = np.random.binomial(n = 1, p = 0.5, size = n_pool)\n",
    "y_pool = np.random.binomial(n = 1, p = 1/(1+np.exp(-1*(X_pool[:, 1]*2 + t_pool*3))))\n",
    "\n",
    "X_test = np.random.normal(size = n_test*p).reshape((n_test,p))\n",
    "t_test = np.random.binomial(n = 1, p = 0.5, size = n_test)\n",
    "y_test = np.random.binomial(n = 1, p = 1/(1+np.exp(-1*(X_test[:, 1]*2 + t_test*3))))\n",
    "# asl = ASLearner(estimator = ITEEstimator(model = XBART(),two_model=False), \n",
    "#          query_strategy=uncertainty_batch_sampling,\n",
    "#          X_training = X_train,\n",
    "#          t_training = t_train,\n",
    "#          y_training = y_train,\n",
    "#          X_pool     = X_pool,\n",
    "#          X_test     = X_test)\n",
    "# asl.fit()\n",
    "# p_ite, p_y1, p_y0 = asl.predict(asl.X_test, return_mean=False)\n",
    "# print(\"Qini before AL: {}\".format(asl.score(preds=np.mean(p_ite, axis=1),\n",
    "#                                             y_true=y_test, t_true=t_test)))\n",
    "# qini_vals = []\n",
    "# for _ in range(10):\n",
    "#     X_query, ix = asl.query(asl.X_pool, n2=n2)\n",
    "#     asl.teach(X_query, t_pool[ix], y_pool[ix])\n",
    "#     asl.X_pool = np.delete(asl.X_pool,ix, axis=0)\n",
    "#     t_pool     = np.delete(t_pool,ix, axis=0) \n",
    "#     y_pool     = np.delete(y_pool,ix, axis=0) \n",
    "#     p_ite, p_y1, p_y0 = asl.predict(asl.X_test, return_mean=False)\n",
    "#     qini_vals.append(asl.score(preds=np.mean(p_ite, axis=1), y_true=y_test, t_true=t_test))\n",
    "#     print(\"Qini after round {} of AL: {}\".format(_,qini_vals[_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qini before AL: 0.12159330581340701\n",
      "[[0.23546293 0.39482968 0.27401979 ... 0.2147234  0.25486699 0.31302206]\n",
      " [0.21441689 0.55059787 0.37328519 ... 0.29221303 0.25333555 0.31302206]\n",
      " [0.45795969 0.55059787 0.51942893 ... 0.2147234  0.14830384 0.31302206]\n",
      " ...\n",
      " [0.33548554 0.39482968 0.37328519 ... 0.29221303 0.25333555 0.31302206]\n",
      " [0.13726011 0.53997632 0.32057036 ... 0.2147234  0.1467724  0.31302206]\n",
      " [0.45795969 0.55059787 0.50807244 ... 0.2147234  0.14830384 0.31302206]]\n",
      "Qini after round 0 of AL: 0.11758657131105969\n",
      "[[0.50175033 0.71411774 0.5328794  ... 0.53980752 1.08152186 0.62098956]\n",
      " [0.13575574 0.2353595  0.59732504 ... 0.49935112 0.61359864 0.84228754]\n",
      " [0.65366367 0.73234102 0.48199339 ... 0.58095258 1.22200858 0.96881801]\n",
      " ...\n",
      " [0.46400738 0.71411774 0.68356255 ... 0.53980752 0.89576561 0.94400747]\n",
      " [0.25275175 0.25358278 0.59732504 ... 0.43847564 0.74026323 0.83108558]\n",
      " [0.65366367 0.76697167 0.45409647 ... 0.58095258 0.82946696 0.96881801]]\n",
      "Qini after round 1 of AL: 0.13511391922104948\n",
      "[[0.29374234 0.50388454 0.57467658 ... 0.28275939 0.46924743 0.42094529]\n",
      " [0.06585059 0.19837217 0.49738655 ... 0.37501251 0.32172614 0.19605816]\n",
      " [0.46105465 0.50388454 0.833834   ... 0.37501251 0.46924743 0.36994738]\n",
      " ...\n",
      " [0.46137767 0.50388454 0.47043508 ... 0.37501251 0.46924743 0.19605816]\n",
      " [0.17684269 0.19837217 0.33753127 ... 0.16915066 0.32172614 0.1557617 ]\n",
      " [0.57236977 0.50388454 0.81500745 ... 0.37501251 0.46924743 0.21210021]]\n",
      "Qini after round 2 of AL: 0.1336029554481505\n",
      "[[ 0.54833243  0.18237165 -0.05301591 ... -0.00095852  0.12633211\n",
      "   0.10409667]\n",
      " [-0.02080779  0.30288477  0.19096157 ... -0.22466443 -0.16192106\n",
      "  -0.0442345 ]\n",
      " [ 0.79857706  0.18237165 -0.01150869 ... -0.06968959  0.30750155\n",
      "   0.28625048]\n",
      " ...\n",
      " [ 0.44115912  0.18237165  0.09184928 ... -0.08355824  0.12633211\n",
      "   0.18756478]\n",
      " [-0.02080779  0.24298345  0.05687889 ... -0.16603407 -0.16192106\n",
      "  -0.0442345 ]\n",
      " [ 0.74855193  0.18237165 -0.01150869 ... -0.06968959  0.30750155\n",
      "   0.28625048]]\n",
      "Qini after round 3 of AL: 0.1359585003677959\n",
      "[[ 1.17918465  0.38458934  0.48637962 ...  0.28010694  0.58242571\n",
      "   0.57211135]\n",
      " [ 0.52653443  0.09193363  0.19155631 ...  0.28708181  0.20199915\n",
      "   0.448365  ]\n",
      " [ 1.33455142  0.26838253  1.01114432 ...  0.28010694  0.58242571\n",
      "   0.68287058]\n",
      " ...\n",
      " [ 1.06126867  0.38458934  0.48637962 ...  0.49721953  0.58242571\n",
      "   0.51480436]\n",
      " [ 0.35196924 -0.13883451  0.22735316 ...  0.26209184  0.15316593\n",
      "   0.31814497]\n",
      " [ 1.15899573  0.21776945  1.01114432 ...  0.4628119   0.58242571\n",
      "   0.57211135]]\n",
      "Qini after round 4 of AL: 0.14673607888397844\n",
      "[[ 0.53401733  0.36512691  0.28652748 ...  0.32216578  0.48858747\n",
      "   0.59531255]\n",
      " [ 0.45763156  0.31764748  0.3576161  ...  0.36353905  0.40819155\n",
      "   0.32159722]\n",
      " [ 0.53401733  0.38073618  0.3576161  ...  0.52090975  0.40819155\n",
      "   0.46716308]\n",
      " ...\n",
      " [ 0.44099353  0.32460793  0.28652748 ...  0.39723063  0.48858747\n",
      "   0.59531255]\n",
      " [-0.00824891 -0.0682138   0.06482392 ...  0.36353905  0.40819155\n",
      "   0.08441878]\n",
      " [ 0.47097814  0.38073618  0.3576161  ...  0.52090975  0.40819155\n",
      "   0.53039422]]\n",
      "Qini after round 5 of AL: 0.13549558479221183\n",
      "[[ 0.38724659  0.58060559  0.44979764 ...  0.0964407   0.60527181\n",
      "   0.67900843]\n",
      " [ 0.27909677  0.54861507  0.41723466 ...  0.0964407   0.68805865\n",
      "   0.56894545]\n",
      " [ 0.47988047  0.58471249  0.48502888 ...  0.21626244  0.58099561\n",
      "   0.66748327]\n",
      " ...\n",
      " [ 0.60811284  0.58060559  0.3663766  ...  0.0964407   0.68805865\n",
      "   0.67900843]\n",
      " [-0.03613211  0.138411    0.06346389 ... -0.19784262  0.68805865\n",
      "   0.55742028]\n",
      " [ 0.65688506  0.58957199  0.48502888 ...  0.0964407   0.60527181\n",
      "   0.66955367]]\n",
      "Qini after round 6 of AL: 0.13769522095617723\n",
      "[[ 0.45262805  0.22426731  0.5557422  ...  0.35898318  0.39756808\n",
      "   0.07931748]\n",
      " [ 0.24215179  0.31659863  0.34170167 ...  0.24269231  0.33326645\n",
      "  -0.03324318]\n",
      " [ 0.45262805  0.22426731  0.5557422  ...  0.36312063  0.39756808\n",
      "   0.2197736 ]\n",
      " ...\n",
      " [ 0.64831958  0.22426731  0.5557422  ...  0.35898318  0.43201124\n",
      "   0.07931748]\n",
      " [-0.09567451  0.06199495 -0.03709721 ...  0.24269231 -0.00242381\n",
      "  -0.03324318]\n",
      " [ 0.5559757   0.16516675  0.5557422  ...  0.36312063  0.39756808\n",
      "   0.2197736 ]]\n",
      "Qini after round 7 of AL: 0.13742471218365307\n",
      "[[ 0.63715436  0.37459348  0.42768963 ... -0.13999704  0.11277759\n",
      "   0.42526442]\n",
      " [ 0.37796158  0.39370453  0.37486281 ... -0.03304877  0.11277759\n",
      "   0.28822893]\n",
      " [ 0.70191856  0.15947877  0.41861635 ...  0.03847337  0.11277759\n",
      "   0.12403135]\n",
      " ...\n",
      " [ 0.72314004  0.33822157  0.42768963 ... -0.10951213  0.11277759\n",
      "   0.424319  ]\n",
      " [ 0.08633468  0.06168933 -0.02776001 ... -0.03304877 -0.09409055\n",
      "   0.16927907]\n",
      " [ 0.70191856  0.15947877  0.41861635 ...  0.03847337  0.11277759\n",
      "   0.12403135]]\n",
      "Qini after round 8 of AL: 0.1381473356644255\n",
      "[[ 0.56429751  0.59383764  0.45794305 ...  0.69645249  0.82976457\n",
      "   0.32066165]\n",
      " [ 0.22234009  0.18174227  0.22789238 ...  0.69645249  0.82976457\n",
      "   0.37603934]\n",
      " [ 0.53332476  0.61076107  0.45794305 ...  0.69645249  0.86514868\n",
      "   0.48188453]\n",
      " ...\n",
      " [ 0.22234009  0.35155202  0.22789238 ...  0.69645249  0.86514868\n",
      "   0.32066165]\n",
      " [ 0.6304912   0.5965742   0.45794305 ...  0.69645249  0.82976457\n",
      "   0.32066165]\n",
      " [ 0.12996772 -0.03125962  0.22789238 ...  0.49158885  0.59108604\n",
      "   0.05679004]]\n",
      "Qini after round 9 of AL: 0.1367497715739552\n"
     ]
    }
   ],
   "source": [
    "asl = ASLearner(estimator = ITEEstimator(model = XBART(),two_model=False), \n",
    "         query_strategy=uncertainty_batch_sampling,\n",
    "         X_training = X_train,\n",
    "         t_training = t_train,\n",
    "         y_training = y_train,\n",
    "         X_pool     = X_pool,\n",
    "         X_test     = X_test)\n",
    "asl.fit()\n",
    "p_ite, p_y1, p_y0 = asl.predict(asl.X_test, return_mean=False)\n",
    "print(\"Qini before AL: {}\".format(asl.score(preds=np.mean(p_ite, axis=1),\n",
    "                                            y_true=y_test, t_true=t_test)))\n",
    "qini_vals = []\n",
    "for _ in range(10):\n",
    "    X_query, ix = asl.query(asl.X_pool, n2=n2, return_mean=False)\n",
    "    asl.teach(X_query, t_pool[ix], y_pool[ix])\n",
    "    asl.X_pool = np.delete(asl.X_pool,ix, axis=0)\n",
    "    t_pool     = np.delete(t_pool,ix, axis=0) \n",
    "    y_pool     = np.delete(y_pool,ix, axis=0) \n",
    "    p_ite, p_y1, p_y0 = asl.predict(asl.X_test, return_mean=False)\n",
    "    qini_vals.append(asl.score(preds=np.mean(p_ite, axis=1), y_true=y_test, t_true=t_test))\n",
    "    print(\"Qini after round {} of AL: {}\".format(_,qini_vals[_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 40)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_ite.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
