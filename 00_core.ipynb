{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASBE - Automatic Stopping for Batch Experiments\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cells will be exported to asbe.core,\n",
      "unless a different module is specified after an export flag: `%nbdev_export special.module`\n"
     ]
    }
   ],
   "source": [
    "%nbdev_default_export core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "from modAL.models.base import BaseLearner\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, RegressorMixin\n",
    "from typing import Union, Optional\n",
    "from copy import deepcopy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-385-4e8cd181c0c1>, line 43)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-385-4e8cd181c0c1>\"\u001b[0;36m, line \u001b[0;32m43\u001b[0m\n\u001b[0;31m    self.estimator.fit(np.hstack(X, X_query)))\u001b[0m\n\u001b[0m                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%nbdev_export\n",
    "def random_batch_sampling(classifier, X_pool, n2):\n",
    "    \"Randomly sample a batch from a pool of unlabaled samples\"\n",
    "    n_samples = len(X_pool)\n",
    "    query_idx = np.random.choice(range(n_samples), size=n2)\n",
    "    return X_pool[query_idx], query_idx\n",
    "\n",
    "estimator_type = ClassifierMixin\n",
    "class ASLearner(BaseLearner):\n",
    "    \"\"\"A(ctively)S(topping)Learner class for automatic stopping in batch-mode AL\"\"\"\n",
    "    def __init__(self,\n",
    "                 estimator: estimator_type=None, \n",
    "                 query_strategy=None,\n",
    "                 assignment_fc=None,\n",
    "                 X_training: np.ndarray = None,\n",
    "                 t_training: np.ndarray = None,\n",
    "                 y_training: np.ndarray = None,\n",
    "                 X_pool: np.ndarray = None\n",
    "                ) -> None:\n",
    "        self.estimator = estimator#,\n",
    "                                  #t_training = t_training,\n",
    "                                  #y_training = y_training,\n",
    "                                  #X_test     = X_pool)\n",
    "        self.query_strategy = query_strategy\n",
    "        self.assignment_fc = assignment_fc\n",
    "        self.X_training = X_training\n",
    "        self.y_training = y_training\n",
    "        self.t_training = t_training\n",
    "        self.X_pool     = X_pool\n",
    "        self.estimator.__dict__.update(X_training = X_training,\n",
    "                                       y_training  = y_training,\n",
    "                                       t_training  = t_training,\n",
    "                                       X_test      = X_pool)\n",
    "\n",
    "        \n",
    "    def teach(self, X, X_query, t_test, y_test):\n",
    "        \"\"\"Teaching new instances to the estimator selected bu the query_strategy\n",
    "        \n",
    "        If no `assignment_fc` is added, all selected samples are used\n",
    "        If assignment function is added, only those instances are used, where\n",
    "        $\\hat{T} = T$\n",
    "        \"\"\"\n",
    "        if assignment_fc is None:\n",
    "            self.estimator.fit()\n",
    "    \n",
    "    def fit(self):\n",
    "        self.estimator.fit()\n",
    "        \n",
    "    def predict(self, X=None):\n",
    "        if self.X_pool is not None:\n",
    "            X = self.X_pool\n",
    "        elif X is None:\n",
    "            raise Exception(\"You need to supply an unlabeled pool of instances (with shape (-1,{}))\".format(self.X_training.shape[1]))\n",
    "        return self.estimator.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "class ITEEstimator(BaseEstimator):\n",
    "    \"\"\" Class for building a naive estimator for ITE estimation\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 model: estimator_type = None,\n",
    "                 two_model: bool = False,\n",
    "                 **kwargs\n",
    "                ) -> None:\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self,X_training: np.ndarray = None,\n",
    "                 t_training: np.ndarray = None,\n",
    "                 y_training: np.ndarray = None,\n",
    "                 X_test: np.ndarray = None):\n",
    "        self.X_training = X_training\n",
    "        self.y_training = y_training\n",
    "        self.t_training = t_training\n",
    "        self.X_test = X_test\n",
    "        self.N_training = X_training.shape[0]\n",
    "        # if \"N_training\" not in self.__dict__:\n",
    "        #     self.N_training = self.X_training.shape[0]\n",
    "        if self.two_model:\n",
    "            self.m1 = deepcopy(self.model)\n",
    "            control_ix = np.where(self.t_training == 0)[0]\n",
    "            self.model.fit(self.X_training[control_ix,:],\n",
    "                           self.y_training[control_ix])\n",
    "            self.m1.fit(self.X_training[-control_ix,:],\n",
    "                        self.y_training[-control_ix])\n",
    "        else:\n",
    "            self.model.fit(np.hstack((self.X_training,\n",
    "                                      self.t_training.reshape((self.N_training, -1)))),\n",
    "                           self.y_training)\n",
    "            \n",
    "    def predict(self, X=None):\n",
    "        if X is None:\n",
    "            X = self.X_test\n",
    "        if self.two_model:\n",
    "            self.y1_preds = self.m1.predict_proba(X)[:,1]\n",
    "            self.y0_preds = self.model.predict_proba(X)[:,1]\n",
    "        else:\n",
    "            N_test = X.shape[0]\n",
    "            self.y1_preds = self.model.predict_proba(\n",
    "                                np.hstack((X,\n",
    "                                np.ones(N_test).reshape(-1,1))))[:,1]\n",
    "            self.y0_preds = self.model.predict_proba(\n",
    "                np.hstack((X,\n",
    "                           np.zeros(N_test).reshape(-1,1))))[:,1]\n",
    "        return self.y1_preds - self.y0_preds, self.y1_preds, self.y0_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ITEEstimator' object has no attribute 'two_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-391-2b82f7ebf0bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mt_test\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mITEEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"lbfgs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtwo_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mLogisticRegression\u001b[0m  \u001b[0;31m# test assigning a model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m  \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;31m# test data passing for class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-390-ceb4b40fbb8b>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_training, t_training, y_training, X_test)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# if \"N_training\" not in self.__dict__:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m#     self.N_training = self.X_training.shape[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtwo_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mcontrol_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_training\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ITEEstimator' object has no attribute 'two_model'"
     ]
    }
   ],
   "source": [
    "X = np.random.normal(size = 1000).reshape((500,2))\n",
    "t = np.random.binomial(n = 1, p = 0.5, size = 500)\n",
    "y = np.random.binomial(n = 1, p = 1/(1+np.exp(X[:, 1]*2 + t*3)))\n",
    "X_test = np.random.normal(size = 200).reshape((100,2))\n",
    "t_test = np.random.binomial(n = 1, p = 0.5, size = 100)\n",
    "y_test = np.random.binomial(n = 1, p = 1/(1+np.exp(X_test[:, 1]*2 + t_test*3)))\n",
    "a = ITEEstimator(LogisticRegression(solver=\"lbfgs\"), two_model = True)\n",
    "a.fit(X, t, y)\n",
    "assert type(a.model) == LogisticRegression  # test assigning a model\n",
    "assert a.X_training.shape  == (500,2)       # test data passing for class\n",
    "assert a.model.intercept_ is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = ITEEstimator(RandomForestClassifier(), X, t, y, X_test, two_model = False )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asl = ASLearner(estimator = ITEEstimator(model = RandomForestClassifier()), \n",
    "         query_strategy=random_batch_sampling,\n",
    "         X_training=X,t_training=t,y_training=y,X_pool=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asl.fit()\n",
    "ite_pred, y1_pred, y0_pred = asl.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel, query_sel = asl.query(asl.X_pool, n2=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_vhstack_dispatcher() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-374-7b6a61cf5183>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0masl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_sel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mque_sel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-367-f08d49f53ed4>\u001b[0m in \u001b[0;36mteach\u001b[0;34m(self, X, X_query)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mteach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: _vhstack_dispatcher() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "asl.teach(X_sel, que_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
