[
  {
    "objectID": "CONTRIBUTING.html",
    "href": "CONTRIBUTING.html",
    "title": "How to contribute",
    "section": "",
    "text": "Before anything else, please install the git hooks that run automatic scripts during each commit and merge to strip the notebooks of superfluous metadata (and avoid merge conflicts). After cloning the repository, run the following command inside it:\nnbdev_install_git_hooks\n\n\n\n\nEnsure the bug was not already reported by searching on GitHub under Issues.\nIf you’re unable to find an open issue addressing the problem, open a new one. Be sure to include a title and clear description, as much relevant information as possible, and a code sample or an executable test case demonstrating the expected behavior that is not occurring.\nBe sure to add the complete error messages.\n\n\n\n\nOpen a new GitHub pull request with the patch.\nEnsure that your PR includes a test that fails without your patch, and pass with it.\nEnsure the PR description clearly describes the problem and solution. Include the relevant issue number if applicable.\n\n\n\n\n\n\nKeep each PR focused. While it’s more convenient, do not combine several unrelated fixes together. Create as many branches as needing to keep each PR focused.\nDo not mix style changes/fixes with “functional” changes. It’s very difficult to review such PRs and it most likely get rejected.\nDo not add/remove vertical whitespace. Preserve the original style of the file you edit as much as you can.\nDo not turn an already submitted PR into your development playground. If after you submitted PR, you discovered that more work is needed - close the PR, do the required work and then submit a new PR. Otherwise each of your commits requires attention from maintainers of the project.\nIf, however, you submitted a PR and received a request for changes, you should proceed with commits inside that PR, so that the maintainer can see the incremental fixes and won’t need to review the whole PR again. In the exception case where you realize it’ll take many many commits to complete the requests, then it’s probably best to close the PR, do the work and then submit it again. Use common sense where you’d choose one way over another.\n\n\n\n\n\nDocs are automatically created from the notebooks in the nbs folder."
  },
  {
    "objectID": "CONTRIBUTING.html#how-to-get-started",
    "href": "CONTRIBUTING.html#how-to-get-started",
    "title": "How to contribute",
    "section": "",
    "text": "Before anything else, please install the git hooks that run automatic scripts during each commit and merge to strip the notebooks of superfluous metadata (and avoid merge conflicts). After cloning the repository, run the following command inside it:\nnbdev_install_git_hooks"
  },
  {
    "objectID": "CONTRIBUTING.html#did-you-find-a-bug",
    "href": "CONTRIBUTING.html#did-you-find-a-bug",
    "title": "How to contribute",
    "section": "",
    "text": "Ensure the bug was not already reported by searching on GitHub under Issues.\nIf you’re unable to find an open issue addressing the problem, open a new one. Be sure to include a title and clear description, as much relevant information as possible, and a code sample or an executable test case demonstrating the expected behavior that is not occurring.\nBe sure to add the complete error messages.\n\n\n\n\nOpen a new GitHub pull request with the patch.\nEnsure that your PR includes a test that fails without your patch, and pass with it.\nEnsure the PR description clearly describes the problem and solution. Include the relevant issue number if applicable."
  },
  {
    "objectID": "CONTRIBUTING.html#pr-submission-guidelines",
    "href": "CONTRIBUTING.html#pr-submission-guidelines",
    "title": "How to contribute",
    "section": "",
    "text": "Keep each PR focused. While it’s more convenient, do not combine several unrelated fixes together. Create as many branches as needing to keep each PR focused.\nDo not mix style changes/fixes with “functional” changes. It’s very difficult to review such PRs and it most likely get rejected.\nDo not add/remove vertical whitespace. Preserve the original style of the file you edit as much as you can.\nDo not turn an already submitted PR into your development playground. If after you submitted PR, you discovered that more work is needed - close the PR, do the required work and then submit a new PR. Otherwise each of your commits requires attention from maintainers of the project.\nIf, however, you submitted a PR and received a request for changes, you should proceed with commits inside that PR, so that the maintainer can see the incremental fixes and won’t need to review the whole PR again. In the exception case where you realize it’ll take many many commits to complete the requests, then it’s probably best to close the PR, do the work and then submit it again. Use common sense where you’d choose one way over another."
  },
  {
    "objectID": "CONTRIBUTING.html#do-you-want-to-contribute-to-the-documentation",
    "href": "CONTRIBUTING.html#do-you-want-to-contribute-to-the-documentation",
    "title": "How to contribute",
    "section": "",
    "text": "Docs are automatically created from the notebooks in the nbs folder."
  },
  {
    "objectID": "estimators.html",
    "href": "estimators.html",
    "title": "Treatment effect estimators",
    "section": "",
    "text": "Unknown section Attributes\nUnknown section Methods\n\nsource\n\nCausalForestEstimator\n\n CausalForestEstimator (model:Union[str,Callable]=None,\n                        dataset:Optional[dict]=None,\n                        two_model:Optional[bool]=None,\n                        ps_model:Optional[Callable]=None, **kwargs)\n\nBase class for estimating treatment effects\nThis is a base class, that is also usable on its own to estimate treatment effects. It works with most models that have a .fit() method, but subclassing is also made straightforward throught a metaclass.\n\nsource\n\n\nOPENBTITEEstimator\n\n OPENBTITEEstimator (model:Union[str,Callable]=None,\n                     dataset:Optional[dict]=None,\n                     two_model:Optional[bool]=None,\n                     ps_model:Optional[Callable]=None, **kwargs)\n\nModified ITE estimator for OPENBT\nThe predictions are transposed so the uncertainty sampler can calculate uncertianty easily\n\n#no-export \nclass CEVAEEstimator(BaseITEEstimator):\n    def fit(self, **kwargs):\n        if self.model is None:\n            self.model = CEVAE()\n        self.model.fit(kwargs[\"X_training\"], \n                       kwargs[\"t_training\"], \n                       y=kwargs[\"y_training\"])\n        \n    def predict(self, **kwargs):\n        return self.model.predict(X = kwargs[\"X\"])\n\n\nsource\n\n\nGPEstimator\n\n GPEstimator (model:Union[str,Callable]=None, dataset:Optional[dict]=None,\n              two_model:Optional[bool]=None,\n              ps_model:Optional[Callable]=None, **kwargs)\n\nBase class for estimating treatment effects\nThis is a base class, that is also usable on its own to estimate treatment effects. It works with most models that have a .fit() method, but subclassing is also made straightforward throught a metaclass.\n\n#no-export\nclass BLREstimator(BaseITEEstimator):\n    def fit(self, **kwargs):\n        with pm.Model() as self.model:\n            # https://juanitorduz.github.io/glm_pymc3/\n            family = pm.glm.families.Normal()\n            data = pm.Data(\"data\", kwargs[\"X_training\"])\n            labels = [\"x\"+str(i) for i in range(kwargs[\"X_training\"].shape[1])]\n            glm.GLM(y=kwargs[\"y_training\"], x = data, family=family, labels=labels)\n            self.trace = sample(3000, cores=2) \n            \n    def predict(self, **kwargs):\n        X0 = np.concatenate((kwargs[\"X\"],\n                             np.zeros(kwargs[\"X\"].shape[0]).reshape((-1,1))),axis=1)\n        X1 = np.concatenate((kwargs[\"X\"],\n                             np.ones(kwargs[\"X\"].shape[0]).reshape((-1,1))),axis=1)\n        pm.set_data({\"data\": X1}, model=self.model)\n        p1 = pm.sample_posterior_predictive(self.trace, model=self.model)\n        pm.set_data({\"data\": X0}, model=self.model)\n        p0 = pm.sample_posterior_predictive(self.trace, model=self.model)\n        ite = p1[\"y\"] - p0[\"y\"]\n        if 'return_mean' in kwargs:\n            out = ite.mean(axis=0)\n        else:\n            out = ite.T\n        return out\n\n\nsource\n\n\nSKLiftEstimator\n\n SKLiftEstimator (sk_model)\n\nBase class for estimating treatment effects\nThis is a base class, that is also usable on its own to estimate treatment effects. It works with most models that have a .fit() method, but subclassing is also made straightforward throught a metaclass.\n\n#no-export\nclass BARTEstimator(BaseITEEstimator):\n    def fit(self, **kwargs):\n        self.model_bart = pm.Model()\n        X = np.concatenate((kwargs[\"X_training\"], kwargs[\"t_training\"].reshape((-1,1))),axis=1)            \n        with self.model_bart:\n            x_obs = pm.MutableData(\"X\", X)\n            self.model_bart.named_vars.pop(\"X\")\n            x_obs = pm.MutableData(\"X\", X)\n            μ = pmb.BART(\"μ\", X=x_obs, Y=kwargs[\"y_training\"], m=100)\n            y_pred = pm.Normal(\"y_pred\", mu=μ, observed=kwargs[\"y_training\"],\n                               shape=μ.shape)\n            self.trace = pm.sample(random_seed=1005)\n            \n    def predict(self, **kwargs):\n        X0 = np.concatenate((kwargs[\"X\"],\n                             np.zeros(kwargs[\"X\"].shape[0]).reshape((-1,1))),axis=1)\n        X1 = np.concatenate((kwargs[\"X\"],\n                             np.ones(kwargs[\"X\"].shape[0]).reshape((-1,1))),axis=1)\n        with self.model_bart:\n            pm.set_data({\"X\": X1})\n            p1 = pm.sample_posterior_predictive(self.trace)\n            pm.set_data({\"X\": X0})\n            p0 = pm.sample_posterior_predictive(self.trace)\n            ite = p1[\"posterior_predictive\"][\"y_pred\"] - p0[\"posterior_predictive\"][\"y_pred\"]\n            ite = ite.mean(axis=0).to_numpy() #across chains\n            if \"return_mean\" in kwargs:\n                if kwargs[\"return_mean\"]:\n                    return ite.mean(axis=0)\n            else:\n                return ite.T"
  },
  {
    "objectID": "offline_data.html",
    "href": "offline_data.html",
    "title": "How to deal with online data",
    "section": "",
    "text": "from asbe.base import *\nfrom asbe.models import *\nfrom asbe.estimators import *\nfrom asbe.helper import *\nfrom dataclasses import dataclass, field\nimport numpy as np\nfrom collections.abc import Callable\nfrom typing import Union\nfrom sklearn.linear_model import LinearRegression\n\n\n# Data generating process\n\n\ndg = BaseDataGenerator(ds = {\"X_pool\":np.array([[1,2,3,4,5,6],[7,8,9,0,1,2]]),\n                         \"t_pool\":np.array( [1,0]),\n                         \"y1_pool\":np.array( [2, 10]),\n                         \"y0_pool\":np.array( [1, 7])})\n\n\nIHDP = BaseDataGenerator(ds = get_ihdp_dict(1))\n\ntest_data = IHDP.get_data()\nassert len(test_data) == 3\nassert type(test_data[0]) is np.ndarray\nassert test_data[1].shape == (1,)\n\n\ndef dgp_x(no_query=1):\n    X1_10 = np.random.normal(size=(no_query,10))\n    X10_20 = np.random.binomial(1, .5, size=(no_query,10))\n    X = np.concatenate((X1_10, X10_20), axis=1)\n    return X\n\ndef dgp_t(X):\n    return np.random.binomial(1, 0.5, size=(X.shape[0]))\n\ndef dgp_y(X,t):\n    y0 = 2.455 - (.4*X[:, 1] + .154*X[:, 2] - .152*X[:, 11] - .126*X[:, 12])\n    gx = .254*X[:,2]**2 - .152*X[:, 11] - .4*X[:,11]**2 - .126*X[:, 12]\n    tau = (.4*X[:, 1] + .154*X[:, 2] - .152*X[:, 11] - .126*X[:, 12]) - np.where(gx&gt;0, 1, 0)\n    y1 = y0 + tau\n    return np.where(t==1, y1, y0)\n\n\nl = BaseDataGenerator(ds= None,no_training=5, dgp_x = dgp_x, dgp_t = dgp_t, dgp_y = dgp_y)\n\n\nassert l.get_data(no_query=10)[0].shape[0] == 10\n\n\nl = BaseDataGenerator(ds = None,\n                      no_training=5,\n                      dgp_x = dgp_x,\n                      dgp_t = dgp_t, \n                      dgp_y = dgp_y)\nasl = BaseActiveLearner(estimator = BaseITEEstimator(model = LinearRegression(),\n                                         two_model=False),\n                        acquisition_function=BaseAcquisitionFunction(),\n                        assignment_function=BaseAssignmentFunction(),\n                        stopping_function = None,\n                        dataset=l,\n                        offline=False, \n                        al_steps=5)\n_ = asl.dataset.get_data(no_query=100, as_test=True)\nasl.simulate(metric=\"Qini\")\n\nAttributeError: 'dict' object has no attribute 'get_X'"
  },
  {
    "objectID": "base.html",
    "href": "base.html",
    "title": "Basic functionalities",
    "section": "",
    "text": "source\n\nFitTask\n\n FitTask (name, bases, clsdict)\n\nMeta class to make preprocessing of data before fitting different models\nThis meta class is needed so new models can be incorporated easily by only having a .fit() method. It will call a prepare_data function, which can also be modified .\n/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Attributes\n  else: warn(msg)\n/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Methods\n  else: warn(msg)\n\nsource\n\n\nBaseITEEstimator\n\n BaseITEEstimator (model:Union[str,Callable]=None,\n                   dataset:Optional[dict]=None,\n                   two_model:Optional[bool]=None,\n                   ps_model:Optional[Callable]=None, **kwargs)\n\nBase class for estimating treatment effects\nThis is a base class, that is also usable on its own to estimate treatment effects. It works with most models that have a .fit() method, but subclassing is also made straightforward throught a metaclass.\n\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nimport sklearn\nbite = BaseITEEstimator(model = LinearRegression(),\n                        two_model = True,\n                        ps_model=None)\nX = np.random.normal(size=(10000,4))\nt = np.random.binomial(1, 0.5, size=(10000,))\ny0 = X[:,1] * 3\nite = X[:,3] * (-2)\ny1 = y0 + ite\ny = np.where(t == 1, y1, y0)\nbite.fit(X_training = X,\n         t_training = t,\n         y_training = y)\npreds = bite.predict(X)\n\ntest_eq(np.round(bite.model.coef_[1]), 3)\ntest_eq(bite.model.coef_.shape[0], 4)\ntest_eq(np.round(np.mean(preds)), 0)\ntest_eq(type(bite.model), sklearn.linear_model._base.LinearRegression)\ntest_eq(bite.ps_model, None)\nbite.ps_model = LogisticRegression()\ntest_eq(type(bite.ps_model), sklearn.linear_model._logistic.LogisticRegression)\nbite.ps_model = None\nbite.two_model = False\nbite.fit(X_training = X,\n        t_training = t,\n        y_training = y)\ntest_eq(bite.model.coef_.shape[0], 5)\n\n/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Attributes\n  else: warn(msg)\n/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Methods\n  else: warn(msg)\n\nsource\n\n\nBaseActiveLearner\n\n BaseActiveLearner (estimator:sklearn.base.BaseEstimator,\n                    acquisition_function:Callable,\n                    assignment_function:Union[Callable,list,NoneType],\n                    stopping_function:Union[Callable,list,NoneType],\n                    dataset:dict, al_steps:int=1, offline=True, **kwargs)\n\nBasic of Active Learners later used, with the capability for treatment effects\nInspired by modAL’s BaseLearner, however modified for ITE estimation. Dataset is provided by a dictionary for easier usage and less clutter, but alternatively a BaseDataGenerator can also be supplied.\n\nsource\n\n\nBaseAcquisitionFunction\n\n BaseAcquisitionFunction (no_query:int=1, method:str='top',\n                          name:str='base')\n\nBase class for acquisition functions\nBased on Eq. 3 in paper: - calculate_metrics is used to get infromativeness/representativeness - calculate_metrics returns a weighted average between the two - select_data does the normalization and selecting top m/Bernoulli draws\n/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Arguments\n  else: warn(msg)\n\nsource\n\n\nBaseAssignmentFunction\n\n BaseAssignmentFunction (base_selection=0)\n\nBase class for assignment functions\n\nsource\n\n\nBaseStoppingRule\n\n BaseStoppingRule (budget=None)\n\nBase class for providing a stopping rule for the active learner\n\nsource\n\n\nBaseDataGenerator\n\n BaseDataGenerator (ds:Union[dict,Callable],\n                    dgp_x:Optional[Callable]=None,\n                    dgp_t:Optional[Callable]=None,\n                    dgp_y:Optional[Callable]=None, no_training:int=10)\n\nClass to generate online data for active learing purposes"
  },
  {
    "objectID": "models.html",
    "href": "models.html",
    "title": "Acquisition and assignment functions",
    "section": "",
    "text": "from nbdev import *\n\n\nfrom sklearn.linear_model import LogisticRegression, SGDRegressor\nfrom sklearn.ensemble import RandomForestClassifier\nimport matplotlib.pyplot as plt\n\n/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Attributes\n  else: warn(msg)\n/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Methods\n  else: warn(msg)\n\nsource\n\nEMCMAcquisitionFunction\n\n EMCMAcquisitionFunction (no_query=1, method='top', name='emcm',\n                          approx_model=SGDRegressor(), B=100, K=5,\n                          threshold=0, k_means=False, k_mean_clusters=1)\n\nBase class for acquisition functions\nBased on Eq. 3 in paper: - calculate_metrics is used to get infromativeness/representativeness - calculate_metrics returns a weighted average between the two - select_data does the normalization and selecting top m/Bernoulli draws\n\nsource\n\n\nTypeSAcquistionFunction\n\n TypeSAcquistionFunction (no_query:int=1, method:str='top',\n                          name:str='base')\n\nBase class for acquisition functions\nBased on Eq. 3 in paper: - calculate_metrics is used to get infromativeness/representativeness - calculate_metrics returns a weighted average between the two - select_data does the normalization and selecting top m/Bernoulli draws\n\nsource\n\n\nUncertaintyAcquisitionFunction\n\n UncertaintyAcquisitionFunction (no_query:int=1, method:str='top',\n                                 name:str='base')\n\nBase class for acquisition functions\nBased on Eq. 3 in paper: - calculate_metrics is used to get infromativeness/representativeness - calculate_metrics returns a weighted average between the two - select_data does the normalization and selecting top m/Bernoulli draws\n\nsource\n\n\nRandomAcquisitionFunction\n\n RandomAcquisitionFunction (no_query:int=1, method:str='top',\n                            name:str='base')\n\nBase class for acquisition functions\nBased on Eq. 3 in paper: - calculate_metrics is used to get infromativeness/representativeness - calculate_metrics returns a weighted average between the two - select_data does the normalization and selecting top m/Bernoulli draws\n/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Arguments\n  else: warn(msg)\n\nsource\n\n\nPMajorityAssignmentFunction\n\n PMajorityAssignmentFunction (base_selection=0, p=0.5)\n\nBase class for assignment functions\n\nsource\n\n\nMajorityAssignmentFunction\n\n MajorityAssignmentFunction (base_selection=0)\n\nBase class for assignment functions\n\nsource\n\n\nUncertaintyAssignmentFunction\n\n UncertaintyAssignmentFunction (base_selection=0)\n\nBase class for assignment functions\n\nsource\n\n\nRandomAssignmentFunction\n\n RandomAssignmentFunction (base_selection=0, p=0.5)\n\nBase class for assignment functions\n\nX = np.random.normal(size = 1000).reshape((500,2))\nt = np.random.binomial(n = 1, p = 0.5, size = 500)\ny = np.random.binomial(n = 1, p = 1/(1+np.exp(X[:, 1]*2 + t*3)))\nX_test = np.random.normal(size = 200).reshape((100,2))\nt_test = np.random.binomial(n = 1, p = 0.5, size = 100)\ny_test = np.random.binomial(n = 1, p = 1/(1+np.exp(X_test[:, 1]*2 + t_test*3)))\na = BaseITEEstimator(LogisticRegression(solver=\"lbfgs\"), two_model = True, ps=LogisticRegression())\na.fit(X_training=X, t_training=t, y_training=y)\nassert type(a.model) == LogisticRegression  # test assigning a model\nassert a.model.intercept_ is not None\n\n\nds = {\"X_training\":X,\n     \"y_training\": y,\n     \"t_training\": t,\n     \"ite_training\": np.zeros_like(t),\n     \"X_pool\": deepcopy(X_test), \n     \"y_pool\": deepcopy(y_test),\n     \"t_pool\": deepcopy(t_test),\n     \"ite_pool\": deepcopy(t_test),\n     \"X_test\": X_test,\n     \"y_test\": y_test,\n      \"t_test\": t_test\n     }\n\n\nasl = BaseActiveLearner(estimator = BaseITEEstimator(model = LogisticRegression()), \n                        acquisition_function=BaseAcquisitionFunction(),\n                        assignment_function=RandomAssignmentFunction(),\n                        stopping_function = None,\n                        dataset=ds)\nasl.fit()\nite_pred = asl.predict(asl.dataset[\"X_test\"])\nX_sel, query_idx = asl.query(no_query=10)\nasl.teach(query_idx)\nassert ite_pred.shape[0] == 100\nassert X_sel.shape       == (10,2)"
  },
  {
    "objectID": "misc.html",
    "href": "misc.html",
    "title": "Misc functions",
    "section": "",
    "text": "Unknown section Arguments\n\nsource\n\nget_ihdp_dict\n\n get_ihdp_dict (i=1, test_size=0.9, seperate_pool_test=False,\n                pool_size=0.8, seed=None)\n\nMethod to query the IHDP data from the AMlab github repo"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Automatic Stopping for Batch-mode Experimentation",
    "section": "",
    "text": "Created with nbdev by Zoltan Puha"
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "Automatic Stopping for Batch-mode Experimentation",
    "section": "Install",
    "text": "Install\npython -m pip install  git+https://github.com/puhazoli/asbe"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "Automatic Stopping for Batch-mode Experimentation",
    "section": "How to use",
    "text": "How to use\nASBE builds on the functional views of modAL, where an AL algorithm can be run by putting together pieces. You need the following ingredients: - an ITE estimator (ITEEstimator()), - an acquisition function, - and an assignment function. - Additionaly, you can add a stopping criteria to your model. If all the above are defined, you can construct an ASLearner, which will help you in the active learning process.\n\nfrom asbe.base import *\nfrom asbe.models import *\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nimport numpy as np\n\n\nN = 1000\nX = np.random.normal(size = N*2).reshape((-1,2))\nt = np.random.binomial(n = 1, p = 0.5, size = N)\ny = np.random.binomial(n = 1, p = 1/(1+np.exp(X[:, 1]*2 + t*3)))\nite = 1/(1+np.exp(X[:, 1]*2 + t*3)) - 1/(1+np.exp(X[:, 1]*2))\na = BaseITEEstimator(LogisticRegression(solver=\"lbfgs\"))\na.fit(X_training=X, t_training=t, y_training=y)"
  },
  {
    "objectID": "index.html#learning-actively",
    "href": "index.html#learning-actively",
    "title": "Automatic Stopping for Batch-mode Experimentation",
    "section": "Learning actively",
    "text": "Learning actively\nSimilarly, you can create an BaseActiveLearner, for which you will initialize the dataset and set the preferred modeling options. Let’s see how it works: - we will use XBART to model the treatment effect with a one-model approach - we will use expected model change maximization - for that, we need an approximate model, we will use the SGDRegressor\nYou can call .fit() on the BaseActiveLearner, which will by default fit the training data supplied. To select new units from the pool, you just need to call the query() method, which will return the selected X and the query_ix of these units. BaseActiveLearner expects the n2 argument, which tells how many units are queried at once. For sequential AL, we can set this to 1. Additionally, some query strategies can require different treatment effect estimates - EMCM needs uncertainty around the ITE. We can explicitly tell the the BaseITEEstimator to return all the predicted treatment effects. Then, we can teach the newly acquired units to the learner, by calling the teach function. The score function provides an evaluation of the given learner.\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import SGDRegressor\nfrom copy import deepcopy\nimport pandas as pd\n\n\nX_train, X_test, t_train, t_test, y_train, y_test, ite_train, ite_test = train_test_split(\n    X, t, y, ite,  test_size=0.8, random_state=1005)\nds = {\"X_training\": X_train,\n     \"y_training\": y_train,\n     \"t_training\": t_train,\n     \"ite_training\": np.zeros_like(y_train),\n     \"X_pool\": deepcopy(X_test), \n     \"y_pool\": deepcopy(y_test),\n     \"t_pool\": deepcopy(t_test),\n     \"ite_pool\" : np.zeros_like(y_test),\n     \"X_test\": X_test,\n     \"y_test\": y_test,\n      \"t_test\": t_test,\n      \"ite_test\": ite_test\n     }\nasl = BaseActiveLearner(estimator = BaseITEEstimator(model = RandomForestClassifier(),\n                                         two_model=False),\n                        acquisition_function=BaseAcquisitionFunction(),\n                        assignment_function=BaseAssignmentFunction(),\n                        stopping_function = None,\n                        dataset=ds)\nasl.fit()\nX_new, query_idx = asl.query(no_query=10)\nasl.teach(query_idx)\npreds = asl.predict(asl.dataset[\"X_test\"])\nasl.score()\n\n0.34842037641629464\n\n\n\nasl = BaseActiveLearner(estimator = BaseITEEstimator(model = RandomForestClassifier(),\n                                         two_model=True),\n                        acquisition_function=[BaseAcquisitionFunction(),\n                                             BaseAcquisitionFunction(no_query=20)],\n                        assignment_function=BaseAssignmentFunction(),\n                        stopping_function = None,\n                        dataset=ds,\n                        al_steps = 3)\nresd = pd.DataFrame(asl.simulate(metric=\"decision\"))\n\n\nresd.plot()\n\n&lt;AxesSubplot:&gt;"
  },
  {
    "objectID": "replicate_sundin.html",
    "href": "replicate_sundin.html",
    "title": "Replication of Sundin et al, ICML 2019",
    "section": "",
    "text": "!pip install git@https://github.com/cavan33/openbt_py.git\n\n\nfrom asbe.base import *\nfrom asbe.models import *\nfrom asbe.estimators import *\nfrom econml.orf import DMLOrthoForest\nfrom econml.dml import CausalForestDML\nfrom openbt.openbt import OPENBT\nimport pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom copy import deepcopy\nimport econml\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import ConstantKernel, RBF\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nimport pickle\nimport scipy.linalg as la\nfrom scipy.stats import norm\nfrom xbart import XBART\nimport GPy\nimport pymc as pm\nimport pymc_bart as pmb\n\n\nclass BARTEstimator(BaseITEEstimator):\n    def fit(self, **kwargs):\n        self.model_bart = pm.Model()\n        X = np.concatenate((kwargs[\"X_training\"], kwargs[\"t_training\"].reshape((-1,1))),axis=1)            \n        with self.model_bart:\n            x_obs = pm.MutableData(\"X\", X)\n            self.model_bart.named_vars.pop(\"X\")\n            x_obs = pm.MutableData(\"X\", X)\n            μ = pmb.BART(\"μ\", X=x_obs, Y=kwargs[\"y_training\"], m=10)\n            y_pred = pm.Normal(\"y_pred\", mu=μ, observed=kwargs[\"y_training\"],\n                               shape=μ.shape)\n            self.trace = pm.sample(random_seed=1005)\n            \n    def predict(self, **kwargs):\n        X0 = np.concatenate((kwargs[\"X\"],\n                             np.zeros(kwargs[\"X\"].shape[0]).reshape((-1,1))),axis=1)\n        X1 = np.concatenate((kwargs[\"X\"],\n                             np.ones(kwargs[\"X\"].shape[0]).reshape((-1,1))),axis=1)\n        with self.model_bart:\n            pm.set_data({\"X\": X1})\n            p1 = pm.sample_posterior_predictive(self.trace)\n            pm.set_data({\"X\": X0})\n            p0 = pm.sample_posterior_predictive(self.trace)\n#             ite = p1[\"posterior_predictive\"][\"y_pred\"] - p0[\"posterior_predictive\"][\"y_pred\"]\n            p1_ypred = p1[\"posterior_predictive\"][\"y_pred\"].mean(axis=0)\n            p0_ypred = p0[\"posterior_predictive\"][\"y_pred\"].mean(axis=0)\n            ite = p1_ypred - p0_ypred\n            ite = ite.mean(axis=0).to_numpy() #across chains\n            if \"return_mean\" in kwargs:\n                if kwargs[\"return_mean\"]:\n                    out =  ite.mean(axis=0)\n            else:\n                out =  ite.T\n            if \"return_counterfactuals\" in kwargs:\n                if kwargs[\"return_counterfactuals\"]:\n                    out = ite.mean(axis=0),p1_ypred.mean().values,p1_ypred.std().values, p0_ypred.mean().values, p0_ypred.std().values\n        return out\n\n\ndef categorical2indicator(data, name, categorical_max=4):\n    '''\n    Transforms categorical variable with name 'name' form a data frame to indicator variables\n    \n    Taken from https://github.com/IirisSundin/active-learning-for-decision-making/blob/e0c83f58181f81da2f867da4c49f1333fa7d0ae6/src/util.py#L14\n    '''\n    values = data[name].values\n    values[values&gt;= categorical_max] = categorical_max\n    uni = np.unique(values)\n    for i, value in enumerate(uni):\n        data[name+'.'+str(i)] = np.array((values==value), dtype=int)\n    data.drop(name, axis=1)\n    return data\n\ndef preprocess(data, categorical_max=2):\n    '''\n    This function preprocesses the hill data \n    '''\n    #Normalization is enough here\n    data['bw'] = normalize(data['bw'])\n    data['nnhealth'] = normalize(data['nnhealth'])\n    data['preterm'] = normalize(data['preterm'])\n    #Taking logarithm does not harm here before normalizing, but might be unneccessary\n    data['b.head'] = normalize(np.log(data['b.head']))\n    data['momage'] = normalize(np.log(data['momage']))\n    \n    #Categorigal variables are made to indicators, could also be just normalized:\n    #Birth order is between 1\n    data = categorical2indicator(data, 'birth.o', categorical_max=categorical_max)\n    \n    #Everything else is binary, so processing doesn't really help, makes only understanding the results harder.\n    \n    #For some reason, indicator variable \"first\" is either 1 or 2, that is why we subtract 1 from it\n    data['first'] = data['first'] -1 \n    \n    return data\n\ndef normalize(data):\n    '''\n    Transforms the data to zero mean unit variance\n    '''\n    return (data- np.mean(data))/np.std(data)\n\ndef prepare_data(id_test, random_state, percent_for_train=0.1335):\n    inputs = pd.read_csv(\"/Users/zoltan/Desktop/ihdp_data/inputs.csv\")\n    #names = [\"treatment\", \"y_factual\", \"y_cfactual\", \"mu0\", \"mu1\"] + [f'x{x}' for x in range(25)])\n    inputs = preprocess(inputs, categorical_max=2)\n    N = inputs.shape[0]\n    N_train = int(np.ceil(N*percent_for_train))\n    D = inputs.columns.shape[0]\n    outcomes = pd.read_csv('/Users/zoltan/Desktop/ihdp_data/observed_outcomes.csv', sep=',')\n    potential_outcomes = pd.read_csv('/Users/zoltan/Desktop/ihdp_data/potential_outcomes.csv', sep=',')\n    potential_outcomes = potential_outcomes[['outcome_c0','outcome_c1']]\n    actions = inputs['treat']\n    pred_names = inputs.columns[1:D]\n    predictors = inputs[pred_names]\n    \n    outcomes = outcomes.values\n    potential_outcomes = potential_outcomes.values\n    actions = actions.values\n    predictors = predictors.values\n    \n    outcomes = np.zeros(actions.shape)\n    for i in range(actions.shape[0]):\n        outcomes[i] = potential_outcomes[i, actions[i]]\n    \n    np.random.seed(random_state)\n    ind = np.arange(N)\n    np.random.shuffle(ind)\n    outcomes = outcomes[ind]\n    potential_outcomes = potential_outcomes[ind,:]\n    actions = actions[ind]\n    predictors = predictors[ind,:]\n\n    \n    # Creating training data\n    X_test = np.copy(predictors[id_test,:])\n    y_test = np.copy(outcomes[id_test])\n    t_test = np.copy(actions[id_test])\n    ite_test = potential_outcomes[id_test, 1]  - potential_outcomes[id_test, 0]\n                     \n    #shuffle the rest again (not test sample)\n    np.random.seed(random_state)\n    \n    ind = np.arange(N-1)\n    np.random.shuffle(ind)\n    outcomes = outcomes[np.arange(N)!=id_test][ind]\n    potential_outcomes = potential_outcomes[np.arange(N)!=id_test][ind,:]\n    actions = actions[np.arange(N)!=id_test][ind]\n    predictors = predictors[np.arange(N)!=id_test,:][ind,:]  \n                     \n    X_train, y_train, t_train = predictors[:N_train,:], outcomes[:N_train], actions[:N_train]\n    y0_train, y1_train = potential_outcomes[:N_train, 0], potential_outcomes[:N_train, 1]\n    ite_train = y1_train - y0_train\n                     \n    X_pool, y_pool, t_pool = predictors[N_train:,:], outcomes[N_train:], actions[N_train:]\n    y0_pool, y1_pool = potential_outcomes[N_train:, 0], potential_outcomes[N_train:, 1]\n    ite_pool = y1_pool - y0_pool\n            \n#     for col in ['bw','nnhealth', 'preterm', 'b.head','momage']:\n#         scalers[col] = StandardScaler()\n#         X_train[col] = scalers[col].fit_transform(X_train[col].to_numpy().reshape(-1,1))\n#         X_pool[col] = scalers[col].transform(X_pool[col].to_numpy().reshape(-1,1))\n#         try:\n#             X_test[col] = scalers[col].transform(X_test[col].to_numpy().reshape(-1,1))\n#         except:\n#             X_test[col] = scalers[col].transform(X_test[col].reshape(-1,1))\n    #X_train, X_pool, y_train, y_pool = X[], X_pool, y_train, y_pool\n    ds = {\"X_training\": X_train,\n     \"y_training\": y_train,\n     \"t_training\": t_train,\n     \"ite_training\": ite_train,\n     \"X_pool\": X_pool, \n     \"y_pool\": y_pool,\n     \"t_pool\": t_pool,\n     \"y1_pool\": y1_pool,\n     \"y0_pool\": y0_pool,\n     \"ite_pool\": ite_pool,\n     \"X_test\": X_test.reshape((1,-1)),\n     \"y_test\": y_test,\n     \"t_test\": t_test,\n     \"ite_test\": ite_test.reshape((-1,1))\n     }\n    return ds\n\n\nclass GPyEstimator(BaseITEEstimator):\n    # https://github.com/IirisSundin/active-learning-for-decision-making/blob/master/src/gpmodel.py\n    def __init__(self,**kwds):\n        super().__init__(**kwds)\n        self.name = \"gpy\"\n        self.update = False\n    \n    def _create_model(self, x, y):\n        d = x.shape[1]\n        prior = GPy.core.parameterization.priors.Gamma(a=1.5,b=3.0)\n        kern = GPy.kern.RBF(input_dim=d, ARD=True)\n        kern.variance.set_prior(prior, warning=False)\n        kern.lengthscale.set_prior(prior, warning=False)\n        lik1 = GPy.likelihoods.Gaussian()\n        lik1.variance.set_prior(prior, warning=False)\n        lik_expert = GPy.likelihoods.Gaussian()\n        lik_expert.variance.set_prior(prior, warning=False)\n        lik = GPy.likelihoods.MixedNoise([lik1, lik_expert])\n        output_index = np.ones(x.shape[0])\n        model = GPy.core.GP(X =  x,\n                                 Y =  y.reshape(-1, 1), \n                                 kernel=kern,\n                                 likelihood=lik, \n                                 Y_metadata = {'output_index':output_index})\n        model.optimize()\n        return model\n        \n    def fit(self, **kwargs):\n        if self.update:\n            action = \"t\" if kwargs[\"t_training\"] == 1 else \"c\"\n            predictor = kwargs[\"X_training\"]\n            oracle_outcome = kwargs[\"y_training\"]\n            mcopy = {}\n            mcopy[\"c\"] = deepcopy(self.models[\"c\"])\n            mcopy[\"t\"] = deepcopy(self.models[\"t\"])\n            mcopy[action].Y_metadata['output_index'] = np.r_[mcopy[action].Y_metadata['output_index'], np.array([1])]\n            mcopy[action].set_XY(np.r_[mcopy[action].X, predictor], np.r_[mcopy[action].Y, oracle_outcome], )\n            mcopy[action].optimize()\n            self.updated_model = mcopy\n        else:\n            self.models = {}\n            Xt, yt = kwargs[\"X_training\"][(kwargs[\"t_training\"] == 1), :],\\\n                    kwargs[\"y_training\"][(kwargs[\"t_training\"] == 1)]\n            Xc, yc = kwargs[\"X_training\"][(kwargs[\"t_training\"] == 0), :],\\\n            kwargs[\"y_training\"][(kwargs[\"t_training\"] == 0)]\n            self.models[\"c\"] = self._create_model(Xc, yc)\n            self.models[\"t\"] = self._create_model(Xt, yt)\n        \n    def predict(self, X, **kwargs):\n        if len(X.shape) == 1:\n            X = X.reshape((1, -1))\n        p1 = self.models[\"t\"].posterior_samples_f(X, 100)\n        p0 = self.models[\"c\"].posterior_samples_f(X, 100)\n        ite = p1 - p0\n        ite = ite.squeeze(1)\n        if \"return_mean\" in kwargs:\n            if kwargs[\"return_mean\"]:\n                ite = self.models[\"t\"].predict_noiseless(X)[\n                    0] - self.models[\"c\"].predict_noiseless(X)[0]\n        if \"return_counterfactuals\" in kwargs:\n            if kwargs[\"return_counterfactuals\"]:\n                p1, p1s = self.models[\"t\"]._raw_predict(X)\n                p0, p0s = self.models[\"c\"]._raw_predict(X)\n                ite = (ite, p1, p0, p1s, p0s)\n        return ite\n\n\nclass ExpectedReliability(BaseAcquisitionFunction): #'decerr'\n        '''\n        Uses Gauss-Hermite quadrature to compute expected type S error rate\n        '''\n        def error_rate(self, preds):\n            mu_tau = np.mean(preds[0])\n            sd_tau = np.std(preds[0])\n            alpha = norm.cdf(-np.abs(mu_tau)/sd_tau)\n            return alpha\n        \n        def calculate_metrics(self, model, dataset):\n            utilities = np.zeros(dataset[\"X_pool\"].shape[0])\n            reload = False\n            for n in range(dataset[\"X_pool\"].shape[0]):\n                x_star = dataset[\"X_pool\"][n,:].reshape(1,-1)\n                a_star = 1 - dataset[\"t_pool\"][n] # counterfactual action\n                decerr = 0.0\n                points, weights = np.polynomial.hermite.hermgauss(16) \n                for ii, yy in enumerate(points):\n                    preds_star = model.predict(X=x_star, return_counterfactuals=True)\n                    if a_star == 1:\n                        mu_star, S_star = preds_star[1], preds_star[3]\n                    else:\n                        mu_star, S_star = preds_star[2], preds_star[4]\n                    y_star = np.sqrt(2)*np.sqrt(S_star)*yy + mu_star #for substitution\n                    new_data = {\"X_training\": np.concatenate((dataset[\"X_training\"], x_star)),\n                               \"y_training\":  np.concatenate((dataset[\"y_training\"], \n                                                              y_star.reshape((1,)))),\n                                \"t_training\": np.concatenate((dataset[\"t_training\"], \n                                                              a_star.reshape((1,))))\n                               }\n                    if model.name == \"gpy\":\n                        model.update = True\n                        model.fit(X_training=x_star,\n                                        y_training=y_star,\n                                        t_training=a_star.reshape((1,)))\n                        gpy_new = GPyEstimator()\n                        gpy_new.models = model.updated_model\n                        preds_next = gpy_new.predict(X = dataset[\"X_test\"],\n                                         return_counterfactuals=True)\n                        model.update = False\n                    else:\n                        try:\n                            new_model = deepcopy(model)\n                            new_model.fit(**new_data)\n                            preds_next = new_model.predict(X = dataset[\"X_test\"],\n                                         return_counterfactuals=True)\n                        except TypeError:\n                            nm = XBARTEstimator(model = XBART(num_sweeps=20), two_model = False)\n                            nm.fit(**new_data)\n                            preds_next = nm.predict(X = dataset[\"X_test\"],\n                                         return_counterfactuals=True)\n                    util = 1-self.error_rate(preds_next)\n                    decerr += weights[ii] * 1/np.sqrt(np.pi) * util\n                utilities[n] = decerr\n                print(f\"{n} is done\")\n            return decerr\n\n\n# class ExpectedTargetedIG(BaseAcquisitionFunction):\n#     def mvn_KL(self, mu1, S1, mu2, S2):\n#         '''\n#         KL divergence between two multivariate normals\n#         '''\n#         if type(mu1)!=np.ndarray:\n#             d = 1\n#         else:\n#             d = mu1.shape[0]\n#         KL = 0.5*(np.log(la.det(S2)/la.det(S1)) + np.trace(la.inv(S2).dot(S1)) + (mu1 - mu2).T.dot(la.inv(S2).dot((mu1 - mu2))) - d)\n#         return KL\n    \n#     def calculate_metrics(self, model, dataset):\n#         '''\n#         Uses Gauss-Hermite quadrature to compute expected information gain in decision\n#         '''\n#         ite_pred, p1, p0, p1s, p0s = model.predict(X = dataset[\"X_test\"],\n#                                          return_counterfactuals=True)\n#         ypred = np.where(p1 &gt; p0, p1, p0)\n#         Spred = np.where(p1 &gt; p0, p1s, p0s)\n#         N = dataset[\"X_pool\"].shape[0]\n#         # d = self._decide(preds)\n#         # ypred, Spred = preds[d]\n#         X_STAR = dataset[\"X_pool\"]\n#         # x_star = self.dat['predictors'][n,:].reshape(1,-1)\n#         a_star = 1 - dataset[\"t_pool\"] # counterfactual action\n\n#         points, weights = np.polynomial.hermite.hermgauss(32) \n#         scores = []\n#         NUM_SIMULATIONS = 10\n#         sims = np.random.choice(N, NUM_SIMULATIONS, replace=False)\n#         for i in sims:\n#             x_star = X_STAR[i, :].reshape((1, -1))\n#             preds_star = model.predict(x_star, return_counterfactuals=True)\n#             targig = 0.0\n#             for ii, yy in enumerate(points):\n#                 if dataset[\"t_pool\"][i] == 1:\n#                     mu_star, S_star = preds_star[1], preds_star[3]\n#                 else:\n#                     mu_star, S_star = preds_star[2], preds_star[4]\n#                 y_star = np.sqrt(2)*np.sqrt(S_star)*yy + mu_star #for substitution\n#                 #try:\n#                 new_model = deepcopy(model)\n#                 new_data = {\"X_training\": np.concatenate((dataset[\"X_training\"], x_star)),\n#                            \"y_training\":  np.concatenate((dataset[\"y_training\"], \n#                                                           dataset[\"y_pool\"][i].reshape((1,)))),\n#                             \"t_training\": np.concatenate((dataset[\"t_training\"], \n#                                                           dataset[\"t_pool\"][i].reshape((1,))))\n#                            }\n#                 new_model.fit(**new_data)\n#                 preds_next = new_model.predict(X = dataset[\"X_test\"],\n#                                  return_counterfactuals=True)\n#                 #model_star = self.update(a_star, x_star, y_star)\n#                 # preds_next = self.predict(new_predictors, model_star)\n#                 #    preds_next = self.predict(new_predictors)\n#                 D_KL = 0\n#                 for d in range(2):\n#                     ypred_next, Spred_next = preds_next[d+1], preds_next[d+3]\n#                     D_KL += self.mvn_KL(ypred_next, Spred_next, ypred, Spred)\n#                 targig += weights[ii] * 1/np.sqrt(np.pi) * D_KL\n#             scores += [targig]\n#         scs = np.zeros(N)\n#         scs[sims] = np.array(scores).ravel()\n#         return scs\n\n\nclass XBARTEstimator(BaseITEEstimator):\n    def __init__(self, model, two_model=False):\n        super().__init__(model = model, two_model = two_model,dataset=None, ps_model=None)\n        \n    def predict(self, **kwargs):\n        X0 = np.concatenate((kwargs[\"X\"],\n                             np.zeros(kwargs[\"X\"].shape[0]).reshape((-1,1))),axis=1)\n        X1 = np.concatenate((kwargs[\"X\"],\n                             np.ones(kwargs[\"X\"].shape[0]).reshape((-1,1))),axis=1)\n        if \"return_mean\" in kwargs:\n            if kwargs[\"return_mean\"] is True:\n                out = self.model.predict(X1) - self.model.predict(X0)\n        else:\n            out = self.model.predict(X1, return_mean=False) - self.model.predict(X0, return_mean=False)\n        if \"return_counterfactuals\" in kwargs:\n            if kwargs[\"return_counterfactuals\"] is True:\n                p1 = self.model.predict(X1, return_mean=False)\n                p0 = self.model.predict(X0, return_mean=False)\n                return (out, np.mean(p1), np.mean(p0), np.std(p1), np.std(p0))\n        return out\n\n\nests = {#\"gpy\":GPyEstimator()\n#         \"gpy\":GPyEstimator(),\n#          \"openbt\": OPENBTITEEstimator(model=openbt.OPENBT(model=\"bart\"),two_model=True),\n#          \"bart\":BARTEstimator(),\n         \"xbart_optimized\":XBARTEstimator(model=XBART( num_sweeps= 50,\n                                            num_trees=400,\n                                            beta=3,alpha=0.6))\n}\nests\n\n\nmodel_results = {}\nfor key, value in ests.items():\n    res = {}\n    for i in range(1):\n        for d in range(747):\n            ds = prepare_data(d, i)\n            asl = BaseActiveLearner(estimator = value,\n                                     acquisition_function=[RandomAcquisitionFunction(name=\"random\",\n                                                                                     method = \"top\" ),\n                                                           EMCMAcquisitionFunction(name=\"emcm\",\n                                                                                   method = \"top\"), \n                                                           UncertaintyAcquisitionFunction(name=\"unc\"),\n#                                                            ExpectedReliability(name=\"er\", method=\"top\")\n                                                         ],\n                                    assignment_function=BaseAssignmentFunction(),\n                                    stopping_function = None,\n                                    dataset=ds,\n                                    al_steps=6)\n            _ = asl.simulate(no_query=1, metric=[\"PEHE\", \"decision\"])\n            res[f\"{key}_{i}_{d}\"] =  pd.DataFrame(asl.simulation_results)\n            res[f\"{key}_{i}_{d}\"][\"sim\"] = i\n            res[f\"{key}_{i}_{d}\"][\"data\"] = d\n#             with open(f\"/Users/zoltan/Desktop/{key}_res.pickle\", \"wb\") as output_file:\n#                 pickle.dump(res, output_file)\n#             print(res)\n#             print(f\"D {d} is done\")\n#             temp_df = create_table(res)\n#             temp_df.to_csv(\"/Users/zoltan/Desktop/asbe_ihdp_results_xbart.csv\")"
  },
  {
    "objectID": "acquisition_functions.html",
    "href": "acquisition_functions.html",
    "title": "Simple usage of different acquisition functions",
    "section": "",
    "text": "from asbe.base import *\nfrom asbe.models import *\nfrom asbe.estimators import *\nfrom econml.orf import DMLOrthoForest\nfrom econml.dml import CausalForestDML\n#from causalml.inference.nn import CEVAE\nimport pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom copy import deepcopy\nimport econml\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import ConstantKernel, RBF\nfrom sklift.datasets import fetch_megafon\n\n\n# np.random.seed(1005)\n# y, X, t, ite, _, e = synthetic_data(mode=1, n=1000, p=5, sigma=1.0)\n\n\nX, y, t = fetch_megafon(return_X_y_t=True)\n\n\nX = X.to_numpy()[:1000,:]\ny = y.to_numpy()[:1000]\nt = t.to_numpy()[:1000]\nt = np.where(t == \"treatment\", 1, 0)\n\n\n# y1 = np.where(t == 1, y, y + ite)\n# y0 = np.where(t == 0, y, y - ite)\nX_train, X_test, t_train, t_test, y_train, y_test = train_test_split(\n    X, t, y,  test_size=0.9, random_state=1005)\nds = {\"X_training\": X_train,\n     \"y_training\": y_train,\n     \"t_training\": t_train,\n     \"X_pool\": deepcopy(X_test), \n     \"y_pool\": deepcopy(y_test),\n     \"t_pool\": deepcopy(t_test),\n     \"y1_pool\": y1_test,\n     \"y0_pool\":y0_test,\n     \"X_test\": X_test,\n     \"y_test\": y_test,\n      \"t_test\": t_test,\n      \"ite_test\": ite_test\n     }\n\n\ndef test_acq(estimator, acq):\n    asl = BaseActiveLearner(estimator = BARTstimator(model = estimator,\n                                         two_model=False,ps_model=None),\n                        acquisition_function=acq,\n                        assignment_function=UncertaintyAssignmentFunction(),\n                        stopping_function = None,\n                        dataset=ds)\n    asl.fit()\n    X_new, query_idx = asl.query(no_query=10)\n    print(query_idx)\n    asl.teach(query_idx)\n    preds = asl.predict(asl.dataset[\"X_test\"])\n    print(asl.score(metric=\"Qini\"))\n    return True\n\n# def test_acq_ob(acq):\n#     asl = BaseActiveLearner(estimator = OPENBTITEEstimator(model = OPENBT(\n#         model=\"bart\",ntrees=200),\n#                                          two_model=False,ps_model=None),\n#                         acquisition_function=acq,\n#                         assignment_function=MajorityAssignmentFunction(),\n#                         stopping_function = None,\n#                         dataset=ds)\n#     asl.fit()\n#     X_new, query_idx = asl.query(no_query=10)\n#     print(query_idx)\n#     asl.teach(query_idx)\n#     preds = asl.predict(asl.dataset[\"X_test\"])\n#     print(asl.score())\n#     return True\n\ndef test_acq_gp(acq):\n    asl = BaseActiveLearner(estimator = GPEstimator(model = GaussianProcessRegressor(ConstantKernel()*RBF(np.ones(ds[\"X_training\"].shape[1],))),\n                                         two_model=True,\n                                                    ps_model=None),\n                        acquisition_function=acq,\n                        assignment_function=MajorityAssignmentFunction(),\n                        stopping_function = None,\n                        dataset=ds)\n    asl.fit()\n    X_new, query_idx = asl.query(no_query=20)\n    print(query_idx)\n    print(asl.score())\n    asl.teach(query_idx)\n    asl.fit()\n    #preds = asl.predict(asl.dataset[\"X_test\"])\n    print(asl.score())\n    return True\n\n\ntest_acq(OPENBT(model=\"bart\"), RandomAcquisitionFunction())\n\nOverwriting k to agree with the model's default\nOverwriting overallnu to agree with the model's default\nOverwriting ntree to agree with the model's default\nOverwriting ntreeh to agree with the model's default\nOverwriting overallsd to agree with the model's default\nWriting config file and data\n/var/folders/44/gtm_t6x110jg6b13p4rbwkfh0000gn/T/openbtpy_ftkizzo6\n3+ x variables\nRunning model...\n[699 609 381 649 806 842 805 314 112 283]\n0.04906324638964392\n\n\nTrue\n\n\n\n# test_acq(RandomForestRegressor(), UncertaintyAcquisitionFunction())\n\n\n#test_acq_ob(UncertaintyAcquisitionFunction())\n\n\n#test_acq_ob(TypeSAcquistionFunction())\n\n\n#test_acq_ob(EMCMAcquisitionFunction(no_query=10, B=10))\n\n\n#test_acq_gp(RandomAcquisitionFunction())\n\n\ntest_acq_gp(UncertaintyAcquisitionFunction())\n\n[687 421 116 185 205 482 486 440 635 243  76 476 869 612 506 108 530 611\n 268 368]\n0.5337187351959323\n[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n[ 0.53038938 -0.55797198  1.52225302 -0.29576746 -0.21913841  0.79679204\n  1.3020338   3.89374152  1.08700095  1.1477019   2.21613025  1.09288272\n  2.93490226  1.64948686  2.07372609  0.98864345  1.93008768  0.86036131\n -0.04415296  0.48432562]\n[ 1.21845907 -0.32675738  1.92124318  0.43299755 -0.00447676  1.56619227\n  1.84402239  4.44810804  1.59475614  1.40139785  2.56874432  1.85665729\n  3.75399006  2.41448468  2.9024177   1.75861399  2.86750032  1.65045353\n  0.22963051  0.74852614]\n[ 0.53038938 -0.55797198  1.52225302 -0.29576746 -0.21913841  0.79679204\n  1.3020338   3.89374152  1.08700095  1.1477019   2.21613025  1.09288272\n  2.93490226  1.64948686  2.07372609  0.98864345  1.93008768  0.86036131\n -0.04415296  0.48432562]\n0.5751091655772831\n\n\nTrue\n\n\n\ntest_acq_gp(TypeSAcquistionFunction())\n\n[300 756 111  71 769 390 612 371 122 360 135 352 835 337 624 141 636 316\n 529 142]\n0.5337187351959323\n[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n[-1.36067322e-03 -5.12796861e-01  1.02289924e+00  8.38177760e-01\n  1.44924400e+00  2.57422847e+00  1.64948686e+00  7.30995761e-01\n  2.59964492e+00  7.20538605e-01  1.66191105e+00  2.78676717e-01\n  5.00527092e-01  1.79809835e+00  3.03647193e+00  2.71252851e+00\n  2.58165302e+00  2.38965847e+00  2.94782426e+00  1.25635611e+00]\n[ 0.33369527 -0.33240087  1.21676014  1.56122575  1.75384184  3.40890769\n  2.41448468  1.21785526  2.83841668  1.2186425   2.36359886  1.08998568\n  1.05927929  2.5266249   3.41148707  3.386568    3.20981977  3.26452459\n  3.29757026  1.64321664]\n[-1.36067322e-03 -5.12796861e-01  1.02289924e+00  8.38177760e-01\n  1.44924400e+00  2.57422847e+00  1.64948686e+00  7.30995761e-01\n  2.59964492e+00  7.20538605e-01  1.66191105e+00  2.78676717e-01\n  5.00527092e-01  1.79809835e+00  3.03647193e+00  2.71252851e+00\n  2.58165302e+00  2.38965847e+00  2.94782426e+00  1.25635611e+00]\n0.6183597398651168\n\n\nTrue\n\n\n\ntest_acq_gp(EMCMAcquisitionFunction())\n\n[199 899 308 306 305 304 303 302 301 300 299 298 297 296 295 294 293 292\n 291 290]\n0.5337187351959323\n[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n[ 1.24313648e-01  1.52989324e+00  1.96915558e-01  1.02021858e+00\n  1.52304711e+00  9.65934285e-01  7.98132313e-01  1.52358418e+00\n  1.40168734e+00 -1.36067322e-03  1.94210522e+00  7.15502131e-01\n -1.32016499e+00  3.50806262e-02  2.86028182e+00  2.80033832e+00\n -5.83705994e-02 -8.77760421e-01 -4.94267359e-01  2.33824913e+00]\n[ 6.61634423e-01  1.92266739e+00  8.08301031e-01  1.63039998e+00\n  1.97606387e+00  1.57041756e+00  1.44214321e+00  1.63268067e+00\n  1.57287874e+00  3.33695275e-01  2.28576981e+00  1.11985145e+00\n -8.27985526e-01  7.35931053e-01  3.64530045e+00  3.32170215e+00\n  1.93474920e-01  3.13327052e-03 -3.62252875e-01  3.18616992e+00]\n[ 1.24313648e-01  1.52989324e+00  1.96915558e-01  1.02021858e+00\n  1.52304711e+00  9.65934285e-01  7.98132313e-01  1.52358418e+00\n  1.40168734e+00 -1.36067322e-03  1.94210522e+00  7.15502131e-01\n -1.32016499e+00  3.50806262e-02  2.86028182e+00  2.80033832e+00\n -5.83705994e-02 -8.77760421e-01 -4.94267359e-01  2.33824913e+00]\n0.5747453437695227\n\n\nTrue"
  },
  {
    "objectID": "ihdp.html",
    "href": "ihdp.html",
    "title": "Showcasing asbe with IHDP data",
    "section": "",
    "text": "from asbe.base import *\nfrom asbe.models import *\nfrom asbe.estimators import *\nimport pandas as pd\nimport numpy as np\nfrom openbt.openbt import OPENBT\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom copy import deepcopy\nfrom sklearn.gaussian_process.kernels import ConstantKernel, RBF\nfrom sklearn.gaussian_process import GaussianProcessRegressor\n# import econml\n# from sklearn.base import BaseEstimator\n\nWe read in the data and create feature, target and treatment vectors. After this, we create a train-test split and put the data in a dictionary that can be used by asbe.\n\ndf = pd.read_csv(\n    \"https://raw.githubusercontent.com/AMLab-Amsterdam/CEVAE/master/datasets/IHDP/csv/ihdp_npci_1.csv\",\n    names = [\"treatment\", \"y_factual\", \"y_cfactual\", \"mu0\", \"mu1\"] + [f'x{x}' for x in range(25)])\n\nX = df.loc[:,\"x0\":].to_numpy()\nt = df[\"treatment\"].to_numpy()\n#t = np.zeros_like(t)\ny = df[\"y_factual\"].to_numpy()\ny1 = np.where(df[\"treatment\"] == 1,\n               df['y_factual'],\n               df['y_cfactual'])\ny0 = np.where(df[\"treatment\"] == 0,\n               df['y_factual'],\n               df['y_cfactual'])\nite = np.where(df[\"treatment\"] == 1,\n               df['y_factual'] - df[\"y_cfactual\"],\n               df['y_cfactual'] - df[\"y_factual\"])\n\n\nX_train, X_test, t_train, t_test, y_train, y_test, ite_train, ite_test, y1_train, y1_test, y0_train, y0_test = train_test_split(\n    X, t, y, ite, y1, y0,  test_size=0.9, random_state=1005)\nds = {\"X_training\": X_train,\n     \"y_training\": y_train,\n     \"t_training\": t_train,\n     \"X_pool\": deepcopy(X_test), \n     \"y_pool\": deepcopy(y_test),\n     \"t_pool\": deepcopy(t_test),\n     \"y1_pool\": y1_test,\n     \"y0_pool\":y0_test,\n     \"X_test\": X_test,\n     \"y_test\": y_test,\n      \"t_test\": t_test,\n      \"ite_test\": ite_test\n     }\nasl = BaseActiveLearner(estimator = BaseITEEstimator(model = RandomForestRegressor(),\n                                         two_model=False,ps_model=None),\n                        acquisition_function=RandomAcquisitionFunction(),\n                        assignment_function=MajorityAssignmentFunction(),\n                        stopping_function = None,\n                        dataset=ds)\n\n\nasl.fit()\nX_new, query_idx = asl.query(no_query=120)\nasl.teach(query_idx)\npreds = asl.predict(asl.dataset[\"X_test\"])\nasl.score()\n\n\\(\\displaystyle 1.7367637517137022\\)\n\n\n\n#nbdev_slow\n#nbdev_slow_test\nbite = OPENBTITEEstimator(model=OPENBT(model=\"bart\"),\n                          two_model = False,\n                          ps_model  = None,\n                          dataset   = ds)\nbite.fit()\npreds_obt = bite.predict(X = ds[\"X_test\"])\n#print(preds_obt.shape)\n\nOverwriting k to agree with the model's default\nOverwriting overallnu to agree with the model's default\nOverwriting ntree to agree with the model's default\nOverwriting ntreeh to agree with the model's default\nOverwriting overallsd to agree with the model's default\nWriting config file and data\n/var/folders/44/gtm_t6x110jg6b13p4rbwkfh0000gn/T/openbtpy_az0r_7lm\n3+ x variables\nRunning model...\n\n\n\n#nbdev_slow\n#nbdev_slow_test\nbite = CausalForestEstimator(\n                        two_model = None,\n                        ps_model  = None,\n                        dataset   = ds)\nbite.fit()\npreds_cf = bite.predict(X = ds[\"X_test\"])\n\n\n#nbdev_slow\n#nbdev_slow_test\nzcite = CEVAEEstimator(dataset=ds,two_model=None)\nzcite.fit()\nzpreds_ce = zcite.predict(X=ds[\"X_test\"])\n\nINFO     Training with 1 minibatches per epoch\nDEBUG    step     0 loss = 51.4242\nINFO     Evaluating 7 minibatches\nDEBUG    batch ate = 0.0681984\nDEBUG    batch ate = 0.0708146\nDEBUG    batch ate = 0.0662221\nDEBUG    batch ate = 0.0651736\nDEBUG    batch ate = 0.0676519\nDEBUG    batch ate = 0.0686008\nDEBUG    batch ate = 0.0672644\n\n\n\n#nbdev_slow\n#nbdev_slow_test\ngite = GPEstimator(model=GaussianProcessRegressor(),\n                          two_model = True,\n                          ps_model  = None,\n                          dataset   = ds)\ngite.fit()\npreds_gp = gite.predict(X = ds[\"X_test\"])"
  }
]