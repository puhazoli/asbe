# AUTOGENERATED! DO NOT EDIT! File to edit: 02_estimators.ipynb (unless otherwise specified).

__all__ = ['CausalForestEstimator', 'OPENBTITEEstimator', 'CEVAEEstimator', 'GPEstimator']

# Cell
#hide_output
from .base import *
from econml.orf import DMLOrthoForest
from econml.dml import CausalForestDML
from causalml.inference.nn import CEVAE
# from openbt.openbt import OPENBT
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression, LogisticRegression
import econml

# Cell
class CausalForestEstimator(BaseITEEstimator):
    def fit(self, **kwargs):
        if self.model is None:
            self.model = CausalForestDML()
        self.model.fit(Y=kwargs["y_training"],
                       T=kwargs["t_training"],
                       X=kwargs["X_training"])

    def predict(self, **kwargs):
        preds = self.model.effect_inference(kwargs["X"])
        if "return_mean" in kwargs:
            out = preds.pred
        else:
            out = (preds.pred, preds.var)
        return out

# Cell
class OPENBTITEEstimator(BaseITEEstimator):
    """Modified ITE estimator for OPENBT

    The predictions are transposed so the uncertainty sampler can calculate uncertianty easily"""
    def predict(self, **kwargs):
        X0 = np.concatenate((kwargs["X"],
                             np.zeros(kwargs["X"].shape[0]).reshape((-1,1))),axis=1)
        X1 = np.concatenate((kwargs["X"],
                             np.ones(kwargs["X"].shape[0]).reshape((-1,1))),axis=1)
        preds0 = self.model.predict(X0)
        preds1 = self.model.predict(X1)
        if "return_mean" in kwargs:
            out = preds1["mmean"] - preds0["mmean"]
        else:
            out = preds1["mdraws"].T - preds0["mdraws"].T
        return out

# Cell
class CEVAEEstimator(BaseITEEstimator):
    def fit(self, **kwargs):
        if self.model is None:
            self.model = CEVAE()
        self.model.fit(kwargs["X_training"],
                       kwargs["t_training"],
                       y=kwargs["y_training"])

    def predict(self, **kwargs):
        return self.model.predict(X = kwargs["X"])

# Cell
class GPEstimator(BaseITEEstimator):
    def predict(self, **kwargs):
        if 'return_mean' in kwargs:
            pred0 = self.model.predict(kwargs["X"])
            pred1 = self.m1.predict(kwargs["X"])
            ite = pred1 - pred0
        else:
            draws0 = self.model.sample_y(kwargs["X"], n_samples=100)
            draws1 = self.m1.sample_y(kwargs["X"], n_samples=100)
            ite = draws1 - draws0
        return ite