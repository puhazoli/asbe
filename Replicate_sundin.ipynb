{
 "cells": [
  {
   "cell_type": "raw",
   "id": "951a14df",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: replicate_sundin.html\n",
    "title: Replication of Sundin et al, ICML 2019\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ce66c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596aa338",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'GPy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mGPy\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mla\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'GPy'"
     ]
    }
   ],
   "source": [
    "from asbe.base import *\n",
    "from asbe.models import *\n",
    "from asbe.estimators import *\n",
    "from econml.orf import DMLOrthoForest\n",
    "from econml.dml import CausalForestDML\n",
    "from openbt.openbt import OPENBT\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "import econml\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel, RBF\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import GPy\n",
    "import pickle\n",
    "import scipy.linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3b69ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical2indicator(data, name, categorical_max=4):\n",
    "    '''\n",
    "    Transforms categorical variable with name 'name' form a data frame to indicator variables\n",
    "    \n",
    "    Taken from https://github.com/IirisSundin/active-learning-for-decision-making/blob/e0c83f58181f81da2f867da4c49f1333fa7d0ae6/src/util.py#L14\n",
    "    '''\n",
    "    values = data[name].values\n",
    "    values[values>= categorical_max] = categorical_max\n",
    "    uni = np.unique(values)\n",
    "    for i, value in enumerate(uni):\n",
    "        data[name+'.'+str(i)] = np.array((values==value), dtype=int)\n",
    "    data.drop(name, axis=1)\n",
    "    return data\n",
    "\n",
    "def prepare_data(row_to_test, random_state,categorical_max=2):\n",
    "    df = pd.read_csv(\"./data/ihdp_rc.csv\")\n",
    "    #names = [\"treatment\", \"y_factual\", \"y_cfactual\", \"mu0\", \"mu1\"] + [f'x{x}' for x in range(25)])\n",
    "    df = categorical2indicator(df, 'birth.o', categorical_max=categorical_max)\n",
    "    cnames = set(df.columns) - set([\"y_factual\", \"y_cfactual\", \"treatment\"])\n",
    "    #X = df.loc[:,\"x0\":].to_numpy()\n",
    "    df[\"first\"] = df[\"first\"] - 1\n",
    "    \n",
    "    # Creating training data\n",
    "    X_test = df.loc[row_to_test, cnames]\n",
    "    y_test = df.loc[row_to_test, \"y_factual\"]\n",
    "    t_test = df.loc[row_to_test, \"treatment\"]\n",
    "    ite_test = np.where(\n",
    "                   df.loc[row_to_test, \"treatment\"] == 1,\n",
    "                   df.loc[row_to_test, 'y_factual'] -  df.loc[row_to_test, \"y_cfactual\"],\n",
    "                   df.loc[row_to_test, 'y_cfactual'] - df.loc[row_to_test, \"y_factual\"])\n",
    "    \n",
    "    df.drop(row_to_test, axis=0, inplace=True)\n",
    "    X = df[cnames]\n",
    "    t = df[\"treatment\"].to_numpy()\n",
    "    y = df[\"y_factual\"].to_numpy()\n",
    "    y1 = np.where(df[\"treatment\"] == 1,\n",
    "                   df['y_factual'],\n",
    "                   df['y_cfactual'])\n",
    "    y0 = np.where(df[\"treatment\"] == 0,\n",
    "                   df['y_factual'],\n",
    "                   df['y_cfactual'])\n",
    "    ite = np.where(df[\"treatment\"] == 1,\n",
    "                   df['y_factual'] - df[\"y_cfactual\"],\n",
    "                   df['y_cfactual'] - df[\"y_factual\"])\n",
    "    \n",
    "    scalers = {}\n",
    "    X_train, X_pool, y_train, y_pool, t_train, t_pool, \\\n",
    "     y1_train, y1_pool, y0_train, y0_pool, ite_train, ite_pool = train_test_split(X, y, t,\n",
    "                                                                         y1, \n",
    "                                                                         y0,\n",
    "                                                                         ite,\n",
    "                                                                         test_size = 646,\n",
    "                                                                         random_state=random_state)\n",
    "    for col in ['bw','nnhealth', 'preterm', 'b.head','momage']:\n",
    "        scalers[col] = StandardScaler()\n",
    "        X_train[col] = scalers[col].fit_transform(X_train[col].to_numpy().reshape(-1,1))\n",
    "        X_pool[col] = scalers[col].transform(X_pool[col].to_numpy().reshape(-1,1))\n",
    "        try:\n",
    "            X_test[col] = scalers[col].transform(X_test[col].to_numpy().reshape(-1,1))\n",
    "        except:\n",
    "            X_test[col] = scalers[col].transform(X_test[col].reshape(-1,1))\n",
    "    #X_train, X_pool, y_train, y_pool = X[], X_pool, y_train, y_pool\n",
    "    ds = {\"X_training\": X_train.to_numpy(),\n",
    "     \"y_training\": y_train,\n",
    "     \"t_training\": t_train,\n",
    "     \"ite_training\": np.zeros_like(y_train),\n",
    "     \"X_pool\": X_pool.to_numpy(), \n",
    "     \"y_pool\": y_pool,\n",
    "     \"t_pool\": t_pool,\n",
    "     \"y1_pool\": y1_pool,\n",
    "     \"y0_pool\": y0_pool,\n",
    "     \"X_test\": X_test.to_numpy().reshape(1, -1),\n",
    "     \"y_test\": y_test,\n",
    "     \"t_test\": t_test,\n",
    "     \"ite_test\": ite_test.reshape(1, -1)\n",
    "     }\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6bf979",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPyEstimator(BaseITEEstimator):\n",
    "    # https://github.com/IirisSundin/active-learning-for-decision-making/blob/master/src/gpmodel.py\n",
    "    \n",
    "    def _create_model(self, x, y):\n",
    "        d = x.shape[1]\n",
    "        prior = GPy.core.parameterization.priors.Gamma(a=1.5,b=3.0)\n",
    "        kern = GPy.kern.RBF(input_dim=d, ARD=True)\n",
    "        kern.variance.set_prior(prior, warning=False)\n",
    "        kern.lengthscale.set_prior(prior, warning=False)\n",
    "        lik1 = GPy.likelihoods.Gaussian()\n",
    "        lik1.variance.set_prior(prior, warning=False)\n",
    "        lik_expert = GPy.likelihoods.Gaussian()\n",
    "        lik_expert.variance.set_prior(prior, warning=False)\n",
    "        lik = GPy.likelihoods.MixedNoise([lik1, lik_expert])\n",
    "        output_index = np.ones(x.shape[0])\n",
    "        model = GPy.core.GP(X =  x,\n",
    "                                 Y =  y.reshape(-1, 1), \n",
    "                                 kernel=kern,\n",
    "                                 likelihood=lik, \n",
    "                                 Y_metadata = {'output_index':output_index})\n",
    "        model.optimize()\n",
    "        return model\n",
    "        \n",
    "    def fit(self, **kwargs):\n",
    "        self.models = {}\n",
    "        Xt, yt = kwargs[\"X_training\"][(kwargs[\"t_training\"] == 1), :],\\\n",
    "                kwargs[\"y_training\"][(kwargs[\"t_training\"] == 1)]\n",
    "        Xc, yc = kwargs[\"X_training\"][(kwargs[\"t_training\"] == 0), :],\\\n",
    "        kwargs[\"y_training\"][(kwargs[\"t_training\"] == 0)]\n",
    "        self.models[\"c\"] = self._create_model(Xc, yc)\n",
    "        self.models[\"t\"] = self._create_model(Xt, yt)\n",
    "        \n",
    "    def predict(self, X, **kwargs):\n",
    "        if len(X.shape) == 1:\n",
    "            X = X.reshape((1, -1))\n",
    "        p1 = self.models[\"t\"].posterior_samples_f(X, 100)\n",
    "        p0 = self.models[\"c\"].posterior_samples_f(X, 100)\n",
    "        ite = p1 - p0\n",
    "        ite = ite.squeeze(1)\n",
    "        if \"return_mean\" in kwargs:\n",
    "            if kwargs[\"return_mean\"]:\n",
    "                ite = self.models[\"t\"].predict_noiseless(X)[\n",
    "                    0] - self.models[\"c\"].predict_noiseless(X)[0]\n",
    "        if \"return_counterfactuals\" in kwargs:\n",
    "            if kwargs[\"return_counterfactuals\"]:\n",
    "                p1, p1s = self.models[\"t\"]._raw_predict(X)\n",
    "                p0, p0s = self.models[\"c\"]._raw_predict(X)\n",
    "                ite = (ite, p1, p0, p1s, p0s)\n",
    "        return ite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb21ba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpectedTargetedIG(BaseAcquisitionFunction):\n",
    "    def mvn_KL(self, mu1, S1, mu2, S2):\n",
    "        '''\n",
    "        KL divergence between two multivariate normals\n",
    "        '''\n",
    "        if type(mu1)!=np.ndarray:\n",
    "            d = 1\n",
    "        else:\n",
    "            d = mu1.shape[0]\n",
    "        KL = 0.5*(np.log(la.det(S2)/la.det(S1)) + np.trace(la.inv(S2).dot(S1)) + (mu1 - mu2).T.dot(la.inv(S2).dot((mu1 - mu2))) - d)\n",
    "        return KL\n",
    "    \n",
    "    def calculate_metrics(self, model, dataset):\n",
    "        '''\n",
    "        Uses Gauss-Hermite quadrature to compute expected information gain in decision\n",
    "        '''\n",
    "        ite_pred, p1, p0, p1s, p0s = model.predict(X = dataset[\"X_test\"],\n",
    "                                         return_counterfactuals=True)\n",
    "        ypred = np.where(p1 > p0, p1, p0)\n",
    "        Spred = np.where(p1 > p0, p1s, p0s)\n",
    "        N = dataset[\"X_pool\"].shape[0]\n",
    "        # d = self._decide(preds)\n",
    "        # ypred, Spred = preds[d]\n",
    "        X_STAR = dataset[\"X_pool\"]\n",
    "        # x_star = self.dat['predictors'][n,:].reshape(1,-1)\n",
    "        a_star = 1 - dataset[\"t_pool\"] # counterfactual action\n",
    "\n",
    "        points, weights = np.polynomial.hermite.hermgauss(32) \n",
    "        scores = []\n",
    "        NUM_SIMULATIONS = N\n",
    "        sims = np.random.choice(N, NUM_SIMULATIONS, replace=False)\n",
    "        #for i in range(X_STAR.shape[0]):\n",
    "        for i in sims:\n",
    "            x_star = X_STAR[i, :].reshape((1, -1))\n",
    "            targig = 0.0\n",
    "            for ii, yy in enumerate(points):\n",
    "                preds_star = model.predict(x_star, return_counterfactuals=True)\n",
    "                if dataset[\"t_pool\"][i] == 1:\n",
    "                    mu_star, S_star = preds_star[1], preds_star[3]\n",
    "                else:\n",
    "                    mu_star, S_star = preds_star[2], preds_star[4]\n",
    "                y_star = np.sqrt(2)*np.sqrt(S_star)*yy + mu_star #for substitution\n",
    "                #try:\n",
    "                new_model = deepcopy(model)\n",
    "                new_data = {\"X_training\": np.concatenate((dataset[\"X_training\"], x_star)),\n",
    "                           \"y_training\":  np.concatenate((dataset[\"y_training\"], \n",
    "                                                          dataset[\"y_pool\"][i].ravel())),\n",
    "                            \"t_training\": np.concatenate((dataset[\"t_training\"], \n",
    "                                                          dataset[\"t_pool\"][i].ravel()))\n",
    "                           }\n",
    "                new_model.fit(**new_data)\n",
    "                preds_next = new_model.predict(X = dataset[\"X_test\"],\n",
    "                                 return_counterfactuals=True)\n",
    "                #model_star = self.update(a_star, x_star, y_star)\n",
    "                # preds_next = self.predict(new_predictors, model_star)\n",
    "                #    preds_next = self.predict(new_predictors)\n",
    "                D_KL = 0\n",
    "                for d in range(2):\n",
    "                    ypred_next, Spred_next = preds_next[d+1], preds_next[d+3]\n",
    "                    D_KL += self.mvn_KL(ypred_next, Spred_next, ypred, Spred)\n",
    "                targig += weights[ii] * 1/np.sqrt(np.pi) * D_KL\n",
    "            scores += [targig]\n",
    "        scs = np.zeros(N)\n",
    "        scs[sims] = np.array(scores).ravel()\n",
    "        return scs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7102c7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xbart import XBART\n",
    "class XBARTEstimator(BaseITEEstimator):\n",
    "    def __init__(self, model, two_model=False):\n",
    "        super().__init__(model = model, two_model = two_model,dataset=None, ps_model=None)\n",
    "        \n",
    "    def predict(self, **kwargs):\n",
    "        X0 = np.concatenate((kwargs[\"X\"],\n",
    "                             np.zeros(kwargs[\"X\"].shape[0]).reshape((-1,1))),axis=1)\n",
    "        X1 = np.concatenate((kwargs[\"X\"],\n",
    "                             np.ones(kwargs[\"X\"].shape[0]).reshape((-1,1))),axis=1)\n",
    "        if \"return_mean\" in kwargs:\n",
    "            out = self.model.predict(X1) - self.model.predict(X0)\n",
    "        else:\n",
    "            out = self.model.predict(X1, return_mean=False) - self.model.predict(X0, return_mean=False)\n",
    "        return out\n",
    "        \n",
    "ests = {#\"xbart\":XBARTEstimator(model = XBART(num_sweeps=20), two_model = False),\n",
    "        \"gpy\":GPyEstimator()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbc0709",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in ests.items():\n",
    "    res = {}\n",
    "    for i in range(5):\n",
    "        for d in range(2):\n",
    "            ds = prepare_data(d, i)\n",
    "            asl = BaseActiveLearner(estimator = value,\n",
    "                                    acquisition_function=[RandomAcquisitionFunction(name=\"random\",\n",
    "                                                                                    method = \"top\" ),\n",
    "                                                          EMCMAcquisitionFunction(name=\"emcm\",\n",
    "                                                                                  method = \"top\"), \n",
    "                                                          ExpectedTargetedIG(name=\"etig\", method=\"top\")],\n",
    "                                    assignment_function=BaseAssignmentFunction(),\n",
    "                                    stopping_function = None,\n",
    "                                    dataset=ds,\n",
    "                                   al_steps=6)\n",
    "            _ = asl.simulate(no_query=1, metric=[\"PEHE\", \"decision\"])\n",
    "            res[f\"{i}_{d}\"] =  pd.DataFrame(asl.simulation_results)\n",
    "            res[f\"{i}_{d}\"][\"sim\"] = i\n",
    "            res[f\"{i}_{d}\"][\"data\"] = d\n",
    "            print(f\"D {d} is done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc97bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>random_1</th>\n",
       "      <th>emcm_1</th>\n",
       "      <th>etig_1</th>\n",
       "      <th>sim</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   random_1  emcm_1  etig_1  sim  data\n",
       "0       NaN     NaN     NaN  0.0   0.0\n",
       "1       0.0     0.0     0.0  NaN   NaN\n",
       "2       0.0     0.0     0.0  NaN   NaN\n",
       "3       0.0     0.0     0.0  NaN   NaN\n",
       "4       0.0     0.0     0.0  NaN   NaN\n",
       "5       0.0     0.0     0.0  NaN   NaN\n",
       "6       0.0     0.0     0.0  NaN   NaN\n",
       "0       NaN     NaN     NaN  0.0   1.0\n",
       "1       0.0     0.0     0.0  NaN   NaN\n",
       "2       0.0     0.0     0.0  NaN   NaN\n",
       "3       0.0     0.0     0.0  NaN   NaN\n",
       "4       0.0     0.0     0.0  NaN   NaN\n",
       "5       0.0     0.0     0.0  NaN   NaN\n",
       "6       0.0     0.0     0.0  NaN   NaN\n",
       "0       NaN     NaN     NaN  1.0   0.0\n",
       "1       0.0     0.0     0.0  NaN   NaN\n",
       "2       0.0     0.0     0.0  NaN   NaN\n",
       "3       0.0     0.0     0.0  NaN   NaN\n",
       "4       0.0     0.0     0.0  NaN   NaN\n",
       "5       0.0     0.0     0.0  NaN   NaN\n",
       "6       0.0     0.0     0.0  NaN   NaN\n",
       "0       NaN     NaN     NaN  1.0   1.0\n",
       "1       0.0     0.0     0.0  NaN   NaN\n",
       "2       0.0     0.0     0.0  NaN   NaN\n",
       "3       0.0     0.0     0.0  NaN   NaN\n",
       "4       0.0     0.0     0.0  NaN   NaN\n",
       "5       0.0     0.0     0.0  NaN   NaN\n",
       "6       0.0     0.0     0.0  NaN   NaN"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([x.loc[\"decision\"].apply(pd.Series).T for x in res.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1fe1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>random_1</th>\n",
       "      <th>unc_1</th>\n",
       "      <th>type_s_1</th>\n",
       "      <th>emcm_1</th>\n",
       "      <th>sim</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       random_1     unc_1  type_s_1    emcm_1  sim  data\n",
       "index                                                   \n",
       "0           NaN       NaN       NaN       NaN  0.0  17.5\n",
       "1      0.750000  0.750000  0.750000  0.750000  NaN   NaN\n",
       "2      0.527778  0.750000  0.777778  0.750000  NaN   NaN\n",
       "3      0.472222  0.611111  0.750000  0.388889  NaN   NaN\n",
       "4      0.722222  0.583333  0.472222  0.555556  NaN   NaN\n",
       "5      0.555556  0.555556  0.722222  0.416667  NaN   NaN\n",
       "6      0.305556  0.333333  0.416667  0.527778  NaN   NaN"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([x.loc[\"decision\"].apply(pd.Series).T for x in res.values()]).reset_index().groupby('index').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa97d8d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
