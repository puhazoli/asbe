{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquisition and assignment functions\n",
    "\n",
    "> All the currently implemented ac. and as. functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#hide_output\n",
    "import numpy as np\n",
    "from asbe.base import *\n",
    "from modAL.models.base import BaseLearner\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, RegressorMixin\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from typing import Union, Optional, Callable\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RandomAcquisitionFunction(BaseAcquisitionFunction):\n",
    "    def calculate_metrics(self, model, dataset):\n",
    "        ixs = np.arange(dataset[\"X_pool\"].shape[0])\n",
    "        np.random.shuffle(ixs)\n",
    "        return ixs\n",
    "    \n",
    "class UncertaintyAcquisitionFunction(BaseAcquisitionFunction):\n",
    "    def calculate_metrics(self, model, dataset):\n",
    "        preds = model.predict(X = dataset[\"X_pool\"])\n",
    "        if type(preds) is tuple:\n",
    "            p, pred_var = preds[0], preds[1]\n",
    "        try:\n",
    "            if preds.shape[1] <= 1:\n",
    "                raise Exception(\"Not possible to calculate uncertainty when dimensions <=1\")\n",
    "            pred_var = np.var(preds, axis = 1)\n",
    "        except IndexError:\n",
    "            raise Exception(\"Not possible to calculate uncertainty when dimensions <=1\")\n",
    "        return pred_var\n",
    "    \n",
    "class TypeSAcquistionFunction(BaseAcquisitionFunction):\n",
    "    def calculate_metrics(self, model, dataset):\n",
    "        preds = model.predict(X=dataset[\"X_pool\"])\n",
    "        if preds.shape[0] <= 1:\n",
    "            raise Exception(\"Type S error needs multiple values per prediction\")\n",
    "        prob_s = np.sum(preds > 0, axis=1)/preds.shape[1]\n",
    "        prob_s_sel = np.where(prob_s > 0.5, 1-prob_s, prob_s) + .0001\n",
    "        return prob_s_sel\n",
    "        \n",
    "class EMCMAcquisitionFunction(BaseAcquisitionFunction):\n",
    "    def __init__(self, no_query = 1,\n",
    "                 method = \"top\",\n",
    "                 name = \"emcm\",\n",
    "                 approx_model = SGDRegressor(),\n",
    "                 B = 100,\n",
    "                 K = 5,\n",
    "                 threshold = 0):\n",
    "        super().__init__(no_query, method, name)\n",
    "        self.approx_model = approx_model\n",
    "        self.B = B\n",
    "        self.K = K\n",
    "        self.threshold = threshold\n",
    "        self.model_change = []\n",
    "        \n",
    "    def calculate_metrics(self, model, dataset, **kwargs):\n",
    "        ite_train_preds = model.predict(X = dataset[\"X_training\"])\n",
    "        ite_pool_preds = model.predict(X = dataset[\"X_pool\"])\n",
    "        if ite_train_preds.shape[1] < 1:\n",
    "            raise ValueError(\"The treatment effect does not have uncertainty around it - \\\n",
    "                         consider using a different estimator\")\n",
    "        sc = StandardScaler()\n",
    "        X_scaled = sc.fit_transform(dataset[\"X_training\"])\n",
    "        # Fit approx model\n",
    "        # calc type-s error\n",
    "        train_type_s_prob_1 = np.sum(ite_train_preds > 0, axis=1)/ite_train_preds.shape[1]\n",
    "        train_type_s = np.where(train_type_s_prob_1 > 0.5, 1-train_type_s_prob_1, train_type_s_prob_1) + .0001\n",
    "        pool_type_s_prob_1 = np.sum(ite_pool_preds > 0, axis=1)/ite_pool_preds.shape[1]\n",
    "        pool_type_s = np.where(pool_type_s_prob_1 > 0.5, 1-pool_type_s_prob_1, pool_type_s_prob_1) + .0001\n",
    "        self.approx_model.fit(\n",
    "            X = X_scaled,\n",
    "            y = np.mean(ite_train_preds, axis=1),\n",
    "            sample_weight = 5*train_type_s)\n",
    "        # Using list as it is faster than appending to np array\n",
    "        query_idx = []\n",
    "        # Using a loop for the combinatorial opt. part\n",
    "        for ix in range(self.no_query):\n",
    "            if self.no_query > (dataset[\"X_pool\"].shape[0]):\n",
    "                raise IndexError(\"Too many samples are queried from the pool ($n_2 > ||X_pool||$)\")\n",
    "            # Select randomly from X_pool\n",
    "            prob_sampling = np.ones((dataset[\"X_pool\"].shape[0]))/(\n",
    "                dataset[\"X_pool\"].shape[0]-len(query_idx))\n",
    "            # Set the probability of already selected samples to 0\n",
    "            if ix > 0:\n",
    "                prob_sampling[query_idx] = 0\n",
    "            # B = 100 by default, can be modified by kwargs\n",
    "            considered_ixes = np.random.choice(dataset[\"X_pool\"].shape[0],\n",
    "                                             size = self.B,\n",
    "                                             replace=False, \n",
    "                                             p=prob_sampling)\n",
    "            # Calculate the grads for all  \n",
    "            grads = np.array([])\n",
    "            for considered_ix in considered_ixes:\n",
    "                new_X = sc.transform(dataset[\"X_pool\"][considered_ix].reshape(1, -1))\n",
    "                app_predicted_ite = self.approx_model.predict(new_X)\n",
    "                # bootstrapping accroding to eq. 11 of Cai and Zhang\n",
    "                true_ite = np.random.choice(ite_pool_preds[considered_ix],\n",
    "                                            size=self.K)\n",
    "                grad = np.sum(np.abs(np.kron((true_ite - app_predicted_ite),new_X)))\n",
    "                grads = np.append(grads, grad)\n",
    "            if np.max(grads) < self.threshold:\n",
    "                break\n",
    "            self.model_change = np.append(self.model_change,np.max(grads))\n",
    "            query_idx.append(int(considered_ixes[np.argmax(grads)]))\n",
    "            self.approx_model.partial_fit(\n",
    "                sc.transform(dataset[\"X_pool\"][int(query_idx[ix])].reshape(1, -1)),\n",
    "                np.random.choice(ite_pool_preds[int(query_idx[ix])], size=1),\n",
    "                sample_weight = np.array(pool_type_s[int(query_idx[ix])]).ravel())\n",
    "        out = np.zeros(dataset[\"X_pool\"].shape[0])\n",
    "        out[query_idx] = 1\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RandomAssignmentFunction(BaseAssignmentFunction):\n",
    "    def __init__(self, base_selection = 0, p = .5):\n",
    "        super().__init__(base_selection)\n",
    "        self.p = p\n",
    "        \n",
    "    def select_treatment(self, model, dataset, query_idx):\n",
    "        return np.random.binomial(1, self.p, (query_idx.shape[0],))\n",
    "    \n",
    "class UncertaintyAssignmentFunction(BaseAssignmentFunction):\n",
    "    def select_treatment(self, model, dataset, query_idx):\n",
    "        preds = model.predict(X = dataset[\"X_pool\"][query_idx, :], return_per_cf = True)\n",
    "        try:\n",
    "            var1 = np.var(preds[\"pred1\"], axis=1)\n",
    "            var0 = np.var(preds[\"pred0\"], axis=1)\n",
    "            ex = var1 / (var1 + var0)\n",
    "            out = np.random.binomial(1,ex)\n",
    "        except:\n",
    "            raise ValueError(\"Can't access uncertainty per counterfactual\")\n",
    "        return out\n",
    "    \n",
    "class MajorityAssignmentFunction(BaseAssignmentFunction):\n",
    "    def select_treatment(self, model, dataset, query_idx):\n",
    "        if sum(dataset[\"t_training\"]) >= dataset[\"t_training\"].shape[0]/2:\n",
    "            out = np.zeros((query_idx.shape[0],))\n",
    "        else:\n",
    "            out = np.ones((query_idx.shape[0],))\n",
    "        return out\n",
    "    \n",
    "class PMajorityAssignmentFunction(BaseAssignmentFunction):\n",
    "    def __init__(self, base_selection = 0, p = .5):\n",
    "        super().__init__(base_selection)\n",
    "        self.p = p\n",
    "        \n",
    "    def select_treatment(self, model, dataset, query_idx):\n",
    "        if sum(dataset[\"t_training\"]) >= dataset[\"t_training\"].shape[0]/2:\n",
    "            out = np.random.binomial(query_idx.shape[0], p = 1-self.p)\n",
    "        else:\n",
    "            out = np.random.binomial(query_idx.shape[0], p = self.p)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.normal(size = 1000).reshape((500,2))\n",
    "t = np.random.binomial(n = 1, p = 0.5, size = 500)\n",
    "y = np.random.binomial(n = 1, p = 1/(1+np.exp(X[:, 1]*2 + t*3)))\n",
    "X_test = np.random.normal(size = 200).reshape((100,2))\n",
    "t_test = np.random.binomial(n = 1, p = 0.5, size = 100)\n",
    "y_test = np.random.binomial(n = 1, p = 1/(1+np.exp(X_test[:, 1]*2 + t_test*3)))\n",
    "a = BaseITEEstimator(LogisticRegression(solver=\"lbfgs\"), two_model = True, ps=LogisticRegression())\n",
    "a.fit(X_training=X, t_training=t, y_training=y)\n",
    "assert type(a.model) == LogisticRegression  # test assigning a model\n",
    "assert a.model.intercept_ is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xbart import XBART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = {\"X_training\":X,\n",
    "     \"y_training\": y,\n",
    "     \"t_training\": t,\n",
    "     \"X_pool\": deepcopy(X_test), \n",
    "     \"y_pool\": deepcopy(y_test),\n",
    "     \"t_pool\": deepcopy(t_test),\n",
    "     \"X_test\": X_test,\n",
    "     \"y_test\": y_test,\n",
    "      \"t_test\": t_test\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asl = BaseActiveLearner(estimator = BaseITEEstimator(model = XBART()), \n",
    "                        acquisition_function=BaseAcquisitionFunction(),\n",
    "                        assignment_function=RandomAssignmentFunction(),\n",
    "                        stopping_function = None,\n",
    "                        dataset=ds)\n",
    "asl.fit()\n",
    "ite_pred = asl.predict(asl.dataset[\"X_test\"])\n",
    "X_sel, query_idx = asl.query(no_query=10)\n",
    "asl.teach(query_idx)\n",
    "assert ite_pred.shape[0] == 100\n",
    "assert X_sel.shape       == (10,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
