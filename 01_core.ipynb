{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASBE - Automatic Stopping for Batch Experiments\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "from asbe.base import *\n",
    "from modAL.models.base import BaseLearner\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, RegressorMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from typing import Union, Optional, Callable\n",
    "from copy import deepcopy\n",
    "from pylift.eval import UpliftEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def random_batch_sampling(classifier, X_pool, n2, **kwargs):\n",
    "    \"Randomly sample a batch from a pool of unlabaled samples\"\n",
    "    n_samples = X_pool.shape[0]\n",
    "    query_idx = np.random.choice(range(n_samples), size=n2,replace=False)\n",
    "    return X_pool[query_idx], query_idx\n",
    "\n",
    "def uncertainty_batch_sampling(classifier, X_pool, n2, **kwargs):\n",
    "    \"Select the top $n_2$ most uncertain units\"\n",
    "    ite_preds, y1_preds, y_preds = classifier.predict(X_pool, **kwargs)\n",
    "    # Calculate variance based on predicted\n",
    "    if y1_preds.shape[0] <= 1 or \\\n",
    "    len(y1_preds.shape) <= 1:\n",
    "            raise Exception(\"Not possible to calculate uncertainty when dimensions <=1 \")\n",
    "    ite_vars = np.var(classifier.estimator.y1_preds - classifier.estimator.y0_preds, axis=1)\n",
    "    query_idx = np.argsort(ite_vars)[-n2:][::-1]\n",
    "        \n",
    "    return X_pool[query_idx], query_idx\n",
    "\n",
    "def type_s_batch_sampling(classifier, X_pool, n2, **kwargs):\n",
    "    \"Select highest type-s\"\n",
    "    ite_preds, y1_preds, y_preds = classifier.predict(X_pool, **kwargs)\n",
    "    prob_s = np.sum(ite_preds > 0, axis=1)/ite_preds.shape[1]\n",
    "    prob_s_sel = np.where(prob_s > 0.5, 1-prob_s, prob_s) + .0001\n",
    "    query_idx = np.argsort(prob_s_sel)[-n2:][::-1]\n",
    "    \n",
    "    return X_pool[query_idx], query_idx\n",
    "   \n",
    "\n",
    "def expected_model_change_maximization(classifier, X_pool, n2, **kwargs):\n",
    "    \"\"\"\n",
    "    Implementation of EMCM for ITE - using a surrogate SGD model.\n",
    "    \"\"\"\n",
    "    # Get mean of the trained prediction\n",
    "    ite_train_preds, y1_train_preds, y0_train_preds = \\\n",
    "        classifier.predict(classifier.X_training, **kwargs)\n",
    "    if ite_train_preds.shape[1] < 1:\n",
    "        raise ValueError(\"The treatment effect does not have uncertainty around it - \\\n",
    "                         consider using a different estimator\")\n",
    "    # Get mean of predicted ITE\n",
    "    ite_pool_preds, y1_pool_preds, y0_pool_preds = \\\n",
    "        classifier.predict(X_pool, **kwargs)\n",
    "    # Then scale the data so sgd works the best\n",
    "    sc = StandardScaler()\n",
    "    X_scaled = sc.fit_transform(classifier.X_training)\n",
    "    # Fit approx model\n",
    "    # calc type-s error\n",
    "    train_type_s_prob_1 = np.sum(ite_train_preds > 0, axis=1)/ite_train_preds.shape[1]\n",
    "    train_type_s = np.where(train_type_s_prob_1 > 0.5, 1-train_type_s_prob_1, train_type_s_prob_1) + .0001\n",
    "    pool_type_s_prob_1 = np.sum(ite_pool_preds > 0, axis=1)/ite_pool_preds.shape[1]\n",
    "    pool_type_s = np.where(pool_type_s_prob_1 > 0.5, 1-pool_type_s_prob_1, pool_type_s_prob_1) + .0001\n",
    "    classifier.approx_model.fit(\n",
    "        X = X_scaled,\n",
    "        y = np.mean(ite_train_preds, axis=1),\n",
    "        sample_weight = 5*train_type_s)\n",
    "    # Using list as it is faster than appending to np array\n",
    "    query_idx = []\n",
    "    # Using a loop for the combinatorial opt. part\n",
    "    for ix in range(n2):\n",
    "        if n2 > (X_pool.shape[0]):\n",
    "            raise IndexError(\"Too many samples are queried from the pool ($n_2 > ||X_pool||$)\")\n",
    "        # Select randomly from X_pool\n",
    "        prob_sampling = np.ones((X_pool.shape[0]))/(X_pool.shape[0]-len(query_idx))\n",
    "        # Set the probability of already selected samples to 0\n",
    "        if ix > 0:\n",
    "            prob_sampling[query_idx] = 0\n",
    "        # B = 100 by default, can be modified by kwargs\n",
    "        considered_ixes = np.random.choice(X_pool.shape[0],\n",
    "                                         size = kwargs[\"B\"] if \"B\" in kwargs else 100,\n",
    "                                         replace=False, \n",
    "                                         p=prob_sampling)\n",
    "        # Calculate the grads for all the \n",
    "        grads = np.array([])\n",
    "        for considered_ix in considered_ixes:\n",
    "            new_X = sc.transform(X_pool[considered_ix].reshape(1, -1))\n",
    "            app_predicted_ite = classifier.approx_model.predict(new_X)\n",
    "            # bootstrapping accroding to eq. 11 of Cai and Zhang\n",
    "            true_ite = np.random.choice(ite_pool_preds[considered_ix],\n",
    "                                        size=kwargs[\"K\"] if \"K\" in kwargs else 5)\n",
    "            grad = np.sum(np.abs(np.kron((true_ite - app_predicted_ite),new_X)))\n",
    "            grads = np.append(grads, grad)\n",
    "        if np.max(grads) < kwargs[\"threshold\"] if \"threshold\" in kwargs else 0:\n",
    "            break\n",
    "        classifier.model_change = np.append(classifier.model_change,np.max(grads))\n",
    "        query_idx.append(int(considered_ixes[np.argmax(grads)]))\n",
    "        classifier.approx_model.partial_fit(\n",
    "            sc.transform(X_pool[int(query_idx[ix])].reshape(1, -1)),\n",
    "            np.random.choice(ite_pool_preds[int(query_idx[ix])], size=1),\n",
    "            sample_weight = np.array(pool_type_s[int(query_idx[ix])]).ravel())\n",
    "        \n",
    "    return X_pool[query_idx], query_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %nbdev_export\n",
    "# def variance_assignment(classifier, X_pool, n2, **kwargs):\n",
    "#     \"\"\"Function to assign treatment or control based on the variance of the cf\n",
    "#     \"\"\"\n",
    "#     ite_pool_preds, y1_pool_preds, y0_pool_preds = \\\n",
    "#         classifier.predict(X_pool, **kwargs)\n",
    "#     var_y1 = np.var(y1_pool_preds, axis=1)\n",
    "#     var_y0 = np.var(y0_pool_preds, axis=1)\n",
    "#     prob_of_treatment = var_y1/(var_y1+var_y0)\n",
    "#     drawn_treatment = np.random.binomial(1, prob_of_treatment)\n",
    "#     return drawn_treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "estimator_type = ClassifierMixin\n",
    "class ASLearner(BaseLearner):\n",
    "    \"\"\"A(ctively)S(topping)Learner class for automatic stopping in batch-mode AL\"\"\"\n",
    "    def __init__(self,\n",
    "                 estimator: estimator_type=None, \n",
    "                 query_strategy=None,\n",
    "                 assignment_fc=None,\n",
    "                 X_training: np.ndarray = None,\n",
    "                 t_training: np.ndarray = None,\n",
    "                 y_training: np.ndarray = None,\n",
    "                 X_pool: np.ndarray = None,\n",
    "                 X_test: np.ndarray = None,\n",
    "                 approx_model: RegressorMixin = None\n",
    "                ) -> None:\n",
    "        self.estimator = estimator\n",
    "        self.query_strategy = query_strategy\n",
    "        self.assignment_fc = assignment_fc\n",
    "        self.X_training = X_training\n",
    "        self.y_training = y_training\n",
    "        self.t_training = t_training\n",
    "        self.X_pool     = X_pool\n",
    "        self.X_test     = X_test\n",
    "        self.approx_model = approx_model\n",
    "        self.model_change = np.array([])\n",
    "        \n",
    "    def _add_queried_data_class(self, X, t, y):\n",
    "        self.X_training = np.vstack((self.X_training, X))\n",
    "        self.t_training = np.concatenate((self.t_training, t))\n",
    "        self.y_training = np.concatenate((self.y_training, y))\n",
    "    \n",
    "    def _update_estimator_values(self):\n",
    "        self.estimator.__dict__.update(X_training = self.X_training,\n",
    "                               y_training  =        self.y_training,\n",
    "                               t_training  =        self.t_training,\n",
    "                               X_test      =        self.X_test)\n",
    "\n",
    "    def teach(self, X_new, t_new, y_new, **kwargs):\n",
    "        \"\"\"Teaching new instances to the estimator selected bu the query_strategy\n",
    "        \n",
    "        If no `assignment_fc` is added, all selected samples are used\n",
    "        If assignment function is added, only those instances are used, where\n",
    "        $\\hat{T} = T$\n",
    "        \"\"\"\n",
    "        if self.assignment_fc is not None:\n",
    "            X_new, t_new, y_new = self.assignment_fc(\n",
    "                self, X_new, t_new,\n",
    "                y_new, simulated=kwargs[\"simulated\"] if \"simulated\" in kwargs else False)\n",
    "        else:\n",
    "            try:\n",
    "                y_new = np.take_along_axis(y_new, t_new[:, None], axis=1)\n",
    "            except:\n",
    "                pass\n",
    "        self._add_queried_data_class(X_new, t_new.ravel(), y_new.ravel())\n",
    "        self.fit()\n",
    "\n",
    "    def fit(self):\n",
    "        self._update_estimator_values()\n",
    "        self.estimator.fit()\n",
    "        \n",
    "    def predict(self, X=None, **kwargs):\n",
    "        \"\"\"Method for predicting treatment effects within Active Learning\n",
    "        \n",
    "        Default is to predict on the unlabeled pool\"\"\"\n",
    "        if X is None:\n",
    "            raise Exception(\"You need to supply an unlabeled pool of instances (with shape (-1,{}))\".format(self.X_training.shape[1]))\n",
    "        self.preds = self.estimator.predict(X, **kwargs)\n",
    "        return self.preds\n",
    "    \n",
    "    def score(self, preds=None, y_true=None, t_true=None, metric = \"Qini\"):\n",
    "        \"\"\"\n",
    "        Scoring the predictions - either ITE or observed outcomes are needed.\n",
    "        \n",
    "        If observed outcomes are provided, the accompanying treatments are also needed.\n",
    "        \"\"\"\n",
    "        if metric not in [\"Qini\", \"PEHE\", \"Cgains\"]:\n",
    "            raise ValueError(f\"Please use a valid error (PEHE, Qini, Cgains), {metric} is not valid\")\n",
    "        if metric == \"Qini\":\n",
    "            upev = UpliftEval(t_true, y_true, self.preds[0] if preds is None else preds)\n",
    "            self.scores = upev\n",
    "            vscore = self.scores.q1_aqini\n",
    "        if metric == \"PEHE\":\n",
    "            vscore = np.sqrt(np.mean(np.square(preds - y_true)))\n",
    "        if metric == \"Cgains\":\n",
    "            upev = UpliftEval(t_true, y_true, self.preds[0] if preds is None else preds)\n",
    "            self.scores = upev\n",
    "            vscore = self.scores.cgains\n",
    "        return vscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ITEEstimator(BaseEstimator):\n",
    "    \"\"\" Class for building a naive estimator for ITE estimation\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 model: estimator_type = None,\n",
    "                 two_model: bool = False,\n",
    "                 ps: Callable = None,\n",
    "                 **kwargs\n",
    "                ) -> None:\n",
    "        self.model = model\n",
    "        self.two_model = two_model\n",
    "        self.ps_model = ps\n",
    "        \n",
    "    def _fit_ps_model(self):\n",
    "        if self.ps_model is not None:\n",
    "            self.ps_model.fit(self.X_training, self.t_training)\n",
    "\n",
    "    def fit(self,X_training: np.ndarray = None,\n",
    "                 t_training: np.ndarray = None,\n",
    "                 y_training: np.ndarray = None,\n",
    "                 X_test: np.ndarray = None,\n",
    "                 ps_scores: np.ndarray = None):\n",
    "            \n",
    "        if X_training is not None:\n",
    "            self.X_training = X_training\n",
    "            self.y_training = y_training\n",
    "            self.t_training = t_training\n",
    "            self.X_test = X_test\n",
    "        self.N_training = self.X_training.shape[0]\n",
    "        try:\n",
    "            self._fit_ps_model()\n",
    "            ps_scores = self.ps_model.predict_proba(self.X_training)\n",
    "        except:\n",
    "            ps_scores = None\n",
    "            # if \"N_training\" not in self.__dict__:\n",
    "        #     self.N_training = self.X_training.shape[0]\n",
    "        if ps_scores is not None:\n",
    "            X_to_train_on = np.hstack((self.X_training, ps_scores[:,1].reshape((-1, 1))))\n",
    "        else:\n",
    "            X_to_train_on = self.X_training                \n",
    "        if self.two_model:\n",
    "            if hasattr(self, \"m1\") is False:\n",
    "                self.m1 = deepcopy(self.model)\n",
    "            control_ix = np.where(self.t_training == 0)[0]\n",
    "            self.model.fit(X_to_train_on[control_ix,:],\n",
    "                           self.y_training[control_ix])\n",
    "            self.m1.fit(X_to_train_on[-control_ix,:],\n",
    "                        self.y_training[-control_ix])\n",
    "        else:\n",
    "            self.model.fit(np.hstack((X_to_train_on,\n",
    "                                      self.t_training.reshape((self.N_training, -1)))),\n",
    "                           self.y_training)\n",
    "            \n",
    "    def _predict_without_proba(self, model, X, **kwargs):\n",
    "        return model.predict(X,\n",
    "            return_mean = kwargs[\"return_mean\"] if \"return_mean\" in kwargs else True)\n",
    "    \n",
    "    def _fix_dim_pred(self, preds):\n",
    "        pred_length = preds.shape[0]\n",
    "        if preds.shape[1] == 1:\n",
    "            if np.all(preds == 0):\n",
    "                preds = np.hstack((preds, np.ones(pred_length).reshape((-1,1))))\n",
    "            elif np.all(preds == 1): \n",
    "                preds = np.hstack((preds, np.zeros(pred_length).reshape((-1,1))))\n",
    "            preds = preds[:, ]\n",
    "        return preds         \n",
    "    \n",
    "    def predict(self, X=None, **kwargs):\n",
    "        if X is None:\n",
    "            X = self.X_test\n",
    "        if self.ps_model is not None and self.ps_model.coef_ is not None:\n",
    "            pred_ps_scores = self.ps_model.predict_proba(X)[:, 1]\n",
    "            X = np.hstack((X, pred_ps_scores.reshape(-1, 1)))\n",
    "        N_test = X.shape[0]\n",
    "        try:\n",
    "            if self.two_model:\n",
    "                self.y1_preds = self.m1.predict_proba(X)\n",
    "                self.y0_preds = self.model.predict_proba(X)\n",
    "            else:\n",
    "                self.y1_preds = self.model.predict_proba(\n",
    "                                    np.hstack((X,\n",
    "                                    np.ones(N_test).reshape(-1,1))))\n",
    "                self.y0_preds = self.model.predict_proba(\n",
    "                    np.hstack((X,\n",
    "                               np.zeros(N_test).reshape(-1,1))))\n",
    "            self.y1_preds = self._fix_dim_pred( self.y1_preds)\n",
    "            self.y0_preds = self._fix_dim_pred( self.y0_preds)\n",
    "        except AttributeError:\n",
    "            try:\n",
    "                if self.two_model:\n",
    "                    self.y1_preds = self._predict_without_proba(self.m1, X, **kwargs)\n",
    "                    self.y0_preds = self._predict_without_proba(self.model, X, **kwargs)\n",
    "                else: \n",
    "                    self.y1_preds = self._predict_without_proba(self.model,\n",
    "                             np.hstack((X,\n",
    "                             np.ones(N_test).reshape(-1,1))), **kwargs)\n",
    "                    self.y0_preds = self._predict_without_proba(self.model,\n",
    "                        np.hstack((X,\n",
    "                                   np.zeros(N_test).reshape(-1,1))), **kwargs)\n",
    "            except:\n",
    "                raise AttributeError(\"No method found for predicting with the supplied class\")\n",
    "        return self.y1_preds - self.y0_preds, self.y1_preds, self.y0_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.normal(size = 1000).reshape((500,2))\n",
    "t = np.random.binomial(n = 1, p = 0.5, size = 500)\n",
    "y = np.random.binomial(n = 1, p = 1/(1+np.exp(X[:, 1]*2 + t*3)))\n",
    "X_test = np.random.normal(size = 200).reshape((100,2))\n",
    "t_test = np.random.binomial(n = 1, p = 0.5, size = 100)\n",
    "y_test = np.random.binomial(n = 1, p = 1/(1+np.exp(X_test[:, 1]*2 + t_test*3)))\n",
    "a = ITEEstimator(LogisticRegression(solver=\"lbfgs\"), two_model = True, ps=LogisticRegression())\n",
    "a.fit(X, t, y)\n",
    "assert type(a.model) == LogisticRegression  # test assigning a model\n",
    "assert a.X_training.shape  == (500,2)       # test data passing for class\n",
    "assert a.model.intercept_ is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = ITEEstimator(RandomForestClassifier(), X, t, y, X_test, two_model = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def variance_based_assf(classifier, X, t, y, simulated=False):\n",
    "    ite_preds, y1_preds, y0_preds = classifier.predict(X, return_mean=False)\n",
    "    if len(y1_preds.shape) <= 1:\n",
    "            raise ValueError(\"Not possible to calculate variance with dim {}\".format(y1_preds.shape))\n",
    "    prop_score = np.var(y1_preds,axis=1)/(\n",
    "        np.var(y1_preds, axis=1)+np.var(y0_preds,axis=1))\n",
    "    t_assigned = np.random.binomial(1, prop_score)\n",
    "    if simulated:\n",
    "        try:\n",
    "            y = np.take_along_axis(y, t_assigned[:, None], axis=1)\n",
    "            t = t_assigned\n",
    "            usable_units = np.repeat(True, repeats=X.shape[0])\n",
    "        except:\n",
    "            raise ValueError(\"Potential outcomes are needed in a matrix with shape (n,2)\")\n",
    "    else:\n",
    "        usable_units = np.where(t_assigned == t)\n",
    "    return X[usable_units], t[usable_units], y[usable_units]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xbart import XBART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = {\"X_training\":X,\n",
    "     \"y_training\": y,\n",
    "     \"t_training\": t,\n",
    "     \"X_pool\": deepcopy(X_test), \n",
    "     \"y_pool\": deepcopy(y_test),\n",
    "     \"t_pool\": deepcopy(t_test),\n",
    "     \"X_test\": X_test,\n",
    "     \"y_test\": y_test,\n",
    "      \"t_test\": t_test\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8e3ff73fdf97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0masl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mite_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"X_test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mX_sel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_sel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"X_test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0masl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_sel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery_sel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery_sel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mite_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/asbe/asbe/base.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, no_query)\u001b[0m\n\u001b[1;32m    125\u001b[0m         query_idx = self.acquisition_function.select_data(self.estimator,\n\u001b[1;32m    126\u001b[0m                                                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                                                           no_query)\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mquery_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/asbe/asbe/base.py\u001b[0m in \u001b[0;36mselect_data\u001b[0;34m(self, model, dataset, no_query)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"top\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0mquery_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mno_query\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0mX_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"X_pool\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "asl = BaseActiveLearner(estimator = BaseITEEstimator(model = XBART()), \n",
    "                        acquisition_function=BaseAcquisitionFunction(),\n",
    "                        assignment_function=variance_based_assf,\n",
    "                        stopping_function = None,\n",
    "                        dataset=ds)\n",
    "asl.fit()\n",
    "ite_pred = asl.predict(asl.dataset[\"X_test\"])\n",
    "X_sel, query_sel = asl.query(asl.dataset[\"X_test\"])\n",
    "asl.teach(X_sel, t_test[query_sel], y_test[query_sel])\n",
    "assert ite_pred.shape[0] == 100\n",
    "assert X_sel.shape       == (10,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ite_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1005)\n",
    "n_train = 100\n",
    "p       = 5\n",
    "n_pool  = 1000\n",
    "n_test  = 1000\n",
    "n2      = 5\n",
    "X_train = np.random.normal(size = n_train*p).reshape((n_train,p))\n",
    "t_train = np.random.binomial(n = 1, p = 0.5, size = n_train)\n",
    "y_train = np.random.binomial(n = 1, p = 1/(1+np.exp(-1*(X_train[:, 1]*2 + t_train*3))))\n",
    "\n",
    "X_pool = np.random.normal(size = n_pool*p).reshape((n_pool,p))\n",
    "t_pool = np.random.binomial(n = 1, p = 0.5, size = n_pool)\n",
    "y_pool = np.random.binomial(n = 1, p = 1/(1+np.exp(-1*(X_pool[:, 1]*2 + t_pool*3))))\n",
    "\n",
    "X_test = np.random.normal(size = n_test*p).reshape((n_test,p))\n",
    "t_test = np.random.binomial(n = 1, p = 0.5, size = n_test)\n",
    "y_test = np.random.binomial(n = 1, p = 1/(1+np.exp(-1*(X_test[:, 1]*2 + t_test*3))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asl = ASLearner(estimator = ITEEstimator(model = XBART(),two_model=False), \n",
    "         query_strategy=expected_model_change_maximization,\n",
    "         X_training = X_train,\n",
    "         t_training = t_train,\n",
    "         y_training = y_train,\n",
    "         X_pool     = X_pool,\n",
    "         X_test     = X_test,\n",
    "         approx_model=SGDRegressor())\n",
    "asl.fit()\n",
    "p_ite, p_y1, p_y0 = asl.predict(asl.X_test, return_mean=False)\n",
    "print(\"Qini before AL: {}\".format(asl.score(preds=np.mean(p_ite, axis=1),\n",
    "                                            y_true=y_test, t_true=t_test)))\n",
    "qini_vals = []\n",
    "for batch_round in range(21):\n",
    "    X_query, ix = asl.query(asl.X_pool, n2=n2, return_mean=False)\n",
    "    asl.teach(X_query, t_pool[ix], y_pool[ix])\n",
    "    asl.X_pool = np.delete(asl.X_pool,ix, axis=0)\n",
    "    t_pool     = np.delete(t_pool,ix, axis=0) \n",
    "    y_pool     = np.delete(y_pool,ix, axis=0) \n",
    "    p_ite, p_y1, p_y0 = asl.predict(asl.X_test, return_mean=False)\n",
    "    qini_vals.append(asl.score(preds=np.mean(p_ite, axis=1), y_true=y_test, t_true=t_test))\n",
    "    if batch_round % 5 == 0:\n",
    "        print(\"Qini after round {} of AL: {}\".format(batch_round,qini_vals[batch_round]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
