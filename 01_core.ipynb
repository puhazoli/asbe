{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASBE - Automatic Stopping for Batch Experiments\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/dask/dataframe/utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "from asbe.base import *\n",
    "from modAL.models.base import BaseLearner\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, RegressorMixin\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from typing import Union, Optional, Callable\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RandomAcquisitionFunction(BaseAcquisitionFunction):\n",
    "    def calculate_metrics(self, model, dataset):\n",
    "        ixs = np.arange(dataset[\"X_pool\"].shape[0])\n",
    "        np.random.shuffle(ixs)\n",
    "        return ixs\n",
    "    \n",
    "class UncertaintyAcquisitionFunction(BaseAcquisitionFunction):\n",
    "    def calculate_metrics(self, model, dataset):\n",
    "        preds = model.predict(X = dataset[\"X_pool\"])\n",
    "        if type(preds) is tuple:\n",
    "            p, pred_var = preds[0], preds[1]\n",
    "        try:\n",
    "            if preds.shape[1] <= 1:\n",
    "                raise Exception(\"Not possible to calculate uncertainty when dimensions <=1\")\n",
    "            pred_var = np.var(preds, axis = 1)\n",
    "        except IndexError:\n",
    "            raise Exception(\"Not possible to calculate uncertainty when dimensions <=1\")\n",
    "        return pred_var\n",
    "    \n",
    "class TypeSAcquistionFunction(BaseAcquisitionFunction):\n",
    "    def calculate_metrics(self, model, dataset):\n",
    "        preds = model.predict(X=dataset[\"X_pool\"])\n",
    "        if preds.shape[0] <= 1:\n",
    "            raise Exception(\"Type S error needs multiple values per prediction\")\n",
    "        prob_s = np.sum(preds > 0, axis=1)/preds.shape[1]\n",
    "        prob_s_sel = np.where(prob_s > 0.5, 1-prob_s, prob_s) + .0001\n",
    "        return prob_s_sel\n",
    "        \n",
    "class EMCMAcquisitionFunction(BaseAcquisitionFunction):\n",
    "    def __init__(self, no_query = 1,\n",
    "                 method = \"top\",\n",
    "                 name = \"emcm\",\n",
    "                 approx_model = SGDRegressor(),\n",
    "                 B = 100,\n",
    "                 K = 5,\n",
    "                 threshold = 0):\n",
    "        super().__init__(no_query, method, name)\n",
    "        self.approx_model = approx_model\n",
    "        self.B = B\n",
    "        self.K = K\n",
    "        self.threshold = threshold\n",
    "        self.model_change = []\n",
    "        \n",
    "    def calculate_metrics(self, model, dataset, **kwargs):\n",
    "        ite_train_preds = model.predict(X = dataset[\"X_training\"])\n",
    "        ite_pool_preds = model.predict(X = dataset[\"X_pool\"])\n",
    "        if ite_train_preds.shape[1] < 1:\n",
    "            raise ValueError(\"The treatment effect does not have uncertainty around it - \\\n",
    "                         consider using a different estimator\")\n",
    "        sc = StandardScaler()\n",
    "        X_scaled = sc.fit_transform(dataset[\"X_training\"])\n",
    "        # Fit approx model\n",
    "        # calc type-s error\n",
    "        train_type_s_prob_1 = np.sum(ite_train_preds > 0, axis=1)/ite_train_preds.shape[1]\n",
    "        train_type_s = np.where(train_type_s_prob_1 > 0.5, 1-train_type_s_prob_1, train_type_s_prob_1) + .0001\n",
    "        pool_type_s_prob_1 = np.sum(ite_pool_preds > 0, axis=1)/ite_pool_preds.shape[1]\n",
    "        pool_type_s = np.where(pool_type_s_prob_1 > 0.5, 1-pool_type_s_prob_1, pool_type_s_prob_1) + .0001\n",
    "        self.approx_model.fit(\n",
    "            X = X_scaled,\n",
    "            y = np.mean(ite_train_preds, axis=1),\n",
    "            sample_weight = 5*train_type_s)\n",
    "        # Using list as it is faster than appending to np array\n",
    "        query_idx = []\n",
    "        # Using a loop for the combinatorial opt. part\n",
    "        for ix in range(self.no_query):\n",
    "            if self.no_query > (dataset[\"X_pool\"].shape[0]):\n",
    "                raise IndexError(\"Too many samples are queried from the pool ($n_2 > ||X_pool||$)\")\n",
    "            # Select randomly from X_pool\n",
    "            prob_sampling = np.ones((dataset[\"X_pool\"].shape[0]))/(\n",
    "                dataset[\"X_pool\"].shape[0]-len(query_idx))\n",
    "            # Set the probability of already selected samples to 0\n",
    "            if ix > 0:\n",
    "                prob_sampling[query_idx] = 0\n",
    "            # B = 100 by default, can be modified by kwargs\n",
    "            considered_ixes = np.random.choice(dataset[\"X_pool\"].shape[0],\n",
    "                                             size = self.B,\n",
    "                                             replace=False, \n",
    "                                             p=prob_sampling)\n",
    "            # Calculate the grads for all  \n",
    "            grads = np.array([])\n",
    "            for considered_ix in considered_ixes:\n",
    "                new_X = sc.transform(dataset[\"X_pool\"][considered_ix].reshape(1, -1))\n",
    "                app_predicted_ite = self.approx_model.predict(new_X)\n",
    "                # bootstrapping accroding to eq. 11 of Cai and Zhang\n",
    "                true_ite = np.random.choice(ite_pool_preds[considered_ix],\n",
    "                                            size=self.K)\n",
    "                grad = np.sum(np.abs(np.kron((true_ite - app_predicted_ite),new_X)))\n",
    "                grads = np.append(grads, grad)\n",
    "            if np.max(grads) < self.threshold:\n",
    "                break\n",
    "            self.model_change = np.append(self.model_change,np.max(grads))\n",
    "            query_idx.append(int(considered_ixes[np.argmax(grads)]))\n",
    "            self.approx_model.partial_fit(\n",
    "                sc.transform(dataset[\"X_pool\"][int(query_idx[ix])].reshape(1, -1)),\n",
    "                np.random.choice(ite_pool_preds[int(query_idx[ix])], size=1),\n",
    "                sample_weight = np.array(pool_type_s[int(query_idx[ix])]).ravel())\n",
    "        out = np.zeros(dataset[\"X_pool\"].shape[0])\n",
    "        out[query_idx] = 1\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RandomAssignmentFunction(BaseAssignmentFunction):\n",
    "    def __init__(self, base_selection = 0, p = .5):\n",
    "        super().__init__(base_selection)\n",
    "        self.p = p\n",
    "        \n",
    "    def select_treatment(self, model, dataset, query_idx):\n",
    "        return np.random.binomial(1, self.p, (query_idx.shape[0],))\n",
    "    \n",
    "class MajorityAssignmentFunction(BaseAssignmentFunction):\n",
    "    def select_treatment(self, model, dataset, query_idx):\n",
    "        if sum(dataset[\"t_training\"]) >= dataset[\"t_training\"].shape[0]/2:\n",
    "            out = np.zeros((query_idx.shape[0],))\n",
    "        else:\n",
    "            out = np.ones((query_idx.shape[0],))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch_sampling(classifier, X_pool, n2, **kwargs):\n",
    "    \"Randomly sample a batch from a pool of unlabaled samples\"\n",
    "    n_samples = X_pool.shape[0]\n",
    "    query_idx = np.random.choice(range(n_samples), size=n2,replace=False)\n",
    "    return X_pool[query_idx], query_idx\n",
    "\n",
    "def uncertainty_batch_sampling(classifier, X_pool, n2, **kwargs):\n",
    "    \"Select the top $n_2$ most uncertain units\"\n",
    "    ite_preds, y1_preds, y_preds = classifier.predict(X_pool, **kwargs)\n",
    "    # Calculate variance based on predicted\n",
    "    if y1_preds.shape[0] <= 1 or \\\n",
    "    len(y1_preds.shape) <= 1:\n",
    "            raise Exception(\"Not possible to calculate uncertainty when dimensions <=1 \")\n",
    "    ite_vars = np.var(classifier.estimator.y1_preds - classifier.estimator.y0_preds, axis=1)\n",
    "    query_idx = np.argsort(ite_vars)[-n2:][::-1]\n",
    "        \n",
    "    return X_pool[query_idx], query_idx\n",
    "\n",
    "def type_s_batch_sampling(classifier, X_pool, n2, **kwargs):\n",
    "    \"Select highest type-s\"\n",
    "    ite_preds, y1_preds, y_preds = classifier.predict(X_pool, **kwargs)\n",
    "    prob_s = np.sum(ite_preds > 0, axis=1)/ite_preds.shape[1]\n",
    "    prob_s_sel = np.where(prob_s > 0.5, 1-prob_s, prob_s) + .0001\n",
    "    query_idx = np.argsort(prob_s_sel)[-n2:][::-1]\n",
    "    \n",
    "    return X_pool[query_idx], query_idx\n",
    "   \n",
    "\n",
    "def expected_model_change_maximization(classifier, X_pool, n2, **kwargs):\n",
    "    \"\"\"\n",
    "    Implementation of EMCM for ITE - using a surrogate SGD model.\n",
    "    \"\"\"\n",
    "    # Get mean of the trained prediction\n",
    "    ite_train_preds, y1_train_preds, y0_train_preds = \\\n",
    "        classifier.predict(classifier.X_training, **kwargs)\n",
    "    if ite_train_preds.shape[1] < 1:\n",
    "        raise ValueError(\"The treatment effect does not have uncertainty around it - \\\n",
    "                         consider using a different estimator\")\n",
    "    # Get mean of predicted ITE\n",
    "    ite_pool_preds, y1_pool_preds, y0_pool_preds = \\\n",
    "        classifier.predict(X_pool, **kwargs)\n",
    "    # Then scale the data so sgd works the best\n",
    "    sc = StandardScaler()\n",
    "    X_scaled = sc.fit_transform(classifier.X_training)\n",
    "    # Fit approx model\n",
    "    # calc type-s error\n",
    "    train_type_s_prob_1 = np.sum(ite_train_preds > 0, axis=1)/ite_train_preds.shape[1]\n",
    "    train_type_s = np.where(train_type_s_prob_1 > 0.5, 1-train_type_s_prob_1, train_type_s_prob_1) + .0001\n",
    "    pool_type_s_prob_1 = np.sum(ite_pool_preds > 0, axis=1)/ite_pool_preds.shape[1]\n",
    "    pool_type_s = np.where(pool_type_s_prob_1 > 0.5, 1-pool_type_s_prob_1, pool_type_s_prob_1) + .0001\n",
    "    classifier.approx_model.fit(\n",
    "        X = X_scaled,\n",
    "        y = np.mean(ite_train_preds, axis=1),\n",
    "        sample_weight = 5*train_type_s)\n",
    "    # Using list as it is faster than appending to np array\n",
    "    query_idx = []\n",
    "    # Using a loop for the combinatorial opt. part\n",
    "    for ix in range(n2):\n",
    "        if n2 > (X_pool.shape[0]):\n",
    "            raise IndexError(\"Too many samples are queried from the pool ($n_2 > ||X_pool||$)\")\n",
    "        # Select randomly from X_pool\n",
    "        prob_sampling = np.ones((X_pool.shape[0]))/(X_pool.shape[0]-len(query_idx))\n",
    "        # Set the probability of already selected samples to 0\n",
    "        if ix > 0:\n",
    "            prob_sampling[query_idx] = 0\n",
    "        # B = 100 by default, can be modified by kwargs\n",
    "        considered_ixes = np.random.choice(X_pool.shape[0],\n",
    "                                         size = kwargs[\"B\"] if \"B\" in kwargs else 100,\n",
    "                                         replace=False, \n",
    "                                         p=prob_sampling)\n",
    "        # Calculate the grads for all the \n",
    "        grads = np.array([])\n",
    "        for considered_ix in considered_ixes:\n",
    "            new_X = sc.transform(X_pool[considered_ix].reshape(1, -1))\n",
    "            app_predicted_ite = classifier.approx_model.predict(new_X)\n",
    "            # bootstrapping accroding to eq. 11 of Cai and Zhang\n",
    "            true_ite = np.random.choice(ite_pool_preds[considered_ix],\n",
    "                                        size=kwargs[\"K\"] if \"K\" in kwargs else 5)\n",
    "            grad = np.sum(np.abs(np.kron((true_ite - app_predicted_ite),new_X)))\n",
    "            grads = np.append(grads, grad)\n",
    "        if np.max(grads) < kwargs[\"threshold\"] if \"threshold\" in kwargs else 0:\n",
    "            break\n",
    "        classifier.model_change = np.append(classifier.model_change,np.max(grads))\n",
    "        query_idx.append(int(considered_ixes[np.argmax(grads)]))\n",
    "        classifier.approx_model.partial_fit(\n",
    "            sc.transform(X_pool[int(query_idx[ix])].reshape(1, -1)),\n",
    "            np.random.choice(ite_pool_preds[int(query_idx[ix])], size=1),\n",
    "            sample_weight = np.array(pool_type_s[int(query_idx[ix])]).ravel())\n",
    "        \n",
    "    return X_pool[query_idx], query_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %nbdev_export\n",
    "# def variance_assignment(classifier, X_pool, n2, **kwargs):\n",
    "#     \"\"\"Function to assign treatment or control based on the variance of the cf\n",
    "#     \"\"\"\n",
    "#     ite_pool_preds, y1_pool_preds, y0_pool_preds = \\\n",
    "#         classifier.predict(X_pool, **kwargs)\n",
    "#     var_y1 = np.var(y1_pool_preds, axis=1)\n",
    "#     var_y0 = np.var(y0_pool_preds, axis=1)\n",
    "#     prob_of_treatment = var_y1/(var_y1+var_y0)\n",
    "#     drawn_treatment = np.random.binomial(1, prob_of_treatment)\n",
    "#     return drawn_treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_type = ClassifierMixin\n",
    "class ASLearner(BaseLearner):\n",
    "    \"\"\"A(ctively)S(topping)Learner class for automatic stopping in batch-mode AL\"\"\"\n",
    "    def __init__(self,\n",
    "                 estimator: estimator_type=None, \n",
    "                 query_strategy=None,\n",
    "                 assignment_fc=None,\n",
    "                 X_training: np.ndarray = None,\n",
    "                 t_training: np.ndarray = None,\n",
    "                 y_training: np.ndarray = None,\n",
    "                 X_pool: np.ndarray = None,\n",
    "                 X_test: np.ndarray = None,\n",
    "                 approx_model: RegressorMixin = None\n",
    "                ) -> None:\n",
    "        self.estimator = estimator\n",
    "        self.query_strategy = query_strategy\n",
    "        self.assignment_fc = assignment_fc\n",
    "        self.X_training = X_training\n",
    "        self.y_training = y_training\n",
    "        self.t_training = t_training\n",
    "        self.X_pool     = X_pool\n",
    "        self.X_test     = X_test\n",
    "        self.approx_model = approx_model\n",
    "        self.model_change = np.array([])\n",
    "        \n",
    "    def _add_queried_data_class(self, X, t, y):\n",
    "        self.X_training = np.vstack((self.X_training, X))\n",
    "        self.t_training = np.concatenate((self.t_training, t))\n",
    "        self.y_training = np.concatenate((self.y_training, y))\n",
    "    \n",
    "    def _update_estimator_values(self):\n",
    "        self.estimator.__dict__.update(X_training = self.X_training,\n",
    "                               y_training  =        self.y_training,\n",
    "                               t_training  =        self.t_training,\n",
    "                               X_test      =        self.X_test)\n",
    "\n",
    "    def teach(self, X_new, t_new, y_new, **kwargs):\n",
    "        \"\"\"Teaching new instances to the estimator selected bu the query_strategy\n",
    "        \n",
    "        If no `assignment_fc` is added, all selected samples are used\n",
    "        If assignment function is added, only those instances are used, where\n",
    "        $\\hat{T} = T$\n",
    "        \"\"\"\n",
    "        if self.assignment_fc is not None:\n",
    "            X_new, t_new, y_new = self.assignment_fc(\n",
    "                self, X_new, t_new,\n",
    "                y_new, simulated=kwargs[\"simulated\"] if \"simulated\" in kwargs else False)\n",
    "        else:\n",
    "            try:\n",
    "                y_new = np.take_along_axis(y_new, t_new[:, None], axis=1)\n",
    "            except:\n",
    "                pass\n",
    "        self._add_queried_data_class(X_new, t_new.ravel(), y_new.ravel())\n",
    "        self.fit()\n",
    "\n",
    "    def fit(self):\n",
    "        self._update_estimator_values()\n",
    "        self.estimator.fit()\n",
    "        \n",
    "    def predict(self, X=None, **kwargs):\n",
    "        \"\"\"Method for predicting treatment effects within Active Learning\n",
    "        \n",
    "        Default is to predict on the unlabeled pool\"\"\"\n",
    "        if X is None:\n",
    "            raise Exception(\"You need to supply an unlabeled pool of instances (with shape (-1,{}))\".format(self.X_training.shape[1]))\n",
    "        self.preds = self.estimator.predict(X, **kwargs)\n",
    "        return self.preds\n",
    "    \n",
    "    def score(self, preds=None, y_true=None, t_true=None, metric = \"Qini\"):\n",
    "        \"\"\"\n",
    "        Scoring the predictions - either ITE or observed outcomes are needed.\n",
    "        \n",
    "        If observed outcomes are provided, the accompanying treatments are also needed.\n",
    "        \"\"\"\n",
    "        if metric not in [\"Qini\", \"PEHE\", \"Cgains\"]:\n",
    "            raise ValueError(f\"Please use a valid error (PEHE, Qini, Cgains), {metric} is not valid\")\n",
    "        if metric == \"Qini\":\n",
    "            upev = UpliftEval(t_true, y_true, self.preds[0] if preds is None else preds)\n",
    "            self.scores = upev\n",
    "            vscore = self.scores.q1_aqini\n",
    "        if metric == \"PEHE\":\n",
    "            vscore = np.sqrt(np.mean(np.square(preds - y_true)))\n",
    "        if metric == \"Cgains\":\n",
    "            upev = UpliftEval(t_true, y_true, self.preds[0] if preds is None else preds)\n",
    "            self.scores = upev\n",
    "            vscore = self.scores.cgains\n",
    "        return vscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ITEEstimator(BaseEstimator):\n",
    "    \"\"\" Class for building a naive estimator for ITE estimation\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 model: estimator_type = None,\n",
    "                 two_model: bool = False,\n",
    "                 ps: Callable = None,\n",
    "                 **kwargs\n",
    "                ) -> None:\n",
    "        self.model = model\n",
    "        self.two_model = two_model\n",
    "        self.ps_model = ps\n",
    "        \n",
    "    def _fit_ps_model(self):\n",
    "        if self.ps_model is not None:\n",
    "            self.ps_model.fit(self.X_training, self.t_training)\n",
    "\n",
    "    def fit(self,X_training: np.ndarray = None,\n",
    "                 t_training: np.ndarray = None,\n",
    "                 y_training: np.ndarray = None,\n",
    "                 X_test: np.ndarray = None,\n",
    "                 ps_scores: np.ndarray = None):\n",
    "            \n",
    "        if X_training is not None:\n",
    "            self.X_training = X_training\n",
    "            self.y_training = y_training\n",
    "            self.t_training = t_training\n",
    "            self.X_test = X_test\n",
    "        self.N_training = self.X_training.shape[0]\n",
    "        try:\n",
    "            self._fit_ps_model()\n",
    "            ps_scores = self.ps_model.predict_proba(self.X_training)\n",
    "        except:\n",
    "            ps_scores = None\n",
    "            # if \"N_training\" not in self.__dict__:\n",
    "        #     self.N_training = self.X_training.shape[0]\n",
    "        if ps_scores is not None:\n",
    "            X_to_train_on = np.hstack((self.X_training, ps_scores[:,1].reshape((-1, 1))))\n",
    "        else:\n",
    "            X_to_train_on = self.X_training                \n",
    "        if self.two_model:\n",
    "            if hasattr(self, \"m1\") is False:\n",
    "                self.m1 = deepcopy(self.model)\n",
    "            control_ix = np.where(self.t_training == 0)[0]\n",
    "            self.model.fit(X_to_train_on[control_ix,:],\n",
    "                           self.y_training[control_ix])\n",
    "            self.m1.fit(X_to_train_on[-control_ix,:],\n",
    "                        self.y_training[-control_ix])\n",
    "        else:\n",
    "            self.model.fit(np.hstack((X_to_train_on,\n",
    "                                      self.t_training.reshape((self.N_training, -1)))),\n",
    "                           self.y_training)\n",
    "            \n",
    "    def _predict_without_proba(self, model, X, **kwargs):\n",
    "        return model.predict(X,\n",
    "            return_mean = kwargs[\"return_mean\"] if \"return_mean\" in kwargs else True)\n",
    "    \n",
    "    def _fix_dim_pred(self, preds):\n",
    "        pred_length = preds.shape[0]\n",
    "        if preds.shape[1] == 1:\n",
    "            if np.all(preds == 0):\n",
    "                preds = np.hstack((preds, np.ones(pred_length).reshape((-1,1))))\n",
    "            elif np.all(preds == 1): \n",
    "                preds = np.hstack((preds, np.zeros(pred_length).reshape((-1,1))))\n",
    "            preds = preds[:, ]\n",
    "        return preds         \n",
    "    \n",
    "    def predict(self, X=None, **kwargs):\n",
    "        if X is None:\n",
    "            X = self.X_test\n",
    "        if self.ps_model is not None and self.ps_model.coef_ is not None:\n",
    "            pred_ps_scores = self.ps_model.predict_proba(X)[:, 1]\n",
    "            X = np.hstack((X, pred_ps_scores.reshape(-1, 1)))\n",
    "        N_test = X.shape[0]\n",
    "        try:\n",
    "            if self.two_model:\n",
    "                self.y1_preds = self.m1.predict_proba(X)\n",
    "                self.y0_preds = self.model.predict_proba(X)\n",
    "            else:\n",
    "                self.y1_preds = self.model.predict_proba(\n",
    "                                    np.hstack((X,\n",
    "                                    np.ones(N_test).reshape(-1,1))))\n",
    "                self.y0_preds = self.model.predict_proba(\n",
    "                    np.hstack((X,\n",
    "                               np.zeros(N_test).reshape(-1,1))))\n",
    "            self.y1_preds = self._fix_dim_pred( self.y1_preds)\n",
    "            self.y0_preds = self._fix_dim_pred( self.y0_preds)\n",
    "        except AttributeError:\n",
    "            try:\n",
    "                if self.two_model:\n",
    "                    self.y1_preds = self._predict_without_proba(self.m1, X, **kwargs)\n",
    "                    self.y0_preds = self._predict_without_proba(self.model, X, **kwargs)\n",
    "                else: \n",
    "                    self.y1_preds = self._predict_without_proba(self.model,\n",
    "                             np.hstack((X,\n",
    "                             np.ones(N_test).reshape(-1,1))), **kwargs)\n",
    "                    self.y0_preds = self._predict_without_proba(self.model,\n",
    "                        np.hstack((X,\n",
    "                                   np.zeros(N_test).reshape(-1,1))), **kwargs)\n",
    "            except:\n",
    "                raise AttributeError(\"No method found for predicting with the supplied class\")\n",
    "        return self.y1_preds - self.y0_preds, self.y1_preds, self.y0_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.normal(size = 1000).reshape((500,2))\n",
    "t = np.random.binomial(n = 1, p = 0.5, size = 500)\n",
    "y = np.random.binomial(n = 1, p = 1/(1+np.exp(X[:, 1]*2 + t*3)))\n",
    "X_test = np.random.normal(size = 200).reshape((100,2))\n",
    "t_test = np.random.binomial(n = 1, p = 0.5, size = 100)\n",
    "y_test = np.random.binomial(n = 1, p = 1/(1+np.exp(X_test[:, 1]*2 + t_test*3)))\n",
    "a = ITEEstimator(LogisticRegression(solver=\"lbfgs\"), two_model = True, ps=LogisticRegression())\n",
    "a.fit(X, t, y)\n",
    "assert type(a.model) == LogisticRegression  # test assigning a model\n",
    "assert a.X_training.shape  == (500,2)       # test data passing for class\n",
    "assert a.model.intercept_ is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = ITEEstimator(RandomForestClassifier(), X, t, y, X_test, two_model = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_based_assf(classifier, X, t, y, simulated=False):\n",
    "    ite_preds, y1_preds, y0_preds = classifier.predict(X, return_mean=False)\n",
    "    if len(y1_preds.shape) <= 1:\n",
    "            raise ValueError(\"Not possible to calculate variance with dim {}\".format(y1_preds.shape))\n",
    "    prop_score = np.var(y1_preds,axis=1)/(\n",
    "        np.var(y1_preds, axis=1)+np.var(y0_preds,axis=1))\n",
    "    t_assigned = np.random.binomial(1, prop_score)\n",
    "    if simulated:\n",
    "        try:\n",
    "            y = np.take_along_axis(y, t_assigned[:, None], axis=1)\n",
    "            t = t_assigned\n",
    "            usable_units = np.repeat(True, repeats=X.shape[0])\n",
    "        except:\n",
    "            raise ValueError(\"Potential outcomes are needed in a matrix with shape (n,2)\")\n",
    "    else:\n",
    "        usable_units = np.where(t_assigned == t)\n",
    "    return X[usable_units], t[usable_units], y[usable_units]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xbart import XBART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = {\"X_training\":X,\n",
    "     \"y_training\": y,\n",
    "     \"t_training\": t,\n",
    "     \"X_pool\": deepcopy(X_test), \n",
    "     \"y_pool\": deepcopy(y_test),\n",
    "     \"t_pool\": deepcopy(t_test),\n",
    "     \"X_test\": X_test,\n",
    "     \"y_test\": y_test,\n",
    "      \"t_test\": t_test\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asl = BaseActiveLearner(estimator = BaseITEEstimator(model = XBART()), \n",
    "                        acquisition_function=BaseAcquisitionFunction(),\n",
    "                        assignment_function=RandomAssignmentFunction(),\n",
    "                        stopping_function = None,\n",
    "                        dataset=ds)\n",
    "asl.fit()\n",
    "ite_pred = asl.predict(asl.dataset[\"X_test\"])\n",
    "X_sel, query_idx = asl.query(no_query=10)\n",
    "asl.teach(query_idx)\n",
    "assert ite_pred.shape[0] == 100\n",
    "assert X_sel.shape       == (10,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.10910279,  0.20880014,  0.02695439,  0.2349721 ,  0.02966905,\n",
       "        0.28290284,  0.28423018,  0.69078027,  0.3857181 ,  0.28828982,\n",
       "        0.69182544,  0.10114306,  0.70870296,  0.41142608,  0.02627783,\n",
       "        0.34047846,  0.15719802,  0.16727003,  0.03141195,  0.20359983,\n",
       "        0.05823517, -0.03074449,  0.29196844,  0.13076063,  0.40661186,\n",
       "        0.18932241,  0.12669815,  0.71879336,  0.11180911,  0.79230938,\n",
       "        0.03015167,  0.11364724,  0.36405992,  0.77812404,  0.21885089,\n",
       "        0.05818353,  0.03817527,  0.09336581,  0.02667948,  0.31917465,\n",
       "        0.73651403,  0.34178272,  0.32608853,  0.24941971,  0.70709352,\n",
       "        0.01110805,  0.55374941,  0.25259113,  0.54402689,  0.82364285,\n",
       "        0.15378244,  0.2124034 ,  0.63054947,  0.21489512,  0.09897677,\n",
       "        0.52283044,  0.31080237,  0.38039005,  0.03015167,  0.70172861,\n",
       "        0.65572218,  0.20131309,  0.28696358,  0.80072869,  0.23556386,\n",
       "        0.6657533 ,  0.33210501, -0.0082054 ,  0.63546017,  0.16275714,\n",
       "        0.06796297,  0.10686679,  0.24525787,  0.84789941,  0.40143024,\n",
       "        0.0998023 ,  0.21602979,  0.70841434,  0.156616  ,  0.27472847,\n",
       "        0.33129712,  0.2823807 ,  0.38400664,  0.36320858,  0.89988277,\n",
       "        0.13948592,  0.85341413,  0.39378793, -0.03566613,  0.67783319,\n",
       "        0.33017345,  0.12218811,  0.62584454,  0.07191278,  0.05943454,\n",
       "        0.60311686, -0.02355262,  0.65331009,  0.76877034,  0.15406109])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ite_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1005)\n",
    "n_train = 100\n",
    "p       = 5\n",
    "n_pool  = 1000\n",
    "n_test  = 1000\n",
    "n2      = 5\n",
    "X_train = np.random.normal(size = n_train*p).reshape((n_train,p))\n",
    "t_train = np.random.binomial(n = 1, p = 0.5, size = n_train)\n",
    "y_train = np.random.binomial(n = 1, p = 1/(1+np.exp(-1*(X_train[:, 1]*2 + t_train*3))))\n",
    "\n",
    "X_pool = np.random.normal(size = n_pool*p).reshape((n_pool,p))\n",
    "t_pool = np.random.binomial(n = 1, p = 0.5, size = n_pool)\n",
    "y_pool = np.random.binomial(n = 1, p = 1/(1+np.exp(-1*(X_pool[:, 1]*2 + t_pool*3))))\n",
    "\n",
    "X_test = np.random.normal(size = n_test*p).reshape((n_test,p))\n",
    "t_test = np.random.binomial(n = 1, p = 0.5, size = n_test)\n",
    "y_test = np.random.binomial(n = 1, p = 1/(1+np.exp(-1*(X_test[:, 1]*2 + t_test*3))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qini before AL: 0.09689246936275164\n",
      "Qini after round 0 of AL: 0.09519354864855538\n",
      "Qini after round 5 of AL: 0.1140321559970714\n",
      "Qini after round 10 of AL: 0.10550342570068655\n",
      "Qini after round 15 of AL: 0.1101196419002971\n",
      "Qini after round 20 of AL: 0.11895157973580262\n"
     ]
    }
   ],
   "source": [
    "asl = ASLearner(estimator = ITEEstimator(model = XBART(),two_model=False), \n",
    "         query_strategy=expected_model_change_maximization,\n",
    "         X_training = X_train,\n",
    "         t_training = t_train,\n",
    "         y_training = y_train,\n",
    "         X_pool     = X_pool,\n",
    "         X_test     = X_test,\n",
    "         approx_model=SGDRegressor())\n",
    "asl.fit()\n",
    "p_ite, p_y1, p_y0 = asl.predict(asl.X_test, return_mean=False)\n",
    "print(\"Qini before AL: {}\".format(asl.score(preds=np.mean(p_ite, axis=1),\n",
    "                                            y_true=y_test, t_true=t_test)))\n",
    "qini_vals = []\n",
    "for batch_round in range(21):\n",
    "    X_query, ix = asl.query(asl.X_pool, n2=n2, return_mean=False)\n",
    "    asl.teach(X_query, t_pool[ix], y_pool[ix])\n",
    "    asl.X_pool = np.delete(asl.X_pool,ix, axis=0)\n",
    "    t_pool     = np.delete(t_pool,ix, axis=0) \n",
    "    y_pool     = np.delete(y_pool,ix, axis=0) \n",
    "    p_ite, p_y1, p_y0 = asl.predict(asl.X_test, return_mean=False)\n",
    "    qini_vals.append(asl.score(preds=np.mean(p_ite, axis=1), y_true=y_test, t_true=t_test))\n",
    "    if batch_round % 5 == 0:\n",
    "        print(\"Qini after round {} of AL: {}\".format(batch_round,qini_vals[batch_round]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
