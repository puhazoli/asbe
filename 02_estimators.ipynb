{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: estimators.html\n",
    "title: Treatment effect estimators\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pymc_env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "#| output: false\n",
    "#| output: false\n",
    "from asbe.base import *\n",
    "from econml.dml import CausalForestDML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "import econml\n",
    "import sklift\n",
    "# import causalml\n",
    "# import pymc as pm \n",
    "# import pymc_bart as pmb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "class CausalForestEstimator(BaseITEEstimator):\n",
    "    def fit(self, **kwargs):\n",
    "        if self.model is None:\n",
    "            self.model = CausalForestDML()\n",
    "        self.model.fit(Y=kwargs[\"y_training\"],\n",
    "                       T=kwargs[\"t_training\"],\n",
    "                       X=kwargs[\"X_training\"])\n",
    "\n",
    "    def predict(self, **kwargs):\n",
    "        if 'return_counterfactuals' in kwargs:\n",
    "            raise ValueError(\"Causal Forest does not support counterfactual predictions out of the box\")\n",
    "        preds = self.model.effect_inference(kwargs[\"X\"])\n",
    "        if \"return_mean\" in kwargs:\n",
    "            out = preds.pred\n",
    "        else:\n",
    "            out = (preds.pred, preds.var)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OPENBTITEEstimator(BaseITEEstimator):\n",
    "    \"\"\"Modified ITE estimator for OPENBT\n",
    "\n",
    "    The predictions are transposed so the uncertainty sampler can calculate uncertianty easily\"\"\"\n",
    "    def predict(self, **kwargs):\n",
    "        X = kwargs[\"X\"]\n",
    "        if self.ps_model is not None:\n",
    "            ps_scores = self.ps_model.predict_proba(X)\n",
    "            X = np.hstack((X, ps_scores[:,1].reshape((-1, 1))))\n",
    "        X0 = np.concatenate((X,\n",
    "                             np.zeros(X.shape[0]).reshape((-1,1))),axis=1)\n",
    "        X1 = np.concatenate((X,\n",
    "                             np.ones(X.shape[0]).reshape((-1,1))),axis=1)\n",
    "        preds0 = self.model.predict(X0)\n",
    "        preds1 = self.model.predict(X1)\n",
    "        if \"return_mean\" in kwargs:\n",
    "            if kwargs[\"return_mean\"]:\n",
    "                out = preds1[\"mmean\"] - preds0[\"mmean\"]\n",
    "        else:\n",
    "            out = preds1[\"mdraws\"].T - preds0[\"mdraws\"].T\n",
    "        if \"return_per_cf\" in kwargs:\n",
    "            if kwargs[\"return_per_cf\"]:\n",
    "                return {\"pred1\": preds1[\"mdraws\"].T , \"pred0\":preds0[\"mdraws\"].T}\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no-export \n",
    "class CEVAEEstimator(BaseITEEstimator):\n",
    "    def fit(self, **kwargs):\n",
    "        if self.model is None:\n",
    "            self.model = CEVAE()\n",
    "        self.model.fit(kwargs[\"X_training\"], \n",
    "                       kwargs[\"t_training\"], \n",
    "                       y=kwargs[\"y_training\"])\n",
    "        \n",
    "    def predict(self, **kwargs):\n",
    "        return self.model.predict(X = kwargs[\"X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GPEstimator(BaseITEEstimator):\n",
    "    def predict(self, **kwargs):\n",
    "        if 'return_mean' in kwargs:\n",
    "            pred0 = self.model.predict(kwargs[\"X\"])\n",
    "            pred1 = self.m1.predict(kwargs[\"X\"])\n",
    "            ite = pred1 - pred0\n",
    "        else:\n",
    "            draws0 = self.model.sample_y(kwargs[\"X\"], n_samples=100)\n",
    "            draws1 = self.m1.sample_y(kwargs[\"X\"], n_samples=100)\n",
    "            ite = draws1 - draws0\n",
    "        return ite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no-export\n",
    "class BLREstimator(BaseITEEstimator):\n",
    "    def fit(self, **kwargs):\n",
    "        with pm.Model() as self.model:\n",
    "            # https://juanitorduz.github.io/glm_pymc3/\n",
    "            family = pm.glm.families.Normal()\n",
    "            data = pm.Data(\"data\", kwargs[\"X_training\"])\n",
    "            labels = [\"x\"+str(i) for i in range(kwargs[\"X_training\"].shape[1])]\n",
    "            glm.GLM(y=kwargs[\"y_training\"], x = data, family=family, labels=labels)\n",
    "            self.trace = sample(3000, cores=2) \n",
    "            \n",
    "    def predict(self, **kwargs):\n",
    "        X0 = np.concatenate((kwargs[\"X\"],\n",
    "                             np.zeros(kwargs[\"X\"].shape[0]).reshape((-1,1))),axis=1)\n",
    "        X1 = np.concatenate((kwargs[\"X\"],\n",
    "                             np.ones(kwargs[\"X\"].shape[0]).reshape((-1,1))),axis=1)\n",
    "        pm.set_data({\"data\": X1}, model=self.model)\n",
    "        p1 = pm.sample_posterior_predictive(self.trace, model=self.model)\n",
    "        pm.set_data({\"data\": X0}, model=self.model)\n",
    "        p0 = pm.sample_posterior_predictive(self.trace, model=self.model)\n",
    "        ite = p1[\"y\"] - p0[\"y\"]\n",
    "        if 'return_mean' in kwargs:\n",
    "            out = ite.mean(axis=0)\n",
    "        else:\n",
    "            out = ite.T\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SKLiftEstimator(BaseITEEstimator):\n",
    "    def __init__(self, sk_model):\n",
    "        self.model = sk_model\n",
    "    \n",
    "    def fit(self, **kwargs):\n",
    "        self.model.fit(X=kwargs[\"X_training\"],\n",
    "                       y=kwargs[\"y_training\"],\n",
    "                       treatment=kwargs[\"t_training\"])\n",
    "    \n",
    "    def predict(self, **kwargs):\n",
    "        if 'return_counterfactuals' in kwargs:\n",
    "            raise ValueError(\"Causal Forest does not support counterfactual predictions out of the box\")\n",
    "        out = self.model.predict(kwargs[\"X_test\"])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no-export\n",
    "class BARTEstimator(BaseITEEstimator):\n",
    "    def fit(self, **kwargs):\n",
    "        self.model_bart = pm.Model()\n",
    "        X = np.concatenate((kwargs[\"X_training\"], kwargs[\"t_training\"].reshape((-1,1))),axis=1)            \n",
    "        with self.model_bart:\n",
    "            x_obs = pm.MutableData(\"X\", X)\n",
    "            self.model_bart.named_vars.pop(\"X\")\n",
    "            x_obs = pm.MutableData(\"X\", X)\n",
    "            μ = pmb.BART(\"μ\", X=x_obs, Y=kwargs[\"y_training\"], m=100)\n",
    "            y_pred = pm.Normal(\"y_pred\", mu=μ, observed=kwargs[\"y_training\"],\n",
    "                               shape=μ.shape)\n",
    "            self.trace = pm.sample(random_seed=1005)\n",
    "            \n",
    "    def predict(self, **kwargs):\n",
    "        X0 = np.concatenate((kwargs[\"X\"],\n",
    "                             np.zeros(kwargs[\"X\"].shape[0]).reshape((-1,1))),axis=1)\n",
    "        X1 = np.concatenate((kwargs[\"X\"],\n",
    "                             np.ones(kwargs[\"X\"].shape[0]).reshape((-1,1))),axis=1)\n",
    "        with self.model_bart:\n",
    "            pm.set_data({\"X\": X1})\n",
    "            p1 = pm.sample_posterior_predictive(self.trace)\n",
    "            pm.set_data({\"X\": X0})\n",
    "            p0 = pm.sample_posterior_predictive(self.trace)\n",
    "            ite = p1[\"posterior_predictive\"][\"y_pred\"] - p0[\"posterior_predictive\"][\"y_pred\"]\n",
    "            ite = ite.mean(axis=0).to_numpy() #across chains\n",
    "            if \"return_mean\" in kwargs:\n",
    "                if kwargs[\"return_mean\"]:\n",
    "                    return ite.mean(axis=0)\n",
    "            else:\n",
    "                return ite.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
