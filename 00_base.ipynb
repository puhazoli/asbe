{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: base.html\n",
    "title: Basic functionalities\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| output: false\n",
    "from sklearn.base import BaseEstimator\n",
    "import numpy as np\n",
    "from typing import Union, Callable, Optional, Tuple, List, Iterator, Any\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass, field\n",
    "#from sklift.metrics import qini_auc_score, qini_curve\n",
    "#from pylift.eval import UpliftEval\n",
    "from pylift.eval import get_scores\n",
    "from fastcore.test import *\n",
    "import asbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "data_types = Union[np.array, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class FitTask(type):\n",
    "    \"\"\"Meta class to make preprocessing of data before fitting different models\n",
    "\n",
    "    This meta class is needed so new models can be incorporated easily\n",
    "    by only having a .fit() method. It will call a prepare_data function, which\n",
    "    can also be modified .\n",
    "    \"\"\"\n",
    "    # https://stackoverflow.com/a/18859019\n",
    "    def __init__(cls, name, bases, clsdict):\n",
    "        if 'fit' in clsdict:\n",
    "            def new_fit(self, **kwargs):\n",
    "                try:\n",
    "                    X_training = kwargs[\"X_training\"] if \"X_training\" in kwargs else self.dataset[\"X_training\"]\n",
    "                    y_training = kwargs[\"y_training\"] if \"y_training\" in kwargs else self.dataset[\"y_training\"]\n",
    "                    t_training = kwargs[\"t_training\"] if \"t_training\" in kwargs else self.dataset[\"t_training\"]\n",
    "                except:\n",
    "                    raise ValueError(\"Can't find (X,t,y) data to fit the model on\")\n",
    "                try:\n",
    "                    ps_scores  = kwargs[\"ps_scores\"] if \"ps_scores\" in kwargs else self.dataset[\"ps_scores\"]\n",
    "                except:\n",
    "                    ps_scores = None\n",
    "                try:\n",
    "                    fun_to_prepare = bases['prepare_data'] if [\"prepare_data\"] in dir(\n",
    "                        bases) else self.prepare_data\n",
    "                    X_training, t_training, y_training, ps_scores = fun_to_prepare(X_training, t_training, y_training, ps_scores)\n",
    "                except:\n",
    "                    raise ValueError(\"Can't prepare data. Use either the default or implement new 'prepare_data' method\")\n",
    "                clsdict['fit'](self, X_training = X_training,\n",
    "                               t_training = t_training,\n",
    "                               y_training = y_training,\n",
    "                               ps_scores = ps_scores)\n",
    "            setattr(cls, 'fit', new_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "class BaseITEEstimator(BaseEstimator, metaclass=FitTask):\n",
    "    \"\"\"Base class for estimating treatment effects\n",
    "\n",
    "    This is a base class, that is also usable on its own to estimate treatment effects.\n",
    "    It works with most models that have a .fit() method, but subclassing is also made\n",
    "    straightforward throught a metaclass.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    model : str, Callable\n",
    "        treatment effect estimator to be used\n",
    "    dataset: dict, BaseDataGenerator\n",
    "        dataset to be used by the model, either offline or online\n",
    "    two_model: bool\n",
    "        Switches between S or T learner approach, when appropriate\n",
    "    ps_model: Callable, None\n",
    "        Propensity score model, if used, must be classifier\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    prepare_data(X_training, t_training, y_training, ps_scores):\n",
    "        Puts together data for training before .fit() is called\n",
    "\n",
    "    fit(X_training, t_training, y_training, ps_scores):\n",
    "        Fits the treatment effect estimator to the training data\n",
    "\n",
    "    predict(X, ps_scores):\n",
    "        Predicts the treatment effects based on the supplied X\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                model: Union[str, Callable] = None,\n",
    "                dataset : Union[dict,None] = None,\n",
    "                two_model: Union[bool,None] = None,\n",
    "                ps_model : Union[Callable, None] = None,\n",
    "                **kwargs)-> None:\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        self.two_model = two_model\n",
    "        self.ps_model = ps_model\n",
    "        self.proba = False\n",
    "        \"\"\"\n",
    "        Makes the estimator ready for its task\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model : str, Callable\n",
    "            treatment effect estimator to be used\n",
    "        dataset: dict, BaseDataGenerator\n",
    "            dataset to be used by the model, either offline or online\n",
    "        two_model: bool\n",
    "            Switches between S or T learner approach, when appropriate\n",
    "        ps_model: Callable, None\n",
    "            Propensity score model, if used, must be classifier\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "\n",
    "    def _fit_ps_model(self, X_training, t_training):\n",
    "        self.ps_model.fit(X_training, t_training)\n",
    "\n",
    "    def prepare_data(self, X_training=None, t_training=None, y_training=None, ps_scores=None):\n",
    "        \"\"\"\n",
    "        Prepares data before fitting the model\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_training : np.ndarray\n",
    "            Training features (size n x d)\n",
    "        t_training : np.ndarray\n",
    "            Training treatments (size n x 1)\n",
    "        y_training : np.ndarray\n",
    "            Training labels (size n x 1)\n",
    "        ps_scores : np.ndarray, None\n",
    "            Optinal propensity scores if they are coming from outside model\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        X_training, t_training, y_training, ps_scores\n",
    "            Updated training data\n",
    "        \"\"\"\n",
    "        if X_training is None:\n",
    "            try:\n",
    "                X_training = deepcopy(self.dataset[\"X_training\"])\n",
    "                y_training = deepcopy(self.dataset[\"y_training\"])\n",
    "                t_training = deepcopy(self.dataset[\"t_training\"])\n",
    "            except:\n",
    "                raise ValueError(\"No data to fit the model on.\")\n",
    "        if np.unique(y_training).shape[0] == 2:\n",
    "            self.proba = True\n",
    "        if self.ps_model is not None or ps_scores is not None:\n",
    "            if self.ps_model is not None:\n",
    "                self._fit_ps_model(X_training, t_training)\n",
    "                ps_scores = self.ps_model.predict_proba(X_training)\n",
    "            try:\n",
    "                X_training = np.hstack((X_training, ps_scores[:,1].reshape((-1, 1))))\n",
    "            except:\n",
    "                raise ValueError(f\"Shape of propensity scores is {ps_scores.shape},instead of (-1,1)\")\n",
    "        X_t_training = np.hstack((X_training, t_training.reshape(-1,1)))\n",
    "        if self.two_model is False:\n",
    "            X_training = deepcopy(X_t_training)\n",
    "\n",
    "        return X_training, t_training, y_training, ps_scores\n",
    "\n",
    "    def fit(self,\n",
    "            X_training,\n",
    "            t_training,\n",
    "            y_training,\n",
    "            ps_scores,\n",
    "            **kwargs):\n",
    "        \"\"\"\n",
    "        Fits the model using .fit() function of other the given ITE estimators\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_training : np.ndarray\n",
    "            Training features (size n x d)\n",
    "        t_training : np.ndarray\n",
    "            Training treatments (size n x 1)\n",
    "        y_training : np.ndarray\n",
    "            Training labels (size n x 1)\n",
    "        ps_scores : np.ndarray, None\n",
    "            Optinal propensity scores if they are coming from outside model\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        if self.two_model is False or self.two_model is None:\n",
    "            self.model.fit(X_training, y_training)\n",
    "        else:\n",
    "            control_ix = np.where(t_training == 0)[0]\n",
    "            self.m1 = deepcopy(self.model)\n",
    "            self.model.fit(X_training[control_ix,:], y_training[control_ix])\n",
    "            self.m1.fit(X_training[-control_ix,:],   y_training[-control_ix])\n",
    "\n",
    "    def _predict_bin_or_con(self, model, X):\n",
    "        if self.proba:\n",
    "            try:\n",
    "                out = model.predict_proba(X)[:, 1]\n",
    "            except:\n",
    "                out = model.predict(X)\n",
    "        else:\n",
    "            out = model.predict(X)\n",
    "        return out\n",
    "\n",
    "    def predict(self,\n",
    "                    X: np.ndarray,\n",
    "                    ps_scores = None,\n",
    "                    **kwargs):\n",
    "        \"\"\"\n",
    "        Predicts the treatment effect using the fitted model on the given features\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Features (size n x d)\n",
    "        ps_scores : np.ndarray, None\n",
    "            Optinal propensity scores if they are coming from outside model\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Predicted treatment effect scores (size n x 1 / n x B)\n",
    "        \"\"\"\n",
    "        if self.ps_model is not None or ps_scores is not None:\n",
    "            if self.ps_model is not None:\n",
    "                ps_scores = self.ps_model.predict_proba(X)\n",
    "            X = np.hstack((X, ps_scores[:,1].reshape((-1, 1))))\n",
    "        if self.two_model:\n",
    "            m0_preds = self._predict_bin_or_con(self.model, X)\n",
    "            m1_preds =  self._predict_bin_or_con(self.m1, X)\n",
    "            ite = m1_preds - m0_preds\n",
    "        else:\n",
    "            try:\n",
    "                X0 = np.hstack((X, np.zeros((X.shape[0], 1))))\n",
    "                X1 = np.hstack((X, np.ones((X.shape[0], 1))))\n",
    "                m1_preds = self._predict_bin_or_con(self.model, X1)\n",
    "                m0_preds = self._predict_bin_or_con(self.model, X0)\n",
    "                ite = m1_preds - m0_preds\n",
    "            except:\n",
    "                ite = self._predict_bin_or_con(self.model, X)\n",
    "        return np.asarray(ite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "import sklearn\n",
    "bite = BaseITEEstimator(model = LinearRegression(),\n",
    "                        two_model = True,\n",
    "                        ps_model=None)\n",
    "X = np.random.normal(size=(10000,4))\n",
    "t = np.random.binomial(1, 0.5, size=(10000,))\n",
    "y0 = X[:,1] * 3\n",
    "ite = X[:,3] * (-2)\n",
    "y1 = y0 + ite\n",
    "y = np.where(t == 1, y1, y0)\n",
    "bite.fit(X_training = X,\n",
    "         t_training = t,\n",
    "         y_training = y)\n",
    "preds = bite.predict(X)\n",
    "\n",
    "test_eq(np.round(bite.model.coef_[1]), 3)\n",
    "test_eq(bite.model.coef_.shape[0], 4)\n",
    "test_eq(np.round(np.mean(preds)), 0)\n",
    "test_eq(type(bite.model), sklearn.linear_model._base.LinearRegression)\n",
    "test_eq(bite.ps_model, None)\n",
    "bite.ps_model = LogisticRegression()\n",
    "test_eq(type(bite.ps_model), sklearn.linear_model._logistic.LogisticRegression)\n",
    "bite.ps_model = None\n",
    "bite.two_model = False\n",
    "bite.fit(X_training = X,\n",
    "        t_training = t,\n",
    "        y_training = y)\n",
    "test_eq(bite.model.coef_.shape[0], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaseActiveLearner(BaseEstimator):\n",
    "    \"\"\"Basic of Active Learners later used, with the capability for treatment effects\n",
    "\n",
    "    Inspired by modAL's BaseLearner, however modified for ITE estimation. Dataset is provided by\n",
    "    a dictionary for easier usage and less clutter, but alternatively a BaseDataGenerator can\n",
    "    also be supplied.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    estimator: BaseEstimator\n",
    "        Estimator for treatment effects, which expects a BaseEstimator or a subclass of it\n",
    "    acquisition_function:\n",
    "        Method that selects units to label\n",
    "    assignment_function:\n",
    "        Method that selects control or treatment for selected units\n",
    "    stopping_function:\n",
    "        Method that determines if the active learning process should stop after the current step\n",
    "    dataset : dict, BaseDataGenerator\n",
    "        Dataset that is used for the active learning process\n",
    "    al_steps : int = 1\n",
    "        number of active learnign steps to take. Can be controlled from the outside by self.current_step\n",
    "    offline : bool\n",
    "        Determines whether data is supplied beforehand or created on the fly\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fit():\n",
    "        Fits the supplied estimator with data from dataset\n",
    "    predict(X):\n",
    "        Predicts X with the estimator\n",
    "    query(no_query = None, acquisition_function = None):\n",
    "        Calls the acquisition function to query datapoints to label.\n",
    "        Number of queries and AF can be supplied, which overwrited the active learner's\n",
    "        at the current step\n",
    "    teach(query_idx=None, assignment_function = None, **kwargs):\n",
    "        Teaches the supplied indices, by moving them to the training set and\n",
    "        selects the counterfactuals used\n",
    "    score(metric=\"PEHE\"):\n",
    "        Uses a test set to calculate a metric from the estimator\n",
    "    simulate(no_query: int = None, metric: str = \"Qini\")\n",
    "        Simulates the active learning process by going through al_steps.\n",
    "        The metric for the simulation to be saved can be set\n",
    "    plot():\n",
    "        Plots the typical active learning style line plot, after simulation\n",
    "        has finished.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 estimator: BaseEstimator,\n",
    "                 acquisition_function: Callable,\n",
    "                 assignment_function: Union[Callable, list, None],\n",
    "                 stopping_function: Union[Callable, list, None],\n",
    "                 dataset: dict,\n",
    "                 al_steps: int = 1,\n",
    "                 offline = True,\n",
    "                 **kwargs\n",
    "                ) -> None:\n",
    "        \"\"\"Initiates the active learning sequence\n",
    "\n",
    "        If the learning happens offline, sets up calls to the data generating processes\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        estimator: BaseEstimator\n",
    "            Estimator for treatment effects, which expects a BaseEstimator or a subclass of it\n",
    "        acquisition_function:\n",
    "            Method that selects units to label\n",
    "        assignment_function:\n",
    "            Method that selects control or treatment for selected units\n",
    "        stopping_function:\n",
    "            Method that determines if the active learning process should stop after the current step\n",
    "        dataset : dict, BaseDataGenerator\n",
    "            Dataset that is used for the active learning process\n",
    "        al_steps : int = 1\n",
    "            number of active learnign steps to take. Can be controlled from the outside by self.current_step\n",
    "        offline : bool\n",
    "            Determines whether data is supplied beforehand or created on the fly\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        self.estimator = estimator\n",
    "        if type(acquisition_function) is list:\n",
    "            self.acquisition_function_list = acquisition_function\n",
    "        else:\n",
    "            self.acquisition_function = acquisition_function\n",
    "            self.acquisition_function_list = []\n",
    "        if type(assignment_function) is list:\n",
    "            self.assignment_function_list = assignment_function\n",
    "        else:\n",
    "            self.assignment_function = assignment_function\n",
    "            self.assignment_function_list = []\n",
    "        self.stopping_function = stopping_function\n",
    "        self.dataset = deepcopy(dataset)\n",
    "        self.al_steps = al_steps\n",
    "        self.current_step = 0\n",
    "        self.next_query = True\n",
    "        self.offline = offline\n",
    "        if self.offline is False:\n",
    "            self.dataset.__dict__[\"X_training\"],\\\n",
    "            self.dataset.__dict__[\"t_training\"],\\\n",
    "            self.dataset.__dict__[\"y_training\"] = self.dataset.get_data(\n",
    "                self.dataset.no_training)\n",
    "\n",
    "\n",
    "    def _update_dataset(self, query_idx, **kwargs):\n",
    "        \"\"\"Moves data with query_idx indices from pool to training\"\"\"\n",
    "        remove_data = kwargs[\"remove_data\"] if \"remove_data\" in kwargs else True\n",
    "        if type(self.dataset) is not dict:\n",
    "            self.dataset = self.dataset.__dict__\n",
    "        if \"outside_data\" in kwargs:\n",
    "            for data in [\"X\", \"t\", \"y\"]:\n",
    "                self.dataset[f\"{data}_training\"] = np.concatenate((\n",
    "                            self.dataset[f\"{data}_training\"],\n",
    "                            kwargs[\"outside_data\"][f\"{data}\"]))\n",
    "            return None\n",
    "        for data in [\"X\", \"t\", \"y\", \"ite\"]:\n",
    "            if data in self.dataset.keys():\n",
    "                if self.dataset[f\"{data}_training\"].shape[0] > 0 :\n",
    "                    if data in [\"X\"]:\n",
    "                        self.dataset[f\"{data}_training\"] = np.concatenate((\n",
    "                            self.dataset[f\"{data}_training\"],\n",
    "                            self.dataset[f\"{data}_pool\"][query_idx,:]))\n",
    "                    else:\n",
    "                        self.dataset[f\"{data}_training\"] = np.concatenate((\n",
    "                            self.dataset[f\"{data}_training\"],\n",
    "                            self.dataset[f\"{data}_pool\"][query_idx]))\n",
    "                else:\n",
    "                    self.dataset[f\"{data}_training\"] = self.dataset[f\"{data}_pool\"][query_idx,:]\n",
    "                if remove_data:\n",
    "                    self.dataset[f\"{data}_pool\"] = np.delete(self.dataset[f\"{data}_pool\"],\n",
    "                                                                 query_idx, 0)\n",
    "        try:\n",
    "            for cfs in [\"y0\",\"y1\"]:\n",
    "                self.dataset[f\"{cfs}_training\"] = np.concatenate((\n",
    "                                self.dataset[f\"{cfs}_training\"],\n",
    "                                self.dataset[f\"{cfs}_pool\"][query_idx]))\n",
    "                self.dataset[f\"{cfs}_pool\"] = np.delete(self.dataset[f\"{cfs}_pool\"],\n",
    "                                                                 query_idx, 0)\n",
    "        except KeyError:\n",
    "            pass\n",
    "        return None\n",
    "\n",
    "\n",
    "    def _select_counterfactuals(self, query_idx, treatment):\n",
    "        \"Rewrites observed outcomes in pool for counterfactuals\"\n",
    "        self.dataset[\"y_pool\"][query_idx] = np.where(treatment == 1,\n",
    "                                                     self.dataset[\"y1_pool\"][query_idx],\n",
    "                                                     self.dataset[\"y0_pool\"][query_idx])\n",
    "\n",
    "        self.dataset[\"t_pool\"][query_idx] = treatment\n",
    "\n",
    "    def fit(self) -> None:\n",
    "        \"\"\"\n",
    "        Fits the model using the given estimator\n",
    "        \"\"\"\n",
    "        self.estimator.fit(X_training = self.dataset[\"X_training\"],\n",
    "                           t_training = self.dataset[\"t_training\"],\n",
    "                           y_training = self.dataset[\"y_training\"])\n",
    "        return None\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predicts using the the given estimator\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            The features to predict on\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Predicted treatment effects\n",
    "        \"\"\"\n",
    "        return self.estimator.predict(X=X)\n",
    "\n",
    "    def query(self, no_query = None,\n",
    "              acquisition_function = None,\n",
    "              return_all=False,\n",
    "              **kwargs):\n",
    "        \"\"\"Main function to select datapoints for labeling\n",
    "\n",
    "        Calls the acquisition function to determine which units to label.\n",
    "        The acquisition function can be overwritten for a given query and the number\n",
    "        of queries as well. Queries happen until the budget is exhauested, which is\n",
    "        controlled by the stopping function.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        no_query : int = None\n",
    "            Number of queries\n",
    "        acquisition_function\n",
    "            Optional acquisition function\n",
    "        return_all\n",
    "            Whether to return a dict of X,t,y or only indices + X\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        X_new, query_idx :\n",
    "            Selected features, selected indices\n",
    "        \"\"\"\n",
    "        if no_query is None:\n",
    "            no_query = self.no_query\n",
    "        if self.stopping_function is not None:\n",
    "            self.next_query = self.stopping_function.check_rule(\n",
    "                self.estimator, self.dataset, self.step)\n",
    "        if self.next_query:\n",
    "            if len(self.acquisition_function_list) == 0:\n",
    "                if acquisition_function is None:\n",
    "                    acquisition_function = self.acquisition_function\n",
    "            else:\n",
    "                if acquisition_function is None:\n",
    "                    acquisition_function = self.acquisition_function\n",
    "            if self.offline:\n",
    "                X_new, query_idx = acquisition_function.select_data(self.estimator,\n",
    "                                                              self.dataset,\n",
    "                                                              no_query,\n",
    "                                                              **kwargs)\n",
    "            else:\n",
    "                X_get = self.dataset.get_X(no_query = no_query)\n",
    "                data_to_estimate = {\"X_training\":self.dataset[\"X_training\"],\n",
    "                                   \"X_pool\": X_get}\n",
    "                decision_to_query = acquisition_function.select_data(self.estimator,\n",
    "                                                              data_to_estimate,\n",
    "                                                              no_query,\n",
    "                                                              offline = False,\n",
    "                                                              **kwargs)\n",
    "                if decision_to_query:\n",
    "                    self.X_to_add = X_get\n",
    "                    X_new = X_get\n",
    "                else:\n",
    "                    X_new = None\n",
    "                try:\n",
    "                    query_idx = self.dataset.selected_ix\n",
    "                except:\n",
    "                    query_idx = None\n",
    "        else:\n",
    "            X_new, query_idx = None, None\n",
    "        if return_all:\n",
    "            return {\"X\": X_new,\n",
    "                    \"t\": self.dataset[\"t_pool\"][query_idx],\n",
    "                    \"y\": self.dataset[\"y_pool\"][query_idx]}\n",
    "        return X_new, query_idx\n",
    "\n",
    "    def teach(self, query_idx=None, assignment_function = None, select_again = False, **kwargs):\n",
    "        \"\"\"Function to assign the selected labels to the training set\n",
    "\n",
    "        Selects counterfactuals (if possible), through the assignmnet function\n",
    "        and moves data from the pool to the training set.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        query_idx : np.array = None\n",
    "            the indices of queryed samples\n",
    "        assignment_function : None\n",
    "            Optional assignment function to be used to select counterfactuals\n",
    "        select_again = False\n",
    "            If there are no matching, select units until all are matching\n",
    "        kwargs[\"outside_data\"] = None\n",
    "            If outside data is given in a dictionary, the assignment function won't do anything\n",
    "            it will assign the data given in this dict\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        if \"outside_data\" in kwargs:\n",
    "            self._update_dataset(query_idx = None,\n",
    "                                 outside_data = kwargs[\"outside_data\"])\n",
    "            return None # exit update immediately\n",
    "        \n",
    "        if len(self.assignment_function_list) == 0:\n",
    "            if assignment_function is None:\n",
    "                if self.assignment_function is None:\n",
    "                    self.assignment_function = asbe.models.RandomAssignmentFunction()\n",
    "                assignment_function = self.assignment_function\n",
    "            else:\n",
    "                raise ValueError(\"No assignment function provided\")\n",
    "        else:\n",
    "            if assignment_function is None:\n",
    "                assignment_function = self.assignment_function\n",
    "        if self.offline:\n",
    "            treatment = assignment_function.select_treatment(self.estimator,\n",
    "                                                              self.dataset,\n",
    "                                                              query_idx)\n",
    "            if \"y0_pool\" in self.dataset:\n",
    "                self._select_counterfactuals(query_idx, treatment)\n",
    "            matching = treatment == self.dataset[\"t_pool\"][query_idx]\n",
    "            if matching.all():\n",
    "                self._update_dataset(query_idx, **kwargs)\n",
    "            else:\n",
    "                self._update_dataset(query_idx[matching], **kwargs)\n",
    "                if select_again:\n",
    "                    while matching.sum() < treatment.shape[0]:\n",
    "                        X_reselected, ix_reselected = self.query(\n",
    "                            treatment.shape[0] - matching.sum())\n",
    "                        treatment = assignment_function.select_treatment(self.estimator,\n",
    "                                                              self.dataset,\n",
    "                                                              ix_reselected)\n",
    "                        matching = treatment == self.dataset[\"t_pool\"][ix_reselected]\n",
    "                        self._update_dataset(ix_reselected[matching], **kwargs)\n",
    "        else:\n",
    "            treatment_to_add = self.dataset.get_t(X_new = self.X_to_add)\n",
    "            y = self.dataset.get_y(X_new=self.X_to_add, t_new = treatment_to_add)\n",
    "            self.dataset.__dict__[\"X_pool\"] = self.X_to_add\n",
    "            self.dataset.__dict__[\"t_pool\"] = treatment_to_add\n",
    "            self.dataset.__dict__[\"y_pool\"] = y\n",
    "            self._update_dataset(np.arange(y.shape[0]), remove_data=True)\n",
    "\n",
    "        return None\n",
    "\n",
    "    def score(self, metric=\"PEHE\"):\n",
    "        \"\"\"\n",
    "        Calculates the metric given on the test set.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        metric : str = \"PEHE\"\n",
    "            Metric to be used when calculating the performance\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        The score of the model\n",
    "        \"\"\"\n",
    "        metrics = [\"Qini\", \"PEHE\", \"Cgains\", \"decision\", \"Qini_curve\"]\n",
    "        if not callable(metric):\n",
    "            if metric not in metrics:\n",
    "                raise ValueError(f\"Please use a valid error ({metrics}), {metric} is not valid\")\n",
    "        try:\n",
    "            preds = self.estimator.predict(X=self.dataset[\"X_test\"], return_mean=True)\n",
    "        except:\n",
    "            preds = self.estimator.predict(X=self.dataset[\"X_test\"])\n",
    "        if metric == \"PEHE\":\n",
    "            try:\n",
    "                sc = np.sqrt(np.mean(np.square(preds - self.dataset[\"ite_test\"])))\n",
    "            except KeyError:\n",
    "                raise Error(\"Check if dataset contains true ITE values\")\n",
    "        elif metric == \"decision\":\n",
    "            dec = np.where((preds >= 0) &( self.dataset[\"ite_test\"] >= 0), 1, 0)\n",
    "            sc = np.sum(dec)/self.dataset[\"ite_test\"].shape[0]\n",
    "        elif metric == \"Qini\":\n",
    "            sc = get_scores(self.dataset[\"t_test\"],\n",
    "                            self.dataset[\"y_test\"],\n",
    "                            preds,\n",
    "                            np.zeros_like(self.dataset[\"t_test\"]) + self.dataset[\"t_test\"].mean())[\"q1_qini\"]\n",
    "#         elif metric == \"Qini_curve\":\n",
    "#             sc = qini_curve(y_true=self.dataset[\"y_test\"],\n",
    "#                                 uplift=preds,\n",
    "#                                 treatment=self.dataset[\"t_test\"])\n",
    "        elif callable(metric):\n",
    "            try:\n",
    "                sc = metric(preds, self.dataset[\"ite_test\"])\n",
    "            except:\n",
    "                raise ValueError(\"Metric can't be used with current data\")\n",
    "        return sc\n",
    "\n",
    "    def simulate(self, no_query: int = None, metric: str = \"Qini\") -> dict:\n",
    "        \"\"\"\n",
    "        Simulates the active learning process based on the attributes to the class\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        no_query:\n",
    "            Number of units to be queried\n",
    "        Metric:\n",
    "            Metric to be calculated at the end of each active learning step\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            Dictionary with keys of assignment functions and values of steps and scores\n",
    "        \"\"\"\n",
    "        ds = deepcopy(self.dataset)\n",
    "        est = deepcopy(self.estimator)\n",
    "        res = {}\n",
    "        if len(self.acquisition_function_list) == 0:\n",
    "            laf = [self.acquisition_function]\n",
    "        else:\n",
    "            laf = self.acquisition_function_list\n",
    "        for af in laf:\n",
    "            if no_query is None:\n",
    "                no_query = af.no_query\n",
    "            self.dataset = deepcopy(ds)\n",
    "            self.estimator = deepcopy(est)\n",
    "            self.current_step = 0\n",
    "            res[af.name] = {}\n",
    "            if type(metric) is list:\n",
    "                for m in metric:\n",
    "                    res[af.name][m]={}\n",
    "            for i in range(1, self.al_steps+1):\n",
    "                self.fit()\n",
    "                X_new, query_idx = self.query(no_query=no_query, acquisition_function = af)\n",
    "                if self.next_query:\n",
    "                    if self.offline:\n",
    "                        self.teach(query_idx)\n",
    "                    else:\n",
    "                        self.teach()\n",
    "                    if type(metric) is list:\n",
    "                        for m in metric:\n",
    "                            res[af.name][m][i] = self.score(metric=m)\n",
    "                    else:\n",
    "                        res[af.name][i] = self.score(metric=metric)\n",
    "                    self.current_step += 1\n",
    "        self.simulation_results = res\n",
    "        return res\n",
    "\n",
    "    def plot(self):\n",
    "        \"\"\"Plots the results of the AL simulation\"\"\"\n",
    "        pd.DataFrame(self.simulation_results).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaseAcquisitionFunction():\n",
    "    \"\"\"Base class for acquisition functions\n",
    "\n",
    "    Based on Eq. 3 in paper:\n",
    "        - calculate_metrics is used to get infromativeness/representativeness\n",
    "        - calculate_metrics returns a weighted average between the two\n",
    "        - select_data does the normalization and selecting top m/Bernoulli draws\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    no_query : int = 1\n",
    "        Number of queries\n",
    "    method : str = \"top\"\n",
    "        Way to select the data after metrics are calculated\n",
    "    name : str\n",
    "        Name of the AF, used in simulations\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    calculate_metrics(model, dataset):\n",
    "        User defined method to get different metrics about the pool set\n",
    "    select_data(model, dataset, no_query):\n",
    "        Based on the calculated metrics, selects the data to be added to the\n",
    "        training set.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                no_query: int = 1,\n",
    "                method: str = \"top\",\n",
    "                name: str = \"base\") -> None:\n",
    "        self.no_query = no_query\n",
    "        self.method = method\n",
    "        self.name = name + \"_\" + str(no_query)\n",
    "\n",
    "    def calculate_metrics(self, model, dataset) -> np.array:\n",
    "        \"\"\"\n",
    "        Method to calculate base metrics for assignment function\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model:\n",
    "            The ITE estimator\n",
    "        dataset:\n",
    "            The dataset dictionary/class that holds the training/pool set.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        weighted average of individual metrics\n",
    "        \"\"\"\n",
    "        return np.arange(dataset[\"X_pool\"].shape[0]) + 1\n",
    "\n",
    "    def select_data(self, model, dataset, no_query, offline=True, **kwargs):\n",
    "        \"\"\"\n",
    "        Based on the calculated metrics, select data and return X and indexes\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model:\n",
    "            The ITE estimator\n",
    "        dataset:\n",
    "            The dataset dictionary/class that holds the training/pool set.\n",
    "        no_query:\n",
    "            Number of queries\n",
    "        offline : bool\n",
    "            Indicator whether the process is online/offline\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tuple of new features and indices\n",
    "        \"\"\"\n",
    "        if no_query is None:\n",
    "            no_query = self.no_query\n",
    "        if dataset[\"X_training\"].shape[0] == 0:\n",
    "            try:\n",
    "                metrics = self.calculate_metrics(model, dataset, **kwargs)\n",
    "            except:\n",
    "                metrics = np.random.shuffle(np.arange(dataset[\"X_pool\"].shape[0]))\n",
    "        else:\n",
    "            metrics = self.calculate_metrics(model, dataset, **kwargs)\n",
    "\n",
    "        if offline:\n",
    "            if self.method in [\"top\", \"normalized\", \"only_ones\"]:\n",
    "                if self.method == \"top\":\n",
    "                    query_idx = np.argsort(np.asarray(metrics))[-no_query:][::-1]\n",
    "                elif self.method == \"normalized\":\n",
    "                    p_j = (metrics - np.min(metrics))/(np.max(metrics) - np.min(metrics))\n",
    "                    query_idx = []\n",
    "                    for pix in p_j.argsort()[::-1]:\n",
    "                        if np.random.binomial(1, p = p_j[pix]) == 1:\n",
    "                            query_idx.append(pix)\n",
    "                        if len(query_idx) == no_query:\n",
    "                            break\n",
    "                    query_idx = np.asarray(query_idx)\n",
    "                elif self.method == \"only_ones\":\n",
    "                    query_idx = np.where(np.asarray(metrics) == 1)[0]\n",
    "                    query_idx = query_idx.tolist()\n",
    "            else:\n",
    "                raise NotImplementedError(\"Please use a method that is implemented\")\n",
    "            X_new = dataset[\"X_pool\"][query_idx,:]\n",
    "            out = (X_new, query_idx)\n",
    "        else:\n",
    "            out = metrics.sum() >= metrics.shape[0]/2\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaseAssignmentFunction():\n",
    "    \"\"\"Base class for assignment functions\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    base_selection : int = 0\n",
    "        Which treatment to select automatically\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    select_treatment(model, dataset, query_idx)\n",
    "        Selects the treaatment based on the model and the dataset.\n",
    "        Predictions can only be done for the selected indices to save time.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_selection = 0):\n",
    "        self.base_selection = base_selection\n",
    "\n",
    "    def select_treatment(self, model, dataset, query_idx):\n",
    "        return dataset[\"t_pool\"][query_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaseStoppingRule():\n",
    "    \"\"\"Base class for providing a stopping rule for the active learner\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    budget : int = None\n",
    "        The budget that the active learner can use to run simulations\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    check_rules(model, dataset, step)\n",
    "        The method to check if the condition is reached to stop the active\n",
    "        learning loop\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, budget=None):\n",
    "        self.budget = budget\n",
    "\n",
    "    def check_rule(self, model, dataset, step):\n",
    "        if self.budget - step >= 0:\n",
    "            out = False\n",
    "        else:\n",
    "            out = True\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class BaseDataGenerator():\n",
    "    \"\"\"Class to generate online data for active learing purposes\"\"\"\n",
    "    ds: Union[dict, Callable]\n",
    "    dgp_x : Union[Callable, None] = None\n",
    "    dgp_t : Union[Callable, None] = None\n",
    "    dgp_y : Union[Callable, None] = None\n",
    "    no_training : int = 10\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return super().__getattribute__(key)\n",
    "\n",
    "    def get_X(self, method : str = \"random\", no_query : int = 1):\n",
    "        if self.ds is not None:\n",
    "            ix = np.random.randint(low = 0, high = self.ds[\"X_pool\"].shape[0], size=(no_query))\n",
    "            X_new = self.ds[\"X_pool\"][ix,:]\n",
    "            self.selected_ix = ix\n",
    "        else:\n",
    "            X_new = self.dgp_x(no_query)\n",
    "        self.X_new = X_new\n",
    "        return X_new\n",
    "\n",
    "    def get_t(self, X_new=None):\n",
    "        if X_new is None:\n",
    "            X_new = self.X_new\n",
    "        if self.ds is not None:\n",
    "            t_new = self.ds[\"t_pool\"][self.selected_ix]\n",
    "        else:\n",
    "            t_new = self.dgp_t(X_new)\n",
    "        self.t_new = t_new\n",
    "        return t_new\n",
    "\n",
    "    def get_y(self, X_new=None, t_new=None):\n",
    "        if X_new is None:\n",
    "            X_new = self.X_new\n",
    "        if t_new is None:\n",
    "            t_new = self.t_new\n",
    "        if self.ds is not None:\n",
    "            y_new = np.where(t_new == 1,\n",
    "                             self.ds[\"y1_pool\"][self.selected_ix],\n",
    "                             self.ds[\"y0_pool\"][self.selected_ix])\n",
    "        else:\n",
    "            y_new = self.dgp_y(X_new, t_new)\n",
    "        return y_new\n",
    "\n",
    "    def get_data(self, no_query=1, as_test=False):\n",
    "        X_new = self.get_X(no_query=no_query)\n",
    "        t_new = self.get_t()\n",
    "        y_new = self.get_y()\n",
    "        if as_test:\n",
    "            self.X_test = X_new\n",
    "            self.t_test = t_new\n",
    "            self.y_test = y_new\n",
    "        return (X_new, t_new, y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
