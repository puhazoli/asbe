{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from sklearn.base import BaseEstimator\n",
    "import numpy as np\n",
    "from typing import Union, Callable, Optional, Tuple, List, Iterator, Any\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = Union[np.array, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FitTask(type):\n",
    "    # https://stackoverflow.com/a/18859019\n",
    "    def __init__(cls, name, bases, clsdict):\n",
    "        if 'fit' in clsdict:\n",
    "            def new_fit(self, X_training, t_training, y_training, ps_scores=None, *args, **kwargs):\n",
    "                clsdict['prepare_data'](self, X_training, t_training, y_training, ps_scores=None)\n",
    "                print(\"Before the fitting\")\n",
    "                clsdict['fit'](self, X_training, t_training, y_training, ps_scores, **kwargs)\n",
    "                print('after')\n",
    "            setattr(cls, 'fit', new_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "class BaseITEEstimator(BaseEstimator, metaclass=FitTask):\n",
    "    \"\"\"Base class for \"\"\"\n",
    "    def __init__(self, \n",
    "                model: Union[str, Callable] = None, \n",
    "                dataset : Union[dict,None] = None,\n",
    "                two_model: bool = False,\n",
    "                ps_model : Union[Callable, None] = None,\n",
    "                **kwargs)-> None:\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        self.two_model = two_model\n",
    "        self.ps_model = ps_model\n",
    "        self.proba = False\n",
    "        \n",
    "    def _fit_ps_model(self, X_training, t_training):\n",
    "        self.ps_model.fit(X_training, t_training)\n",
    "        \n",
    "    def prepare_data(self, X_training=None, t_training=None, y_training=None, ps_scores=None):\n",
    "        if X_training is None:\n",
    "            try:\n",
    "                X_training = deepcopy(self.dataset[\"X_training\"])\n",
    "                y_training = deepcopy(self.dataset[\"y_training\"])\n",
    "                t_training = deepcopy(self.dataset[\"t_training\"])\n",
    "            except:\n",
    "                raise ValueError(\"No data to fit the model on.\")\n",
    "        return X_training, t_training, y_training, ps_scores\n",
    "                \n",
    "    def fit(self, \n",
    "            X_training: Union[np.ndarray, None] = None, \n",
    "            t_training: Union[np.ndarray, None] = None,\n",
    "            y_training: Union[np.ndarray, None] = None,\n",
    "            ps_scores: Union[np.ndarray, None] = None,\n",
    "            **kwargs):\n",
    "        \"Fit function, using .fit() from other models\"\n",
    "        if X_training is None:\n",
    "            try:\n",
    "                X_training = deepcopy(self.dataset[\"X_training\"])\n",
    "                y_training = deepcopy(self.dataset[\"y_training\"])\n",
    "                t_training = deepcopy(self.dataset[\"t_training\"])\n",
    "            except:\n",
    "                raise ValueError(\"No data to fit the model on.\")\n",
    "            \n",
    "        if np.unique(y_training).shape[0] == 2:\n",
    "            self.proba = True\n",
    "        if self.ps_model is not None or ps_scores is not None:\n",
    "            if self.ps_model is not None:\n",
    "                self._fit_ps_model(X_training, t_training)\n",
    "                ps_scores = self.ps_model.predict_proba(X_training)\n",
    "            try:\n",
    "                X_training = np.hstack((X_training, ps_scores[:,1].reshape((-1, 1))))\n",
    "            except:\n",
    "                raise ValueError(f\"Shape of propensity scores is {ps_scores.shape},instead of (-1,1)\")\n",
    "            \n",
    "        X_t_training = np.hstack((X_training, t_training.reshape(-1,1)))\n",
    "        if self.two_model is False or self.two_model is None:\n",
    "            self.model.fit(X_t_training, y_training)\n",
    "        else:\n",
    "            control_ix = np.where(t_training == 0)[0]\n",
    "            self.m1 = deepcopy(self.model)\n",
    "            self.model.fit(X_training[control_ix,:], y_training[control_ix])\n",
    "            self.m1.fit(X_training[-control_ix,:],   y_training[-control_ix])\n",
    "                \n",
    "    def _predict_bin_or_con(self, model, X):\n",
    "        if self.proba:\n",
    "            try:\n",
    "                out = model.predict_proba(X)[:, 1]\n",
    "            except:\n",
    "                out = model.predict(X)\n",
    "        else:\n",
    "            out = model.predict(X)\n",
    "        return out\n",
    "                  \n",
    "    def predict(self,\n",
    "                    X: np.ndarray,\n",
    "                    ps_scores = None):\n",
    "        if self.ps_model is not None or ps_scores is not None:\n",
    "            if self.ps_model is not None:\n",
    "                ps_scores = self.ps_model.predict_proba(X)\n",
    "            X = np.hstack((X, ps_scores[:,1].reshape((-1, 1))))\n",
    "        if self.two_model:\n",
    "            m0_preds = self._predict_bin_or_con(self.model, X)\n",
    "            m1_preds =  self._predict_bin_or_con(self.m1, X)\n",
    "            ite = m1_preds - m0_preds\n",
    "        else:\n",
    "            try:\n",
    "                X0 = np.hstack((X, np.zeros((X.shape[0], 1))))\n",
    "                X1 = np.hstack((X, np.ones((X.shape[0], 1))))\n",
    "                m1_preds = self._predict_bin_or_con(self.model, X1)\n",
    "                m0_preds = self._predict_bin_or_con(self.model, X0)\n",
    "                ite = m1_preds - m0_preds\n",
    "            except:\n",
    "                ite = self._predict_bin_or_con(self.model, X)\n",
    "        return np.asarray(ite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BaseActiveLearner(BaseEstimator):\n",
    "    \"\"\"Basic of Active Learners later used, with the capability for treatment effects\n",
    "    \n",
    "    Inspired by modAL's BaseLearner, however modified for ITE estimation. Dataset is provided by \n",
    "    a dictionary for easier usage and less clutter.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 estimator: BaseEstimator,\n",
    "                 acquisition_function: Callable,\n",
    "                 assignment_function: Union[Callable, list, None],\n",
    "                 stopping_function: Union[Callable, list, None],\n",
    "                 dataset: dict,\n",
    "                 al_steps: int = 1,\n",
    "                 **kwargs\n",
    "                ) -> None:\n",
    "        self.estimator = estimator\n",
    "        if type(acquisition_function) is list:\n",
    "            self.acquisition_function_list = acquisition_function\n",
    "        else:\n",
    "            self.acquisition_function = acquisition_function\n",
    "            self.acquisition_function_list = []\n",
    "        if type(assignment_function) is list:\n",
    "            self.assignment_function_list = assignment_function\n",
    "        else:\n",
    "            self.assignment_function = assignment_function\n",
    "            self.assignment_function_list = []\n",
    "        self.stopping_function = stopping_function\n",
    "        self.dataset = deepcopy(dataset)\n",
    "        self.al_steps = al_steps\n",
    "        self.current_step = 0\n",
    "        \n",
    "    def _update_dataset(self, query_idx, treatment, **kwargs):\n",
    "        \"\"\"Moves data with query_idx indices from pool to training\"\"\"\n",
    "        remove_data = kwargs[\"remove_data\"] if \"remove_data\" in kwargs else True\n",
    "        for data in [\"X\", \"t\", \"y\"]:\n",
    "            if self.dataset[f\"{data}_training\"].shape[0] > 0 :\n",
    "                try:\n",
    "                    self.dataset[f\"{data}_training\"] = np.concatenate((\n",
    "                        self.dataset[f\"{data}_training\"],\n",
    "                        self.dataset[f\"{data}_pool\"][query_idx,:]))\n",
    "                except:\n",
    "                    self.dataset[f\"{data}_training\"] = np.concatenate((\n",
    "                        self.dataset[f\"{data}_training\"],\n",
    "                        self.dataset[f\"{data}_pool\"][query_idx]))\n",
    "            else: \n",
    "                self.dataset[f\"{data}_training\"] = self.dataset[f\"{data}_pool\"][query_idx,:]\n",
    "            if remove_data:\n",
    "                self.dataset[f\"{data}_pool\"] = np.delete(self.dataset[f\"{data}_pool\"],\n",
    "                                                             query_idx, 0)\n",
    "                \n",
    "    def _select_counterfactuals(self, query_idx, treatment):\n",
    "        self.dataset[\"y_pool\"][query_idx] = np.where(treatment == 1,\n",
    "                                                     self.dataset[\"y1_pool\"][query_idx],\n",
    "                                                     self.dataset[\"y0_pool\"][query_idx])\n",
    "        \n",
    "        self.dataset[\"t_pool\"][query_idx] = treatment\n",
    "                \n",
    "    def fit(self) -> None:\n",
    "        self.estimator.fit(self.dataset[\"X_training\"],\n",
    "                           self.dataset[\"t_training\"],\n",
    "                           self.dataset[\"y_training\"])\n",
    "        return None\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.estimator.predict(X)\n",
    "            \n",
    "    def query(self, no_query = None, acquisition_function = None):\n",
    "        \"\"\"Main function to select datapoints\"\"\"\n",
    "        if len(self.acquisition_function_list) == 0:\n",
    "            if acquisition_function is None:\n",
    "                acquisition_function = self.acquisition_function\n",
    "        else:\n",
    "            if acquisition_function is None:\n",
    "                acquisition_function = self.acquisition_function\n",
    "        X_new, query_idx = acquisition_function.select_data(self.estimator,\n",
    "                                                          self.dataset, \n",
    "                                                          no_query)\n",
    "        return X_new, query_idx\n",
    "    \n",
    "    def teach(self, query_idx, assignment_function = None, **kwargs):\n",
    "        \"\"\"Function to assign the selected labels \"\"\"\n",
    "        if len(self.assignment_function_list) == 0:\n",
    "            if assignment_function is None:\n",
    "                assignment_function = self.assignment_function\n",
    "            else:\n",
    "                raise ValueError(\"No assignment function provided\")\n",
    "        else:\n",
    "            if assignment_function is None:\n",
    "                assignment_function = self.assignment_function\n",
    "        treatment = assignment_function.select_treatment(self.estimator,\n",
    "                                                              self.dataset,\n",
    "                                                              query_idx)\n",
    "        if \"y0_pool\" in self.dataset:\n",
    "            self._select_counterfactuals(query_idx, treatment)\n",
    "        \n",
    "        matching = treatment == self.dataset[\"t_pool\"][query_idx]\n",
    "        \n",
    "        if matching.all():\n",
    "            self._update_dataset(query_idx, treatment, **kwargs)\n",
    "        elif matching.sum() > 0:\n",
    "            self._update_dataset(query_idx[matching], treatment[matching], **kwargs)\n",
    "        else:\n",
    "            pass            \n",
    "    \n",
    "    def score(self, metric=\"PEHE\"):\n",
    "        if metric not in [\"Qini\", \"PEHE\", \"Cgains\"]:\n",
    "            raise ValueError(f\"Please use a valid error (PEHE, Qini, Cgains), {metric} is not valid\")\n",
    "        if metric == \"PEHE\":\n",
    "            preds = self.estimator.predict(self.dataset[\"X_test\"])\n",
    "            try:\n",
    "                sc = np.sqrt(np.mean(np.square(preds - self.dataset[\"ite_test\"])))\n",
    "            except KeyError:\n",
    "                raise Error(\"Check if dataset contains true ITE values\")\n",
    "        return sc\n",
    "    \n",
    "    def simulate(self, no_query: int = None) -> dict:\n",
    "        ds = deepcopy(self.dataset)\n",
    "        est = deepcopy(self.estimator)\n",
    "        res = {}\n",
    "        if len(self.acquisition_function_list) == 0:\n",
    "            laf = [self.acquisition_function]\n",
    "        else:\n",
    "            laf = self.acquisition_function_list\n",
    "        for af in laf:\n",
    "            if no_query is None:\n",
    "                no_query = af.no_query\n",
    "            self.dataset = deepcopy(ds)\n",
    "            self.estimator = deepcopy(est)\n",
    "            self.current_step = 0\n",
    "            res[af.name] = {}\n",
    "            for i in range(1, self.al_steps+1):\n",
    "                self.fit()\n",
    "                X_new, query_idx = self.query(no_query=no_query, acquisition_function = af)\n",
    "                self.teach(query_idx)\n",
    "                preds = self.predict(self.dataset[\"X_test\"])\n",
    "                res[af.name][i] = self.score()\n",
    "                self.current_step += 1\n",
    "        self.simulation_results = res\n",
    "        return res\n",
    "    \n",
    "    def plot(self):\n",
    "        pd.DataFrame(self.simulation_results).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BaseAcquisitionFunction():\n",
    "    \"\"\"Base class for acquisition functions\"\"\"\n",
    "    def __init__(self,\n",
    "                no_query: int = 1,\n",
    "                method: str = \"top\",\n",
    "                name: str = \"base\") -> None:\n",
    "        self.no_query = no_query\n",
    "        self.method = method\n",
    "        self.name = name + \"_\" + str(no_query)\n",
    "    \n",
    "    def calculate_metrics(self, model, dataset) -> np.array:\n",
    "        #return model.predict(dataset[\"X_pool\"])\n",
    "        return np.arange(dataset[\"X_pool\"].shape[0])\n",
    "    \n",
    "    def select_data(self, model, dataset, no_query):\n",
    "        if no_query is None:\n",
    "            no_query = self.no_query\n",
    "        metrics = self.calculate_metrics(model, dataset)\n",
    "        if self.method == \"top\":\n",
    "            query_idx = np.argsort(np.asarray(metrics))[-no_query:][::-1]\n",
    "            X_new = dataset[\"X_pool\"][query_idx,:]\n",
    "        return X_new, query_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BaseAssignmentFunction():\n",
    "    \"\"\"Base class for assignment functions\"\"\"\n",
    "    def __init__(self, base_selection = 0):\n",
    "        self.base_selection = base_selection\n",
    "    \n",
    "    def select_treatment(self, model, dataset, query_idx):\n",
    "        return dataset[\"t_pool\"][query_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
