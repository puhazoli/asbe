{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from sklearn.base import BaseEstimator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Union, Callable, Optional, Tuple, List, Iterator, Any\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = Union[np.array, pd.DataFrame]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "class BaseITEEstimator(BaseEstimator):\n",
    "    \"\"\"Base class for \"\"\"\n",
    "    def __init__(self, \n",
    "                model, \n",
    "                dataset : Union[dict,None] = None,\n",
    "                two_model: bool = False,\n",
    "                ps_model : Union[Callable, None] = None,\n",
    "                **kwargs)-> None:\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        self.two_model = two_model\n",
    "        self.ps_model = ps_model\n",
    "        self.proba = False\n",
    "        \n",
    "    def _fit_ps_model(self, X_training, t_training):\n",
    "        self.ps_model.fit(X_training, t_training)\n",
    "        \n",
    "    def fit(self, \n",
    "            X_training: Union[np.ndarray, None] = None, \n",
    "            t_training: Union[np.ndarray, None] = None,\n",
    "            y_training: Union[np.ndarray, None] = None,\n",
    "            ps_scores: Union[np.ndarray, None] = None):\n",
    "        \"Fit function, using .fit() from other models\"\n",
    "        if X_training is None:\n",
    "            X_training = deepcopy(self.X_training)\n",
    "            y_training = deepcopy(self.y_training)\n",
    "            t_training = deepcopy(self.t_training)\n",
    "            \n",
    "        if np.unique(y_training).shape[0] == 2:\n",
    "            self.proba = True\n",
    "        if not self.ps_model and ps_scores is not None:\n",
    "            self._fit_ps_model(X_training, t_training)\n",
    "            ps_scores = self.ps_model.predict(X_training)\n",
    "            try:\n",
    "                X_training = np.hstack((X_training, ps_scores[:,1].reshape((-1, 1))))\n",
    "            except:\n",
    "                raise ValueError(f\"Shape of propensiry scores is {ps_scores.shape},instead of (-1,1)\")\n",
    "            \n",
    "        X_t_training = np.hstack((X_training, t_training.reshape(-1,1)))\n",
    "        if self.two_model is False or two_model is None:\n",
    "            self.model.fit(X_t_training, y_training)\n",
    "        else:\n",
    "            try:\n",
    "                self.model.fit(X_t_training, y_training)\n",
    "            except:\n",
    "                control_ix = np.where(self.t_training == 0)[0]\n",
    "                self.m1 = deepcopy(self.model)\n",
    "                self.model.fit(X_training[control_ix,:], y_training[control_ix])\n",
    "                self.m1.fit(X_training[-control_ix,:],   y_training[-control_ix])\n",
    "                \n",
    "    def _predict_bin_or_con(self, model, X):\n",
    "        if self.proba:\n",
    "            try:\n",
    "                out = model.predict_proba(X)[:, 1]\n",
    "            except:\n",
    "                out = model.predict(X)\n",
    "        else:\n",
    "            out = model.predict(X)\n",
    "        return out\n",
    "                  \n",
    "    def predict(self,\n",
    "                    X: np.ndarray,\n",
    "                    ps_scores = None):\n",
    "        if self.ps_model is not None and ps_scores is None:\n",
    "            ps_scores = self.ps_model.predict_proba(X)\n",
    "            X = np.hstack((X, ps_scores[:,1].reshape((-1, 1))))\n",
    "        if self.two_model:\n",
    "            m0_preds = self._predict_bin_or_con(self.model, X)\n",
    "            m1_preds =  self._predict_bin_or_con(self.m1, X)\n",
    "            ite = m1_preds - m0_preds\n",
    "        else:\n",
    "            try:\n",
    "                X0 = np.hstack((X, np.zeros((X.shape[0], 1))))\n",
    "                X1 = np.hstack((X, np.ones((X.shape[0], 1))))\n",
    "                m1_preds = self._predict_bin_or_con(self.model, X1)\n",
    "                m0_preds = self._predict_bin_or_con(self.model, X0)\n",
    "                ite = m1_preds - m0_preds\n",
    "            except:\n",
    "                ite = self._predict_bin_or_con(self.model, X)\n",
    "        return np.array(ite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BaseActiveLearner(BaseEstimator):\n",
    "    \"\"\"Basic of Active Learners later used, with the capability for treatment effects\n",
    "    \n",
    "    Inspired by modAL's BaseLearner, however modified for ITE estimation. Dataset is provided by \n",
    "    a dictionary for easier usage and less clutter.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 estimator: BaseEstimator,\n",
    "                 acquisition_function: Callable,\n",
    "                 assignment_function: Union[Callable, None],\n",
    "                 stopping_function: Union[Callable, None],\n",
    "                 dataset: dict,\n",
    "                 **kwargs\n",
    "                ) -> None:\n",
    "        self.estimator = estimator\n",
    "        self.acquisition_function = acquisition_function\n",
    "        self.assignment_function = assignment_function\n",
    "        self.stopping_function = stopping_function\n",
    "        self.dataset = dataset\n",
    "        \n",
    "    def _update_dataset(self, query_idx, treatment, **kwargs):\n",
    "        \"\"\"Moves data with query_idx indices from pool to training\"\"\"\n",
    "        remove_data = kwargs[\"remove_data\"] if \"remove_data\" in kwargs else True\n",
    "        for data in [\"X\", \"t\", \"y\"]:\n",
    "            if self.dataset[f\"{data}_training\"].shape[0] > 0 :\n",
    "                try:\n",
    "                    self.dataset[f\"{data}_training\"] = np.concatenate((\n",
    "                        self.dataset[f\"{data}_training\"],\n",
    "                        self.dataset[f\"{data}_pool\"][query_idx,:]))\n",
    "                except:\n",
    "                    self.dataset[f\"{data}_training\"] = np.concatenate((\n",
    "                        self.dataset[f\"{data}_training\"],\n",
    "                        self.dataset[f\"{data}_pool\"][query_idx]))\n",
    "            else: \n",
    "                self.dataset[f\"{data}_training\"] = self.dataset[f\"{data}_pool\"][query_idx,:]\n",
    "            if remove_data:\n",
    "                self.dataset[f\"{data}_pool\"] = np.delete(self.dataset[f\"{data}_pool\"],\n",
    "                                                             query_idx, 0)\n",
    "                \n",
    "    def fit(self) -> None:\n",
    "        self.estimator.fit(self.dataset[\"X_training\"],\n",
    "                           self.dataset[\"t_training\"],\n",
    "                           self.dataset[\"y_training\"])\n",
    "        return None\n",
    "    \n",
    "    def predict(self, X):\n",
    "        self.estimator.predict(X)\n",
    "            \n",
    "    def query(self, no_query = None):\n",
    "        \"\"\"Main function to get labels of datapoints\"\"\"\n",
    "        query_idx = self.acquisition_function.select_data(self.estimator,\n",
    "                                                          self.dataset, \n",
    "                                                          no_query)\n",
    "        return query_idx\n",
    "    \n",
    "    def teach(self, query_idx, **kwargs):\n",
    "        treatment = self.assignment_function.select_treatment(self.estimator,\n",
    "                                                              self.dataset,\n",
    "                                                              query_idx)\n",
    "        matching = treatment == self.dataset[\"t_pool\"][query_idx]\n",
    "        \n",
    "        if matching.all():\n",
    "            self._update_dataset(query_idx, treatment, **kwargs)\n",
    "        elif matching.sum() > 0:\n",
    "            self._update_dataset(query_idx[matching], treatment[matching], **kwargs)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    def score(self, metric=\"PEHE\"):\n",
    "        if metric not in [\"Qini\", \"PEHE\", \"Cgains\"]:\n",
    "            raise ValueError(f\"Please use a valid error (PEHE, Qini, Cgains), {metric} is not valid\")\n",
    "        if metric == \"PEHE\":\n",
    "            preds = self.estimator.predict(self.dataset[\"X_test\"])\n",
    "            try:\n",
    "                sc = np.sqrt(np.mean(np.square(preds - self.dataset[\"ite_test\"])))\n",
    "            except KeyError:\n",
    "                raise Error(\"Check if dataset contains true ITE values\")\n",
    "        return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BaseAcquisitionFunction():\n",
    "    \"\"\"Base class for acquisition functions\"\"\"\n",
    "    def __init__(self,\n",
    "                no_query: int = 1,\n",
    "                method: str = \"top\") -> None:\n",
    "        self.no_query = no_query\n",
    "        self.method = method\n",
    "    \n",
    "    def calculate_metrics(self, model, dataset) -> np.array:\n",
    "        return model.predict(dataset[\"X_pool\"])\n",
    "    \n",
    "    def select_data(self, model, dataset, no_query):\n",
    "        if no_query is None:\n",
    "            no_query = self.no_query\n",
    "        metrics = self.calculate_metrics(model, dataset)\n",
    "        if self.method == \"top\":\n",
    "            query_idx = np.argsort(metrics)[-no_query:][::-1]\n",
    "            X_new = dataset[\"X_pool\"][query_idx,:]\n",
    "        return X_new, query_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BaseAssignmentFunction():\n",
    "    \"\"\"Base class for assignment functions\"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def select_treatment(self, model, dataset, query_idx):\n",
    "        return dataset[\"t_pool\"][query_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
