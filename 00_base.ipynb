{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from sklearn.base import BaseEstimator\n",
    "import numpy as np\n",
    "from typing import Union, Callable, Optional, Tuple, List, Iterator, Any\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass, field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = Union[np.array, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FitTask(type):\n",
    "    # https://stackoverflow.com/a/18859019\n",
    "    def __init__(cls, name, bases, clsdict):\n",
    "        if 'fit' in clsdict:\n",
    "            def new_fit(self, **kwargs):\n",
    "                try:\n",
    "                    X_training = kwargs[\"X_training\"] if \"X_training\" in kwargs else self.dataset[\"X_training\"]\n",
    "                    y_training = kwargs[\"y_training\"] if \"y_training\" in kwargs else self.dataset[\"y_training\"]\n",
    "                    t_training = kwargs[\"t_training\"] if \"t_training\" in kwargs else self.dataset[\"t_training\"]\n",
    "                except:\n",
    "                    raise ValueError(\"Can't find (X,t,y) data to fit the model on\")\n",
    "                try:\n",
    "                    ps_scores  = kwargs[\"ps_scores\"] if \"ps_scores\" in kwargs else self.dataset[\"ps_scores\"]\n",
    "                except:\n",
    "                    ps_scores = None\n",
    "                try:\n",
    "                    fun_to_prepare = bases['prepare_data'] if [\"prepare_data\"] in dir(\n",
    "                        bases) else self.prepare_data\n",
    "                    X_training, t_training, y_training, ps_scores = fun_to_prepare(X_training, t_training, y_training, ps_scores)\n",
    "                except:\n",
    "                    raise ValueError(\"Can't prepare data. Use either the default or implement new 'prepare_data' method\")\n",
    "                clsdict['fit'](self, X_training = X_training,\n",
    "                               t_training = t_training,\n",
    "                               y_training = y_training,\n",
    "                               ps_scores = ps_scores)\n",
    "            setattr(cls, 'fit', new_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "class BaseITEEstimator(BaseEstimator, metaclass=FitTask):\n",
    "    \"\"\"Base class for estimating treatment effects\n",
    "    \n",
    "    This is a base class, that is also usable on its own to estimate treatment effects.\n",
    "    It works with most models that have a .fit() method, but subclassing is also made\n",
    "    straightforward throught a metaclass. \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                model: Union[str, Callable] = None, \n",
    "                dataset : Union[dict,None] = None,\n",
    "                two_model: Union[bool,None] = None,\n",
    "                ps_model : Union[Callable, None] = None,\n",
    "                **kwargs)-> None:\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        self.two_model = two_model\n",
    "        self.ps_model = ps_model\n",
    "        self.proba = False\n",
    "        \n",
    "    def _fit_ps_model(self, X_training, t_training):\n",
    "        self.ps_model.fit(X_training, t_training)\n",
    "        \n",
    "    def prepare_data(self, X_training=None, t_training=None, y_training=None, ps_scores=None):\n",
    "        if X_training is None:\n",
    "            try:\n",
    "                X_training = deepcopy(self.dataset[\"X_training\"])\n",
    "                y_training = deepcopy(self.dataset[\"y_training\"])\n",
    "                t_training = deepcopy(self.dataset[\"t_training\"])\n",
    "            except:\n",
    "                raise ValueError(\"No data to fit the model on.\")\n",
    "        if np.unique(y_training).shape[0] == 2:\n",
    "            self.proba = True\n",
    "        if self.ps_model is not None or ps_scores is not None:\n",
    "            if self.ps_model is not None:\n",
    "                self._fit_ps_model(X_training, t_training)\n",
    "                ps_scores = self.ps_model.predict(X_training)\n",
    "            try:\n",
    "                X_training = np.hstack((X_training, ps_scores[:,1].reshape((-1, 1))))\n",
    "            except:\n",
    "                raise ValueError(f\"Shape of propensity scores is {ps_scores.shape},instead of (-1,1)\")\n",
    "        X_t_training = np.hstack((X_training, t_training.reshape(-1,1)))\n",
    "        if self.two_model is False:\n",
    "            X_training = deepcopy(X_t_training)\n",
    "\n",
    "        return X_training, t_training, y_training, ps_scores\n",
    "                \n",
    "    def fit(self, \n",
    "            X_training, \n",
    "            t_training,\n",
    "            y_training,\n",
    "            ps_scores,\n",
    "            **kwargs):\n",
    "        \"Fit function, using .fit() from other models\"        \n",
    "        if self.two_model is False or self.two_model is None:\n",
    "            self.model.fit(X_training, y_training)\n",
    "        else:\n",
    "            control_ix = np.where(t_training == 0)[0]\n",
    "            self.m1 = deepcopy(self.model)\n",
    "            self.model.fit(X_training[control_ix,:], y_training[control_ix])\n",
    "            self.m1.fit(X_training[-control_ix,:],   y_training[-control_ix])\n",
    "                \n",
    "    def _predict_bin_or_con(self, model, X):\n",
    "        if self.proba:\n",
    "            try:\n",
    "                out = model.predict_proba(X)[:, 1]\n",
    "            except:\n",
    "                out = model.predict(X)\n",
    "        else:\n",
    "            out = model.predict(X)\n",
    "        return out\n",
    "                  \n",
    "    def predict(self,\n",
    "                    X: np.ndarray,\n",
    "                    ps_scores = None,\n",
    "                    **kwargs):\n",
    "        if self.ps_model is not None or ps_scores is not None:\n",
    "            if self.ps_model is not None:\n",
    "                ps_scores = self.ps_model.predict_proba(X)\n",
    "            X = np.hstack((X, ps_scores[:,1].reshape((-1, 1))))\n",
    "        if self.two_model:\n",
    "            m0_preds = self._predict_bin_or_con(self.model, X)\n",
    "            m1_preds =  self._predict_bin_or_con(self.m1, X)\n",
    "            ite = m1_preds - m0_preds\n",
    "        else:\n",
    "            try:\n",
    "                X0 = np.hstack((X, np.zeros((X.shape[0], 1))))\n",
    "                X1 = np.hstack((X, np.ones((X.shape[0], 1))))\n",
    "                m1_preds = self._predict_bin_or_con(self.model, X1)\n",
    "                m0_preds = self._predict_bin_or_con(self.model, X0)\n",
    "                ite = m1_preds - m0_preds\n",
    "            except:\n",
    "                ite = self._predict_bin_or_con(self.model, X)\n",
    "        return np.asarray(ite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BaseActiveLearner(BaseEstimator):\n",
    "    \"\"\"Basic of Active Learners later used, with the capability for treatment effects\n",
    "    \n",
    "    Inspired by modAL's BaseLearner, however modified for ITE estimation. Dataset is provided by \n",
    "    a dictionary for easier usage and less clutter.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 estimator: BaseEstimator,\n",
    "                 acquisition_function: Callable,\n",
    "                 assignment_function: Union[Callable, list, None],\n",
    "                 stopping_function: Union[Callable, list, None],\n",
    "                 dataset: dict,\n",
    "                 al_steps: int = 1,\n",
    "                 offline = True,\n",
    "                 **kwargs\n",
    "                ) -> None:\n",
    "        self.estimator = estimator\n",
    "        if type(acquisition_function) is list:\n",
    "            self.acquisition_function_list = acquisition_function\n",
    "        else:\n",
    "            self.acquisition_function = acquisition_function\n",
    "            self.acquisition_function_list = []\n",
    "        if type(assignment_function) is list:\n",
    "            self.assignment_function_list = assignment_function\n",
    "        else:\n",
    "            self.assignment_function = assignment_function\n",
    "            self.assignment_function_list = []\n",
    "        self.stopping_function = stopping_function\n",
    "        self.dataset = deepcopy(dataset)\n",
    "        self.al_steps = al_steps\n",
    "        self.current_step = 0\n",
    "        self.next_query = True\n",
    "        self.offline = offline\n",
    "        if self.offline is False:\n",
    "            self.dataset.__dict__[\"X_training\"],\\\n",
    "            self.dataset.__dict__[\"t_training\"],\\\n",
    "            self.dataset.__dict__[\"y_training\"] = self.dataset.get_data(\n",
    "                self.dataset.no_training)\n",
    "            \n",
    "        \n",
    "    def _update_dataset(self, query_idx, **kwargs):\n",
    "        \"\"\"Moves data with query_idx indices from pool to training\"\"\"\n",
    "        remove_data = kwargs[\"remove_data\"] if \"remove_data\" in kwargs else True\n",
    "        if type(self.dataset) is not dict:\n",
    "            sds = self.dataset.__dict__\n",
    "        else:\n",
    "            sds = self.dataset\n",
    "        for data in [\"X\", \"t\", \"y\"]:\n",
    "            if sds[f\"{data}_training\"].shape[0] > 0 :\n",
    "                try:\n",
    "                    sds[f\"{data}_training\"] = np.concatenate((\n",
    "                        sds[f\"{data}_training\"],\n",
    "                        sds[f\"{data}_pool\"][query_idx,:]))\n",
    "                except:\n",
    "                    sds[f\"{data}_training\"] = np.concatenate((\n",
    "                        sds[f\"{data}_training\"],\n",
    "                        sds[f\"{data}_pool\"][query_idx]))\n",
    "            else: \n",
    "                sds[f\"{data}_training\"] = sds[f\"{data}_pool\"][query_idx,:]\n",
    "            if remove_data:\n",
    "                sds[f\"{data}_pool\"] = np.delete(sds[f\"{data}_pool\"],\n",
    "                                                             query_idx, 0)\n",
    "        try:\n",
    "            sds[\"y0_pool\"] = np.delete(sds[\"y0_pool\"],\n",
    "                                                             query_idx, 0)\n",
    "            sds[\"y1_pool\"] = np.delete(sds[\"y1_pool\"],\n",
    "                                                             query_idx, 0)\n",
    "        except:\n",
    "            pass\n",
    "                    \n",
    "                \n",
    "    def _select_counterfactuals(self, query_idx, treatment):\n",
    "        \"Rewrited observed outcome in pool for counterfactuals\"\n",
    "        self.dataset[\"y_pool\"][query_idx] = np.where(treatment == 1,\n",
    "                                                     self.dataset[\"y1_pool\"][query_idx],\n",
    "                                                     self.dataset[\"y0_pool\"][query_idx])\n",
    "        \n",
    "        self.dataset[\"t_pool\"][query_idx] = treatment\n",
    "                \n",
    "    def fit(self) -> None:\n",
    "        self.estimator.fit(X_training = self.dataset[\"X_training\"],\n",
    "                           t_training = self.dataset[\"t_training\"],\n",
    "                           y_training = self.dataset[\"y_training\"])\n",
    "        return None\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.estimator.predict(X=X)\n",
    "            \n",
    "    def query(self, no_query = None, acquisition_function = None):\n",
    "        \"\"\"Main function to select datapoints\"\"\"\n",
    "        if self.stopping_function is not None:\n",
    "            self.next_query = self.stopping_function.check_rule(\n",
    "                self.estimator, self.dataset, self.step)\n",
    "        if self.next_query:\n",
    "            if len(self.acquisition_function_list) == 0:\n",
    "                if acquisition_function is None:\n",
    "                    acquisition_function = self.acquisition_function\n",
    "            else:\n",
    "                if acquisition_function is None:\n",
    "                    acquisition_function = self.acquisition_function\n",
    "            if self.offline:\n",
    "                X_new, query_idx = acquisition_function.select_data(self.estimator,\n",
    "                                                              self.dataset, \n",
    "                                                              no_query)\n",
    "            else:\n",
    "                X_get = self.dataset.get_X(no_query = no_query)\n",
    "                data_to_estimate = {\"X_training\":self.dataset[\"X_training\"],\n",
    "                                   \"X_pool\": X_get}\n",
    "                decision_to_query = acquisition_function.select_data(self.estimator,\n",
    "                                                              data_to_estimate, \n",
    "                                                              no_query,\n",
    "                                                              offline = False)\n",
    "                if decision_to_query:\n",
    "                    self.X_to_add = X_get\n",
    "                    X_new = X_get\n",
    "                else:\n",
    "                    X_new = None\n",
    "                try:\n",
    "                    query_idx = self.dataset.selected_ix\n",
    "                except:\n",
    "                    query_idx = None\n",
    "        else:\n",
    "            X_new, query_idx = None, None\n",
    "        return X_new, query_idx\n",
    "    \n",
    "    def teach(self, query_idx=None, assignment_function = None, **kwargs):\n",
    "        \"\"\"Function to assign the selected labels \"\"\"\n",
    "\n",
    "        if len(self.assignment_function_list) == 0:\n",
    "            if assignment_function is None:\n",
    "                assignment_function = self.assignment_function\n",
    "            else:\n",
    "                raise ValueError(\"No assignment function provided\")\n",
    "        else:\n",
    "            if assignment_function is None:\n",
    "                assignment_function = self.assignment_function\n",
    "        try:\n",
    "            treatment = assignment_function.select_treatment(self.estimator,\n",
    "                                                              self.dataset,\n",
    "                                                              query_idx)\n",
    "            if \"y0_pool\" in self.dataset:\n",
    "                self._select_counterfactuals(query_idx, treatment)\n",
    "            matching = treatment == self.dataset[\"t_pool\"][query_idx]\n",
    "            if matching.all():\n",
    "                self._update_dataset(query_idx, **kwargs)\n",
    "            elif matching.sum() > 0:\n",
    "                self._update_dataset(query_idx[matching], **kwargs)\n",
    "            else:\n",
    "                pass\n",
    "        except (AttributeError, IndexError) as e:\n",
    "            treatment_to_add = self.dataset.get_t(X_new = self.X_to_add)\n",
    "            y = self.dataset.get_y(X_new=self.X_to_add, t_new = treatment_to_add)\n",
    "            self.dataset.__dict__[\"X_pool\"] = self.X_to_add\n",
    "            self.dataset.__dict__[\"t_pool\"] = treatment_to_add\n",
    "            self.dataset.__dict__[\"y_pool\"] = y\n",
    "            self._update_dataset(np.arange(y.shape[0]), remove_data=True)\n",
    "\n",
    "        return None\n",
    "    \n",
    "    def score(self, metric=\"PEHE\"):\n",
    "        metrics = [\"Qini\", \"PEHE\", \"Cgains\", \"decision\"]\n",
    "        if metric not in metrics:\n",
    "            raise ValueError(f\"Please use a valid error ({metrics}), {metric} is not valid\")\n",
    "        try:\n",
    "            preds = self.estimator.predict(X=self.dataset[\"X_test\"], return_mean=True)\n",
    "        except:\n",
    "            preds = self.estimator.predict(X=self.dataset[\"X_test\"])\n",
    "        if metric == \"PEHE\":\n",
    "            try:\n",
    "                sc = np.sqrt(np.mean(np.square(preds - self.dataset[\"ite_test\"])))\n",
    "            except KeyError:\n",
    "                raise Error(\"Check if dataset contains true ITE values\")\n",
    "        elif metric == \"decision\":\n",
    "            dec = np.where((preds >= 0) &( self.dataset[\"ite_test\"] >= 0), 1, 0)\n",
    "            sc = np.sum(dec)/self.dataset[\"ite_test\"].shape[0]\n",
    "        elif metric == \"Qini\":\n",
    "            \n",
    "        return sc\n",
    "    \n",
    "    def simulate(self, no_query: int = None, metric: str = \"Qini\") -> dict:\n",
    "        ds = deepcopy(self.dataset)\n",
    "        est = deepcopy(self.estimator)\n",
    "        res = {}\n",
    "        if len(self.acquisition_function_list) == 0:\n",
    "            laf = [self.acquisition_function]\n",
    "        else:\n",
    "            laf = self.acquisition_function_list\n",
    "        for af in laf:\n",
    "            if no_query is None:\n",
    "                no_query = af.no_query\n",
    "            self.dataset = deepcopy(ds)\n",
    "            self.estimator = deepcopy(est)\n",
    "            self.current_step = 0\n",
    "            res[af.name] = {}\n",
    "            for i in range(1, self.al_steps+1):\n",
    "                self.fit()\n",
    "                X_new, query_idx = self.query(no_query=no_query, acquisition_function = af)\n",
    "                if self.next_query:\n",
    "                    if self.offline:\n",
    "                        self.teach(query_idx)\n",
    "                    else:\n",
    "                        self.teach()\n",
    "                    res[af.name][i] = self.score(metric=metric)\n",
    "                    self.current_step += 1\n",
    "        self.simulation_results = res\n",
    "        return res\n",
    "    \n",
    "    def plot(self):\n",
    "        pd.DataFrame(self.simulation_results).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BaseAcquisitionFunction():\n",
    "    \"\"\"Base class for acquisition functions\"\"\"\n",
    "    def __init__(self,\n",
    "                no_query: int = 1,\n",
    "                method: str = \"top\",\n",
    "                name: str = \"base\") -> None:\n",
    "        self.no_query = no_query\n",
    "        self.method = method\n",
    "        self.name = name + \"_\" + str(no_query)\n",
    "    \n",
    "    def calculate_metrics(self, model, dataset) -> np.array:\n",
    "        \"\"\"Method to calculate base metrics for assignment function\"\"\"\n",
    "        return np.arange(dataset[\"X_pool\"].shape[0]) + 1\n",
    "    \n",
    "    def select_data(self, model, dataset, no_query, offline=True):\n",
    "        \"\"\"Based on the calculated metrics, select data and return X and indexes\"\"\"\n",
    "        if no_query is None:\n",
    "            no_query = self.no_query\n",
    "        metrics = self.calculate_metrics(model, dataset)\n",
    "        if offline:\n",
    "            if self.method == \"top\":\n",
    "                query_idx = np.argsort(np.asarray(metrics))[-no_query:][::-1]\n",
    "                X_new = dataset[\"X_pool\"][query_idx,:]\n",
    "            else:\n",
    "                raise NotImplementedError(\"Please use a method that is implemented\")\n",
    "            out = (X_new, query_idx)\n",
    "        else:\n",
    "            out = metrics.sum() >= metrics.shape[0]/2\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BaseAssignmentFunction():\n",
    "    \"\"\"Base class for assignment functions\"\"\"\n",
    "    \n",
    "    def __init__(self, base_selection = 0):\n",
    "        self.base_selection = base_selection\n",
    "    \n",
    "    def select_treatment(self, model, dataset, query_idx):\n",
    "        return dataset[\"t_pool\"][query_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BaseStoppingRule():\n",
    "    \"\"\"Base class for providing a stopping rule for the active learner\"\"\"\n",
    "    \n",
    "    def __init__(self, budget=None):\n",
    "        self.budget = budget\n",
    "    \n",
    "    def check_rule(self, model, dataset, step):\n",
    "        if self.budget - step >= 0:\n",
    "            out = False\n",
    "        else:\n",
    "            out = True\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class BaseDataGenerator():\n",
    "    ds: Union[dict, Callable]\n",
    "    dgp_x : Union[Callable, None] = None\n",
    "    dgp_t : Union[Callable, None] = None\n",
    "    dgp_y : Union[Callable, None] = None\n",
    "    no_training : int = 10\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        return super().__getattribute__(key)\n",
    "        \n",
    "    def get_X(self, method : str = \"random\", no_query : int = 1):\n",
    "        if self.ds is not None:\n",
    "            ix = np.random.randint(low = 0, high = self.ds[\"X_pool\"].shape[0], size=(no_query))\n",
    "            X_new = self.ds[\"X_pool\"][ix,:]\n",
    "            self.selected_ix = ix\n",
    "        else:\n",
    "            X_new = self.dgp_x(no_query)\n",
    "        self.X_new = X_new\n",
    "        return X_new\n",
    "            \n",
    "    def get_t(self, X_new=None):\n",
    "        if X_new is None:\n",
    "            X_new = self.X_new\n",
    "        if self.ds is not None:\n",
    "            t_new = self.ds[\"t_pool\"][self.selected_ix]\n",
    "        else:\n",
    "            t_new = self.dgp_t(X_new)\n",
    "        self.t_new = t_new\n",
    "        return t_new\n",
    "        \n",
    "    def get_y(self, X_new=None, t_new=None):\n",
    "        if X_new is None:\n",
    "            X_new = self.X_new\n",
    "        if t_new is None:\n",
    "            t_new = self.t_new\n",
    "        if self.ds is not None:\n",
    "            y_new = np.where(t_new == 1,\n",
    "                             self.ds[\"y1_pool\"][self.selected_ix],\n",
    "                             self.ds[\"y0_pool\"][self.selected_ix])\n",
    "        else:\n",
    "            y_new = self.dgp_y(X_new, t_new)\n",
    "        return y_new\n",
    "            \n",
    "    def get_data(self, no_query=1, as_test=False):\n",
    "        X_new = self.get_X(no_query=no_query)\n",
    "        t_new = self.get_t()\n",
    "        y_new = self.get_y()\n",
    "        if as_test:\n",
    "            self.__dict__[\"X_test\"] = X_new\n",
    "        return (X_new, t_new, y_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
